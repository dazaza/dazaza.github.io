<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>基于多视点几何的三维人体姿态自监督学习</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">基于多视点几何的三维人体姿态自监督学习</h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2020-05-28 12:00:19</div><div class="story_img_container"><a href="http://img.diglog.com/img/2020/5/aacf1b3738114cd3b1f92ff7dae0e401.jpeg"><img src="http://img.diglog.com/img/2020/5/aacf1b3738114cd3b1f92ff7dae0e401.jpeg" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>这是一个基于多视点几何纸的三维人体姿态自监督学习的Pytorch实现。</p><p>使用多视图几何学的3D人体姿势的自监督学习，Muhammed Kocabas*，Salih Karagoz*，Emre Akbas，IEEE计算机视觉和模式识别，2019年(*相等贡献)。</p><p>在这项工作中，我们提出了一种自监督的三维人体姿态估计方法EpipolarPose，它不需要任何3D地面真实数据或摄像机附加元件。</p><p>在训练过程中，EpipolarPose从多视图图像中估计2D姿态，然后利用核线几何来获得3D姿态和相机几何，随后使用这些几何来训练3D姿态估计器。</p><p>在测试时间内，只需使用RGB图像即可生成3D姿势结果。查看demo.ipynb并运行一个简单的演示。</p><p>这里我们展示了我们的模型在Human3.6M数据集上的一些样本输出，对于每组结果，我们首先显示输入图像，然后是地面真实情况、完全监督模型和自我监督模型输出。</p><p>代码是在Ubuntu 16.04上使用python 3.7.1开发的。NVIDIA GPU需要进行培训和测试。有关其他依赖项，请参阅Requirements.txt或Environmental ment.yml。</p><p>按照官方说明安装pytorch&gt；=v1.0.0。请注意，如果您使用的是pytorch&lt；v1.0.0版，则应按照https://github.com/Microsoft/human-pose-estimation.pytorch上的说明禁用cudnn&#39；的BatchNorm层实现。我们建议您使用更高版本的pytorch(&gt；=v1.0.0)</p><p>从GoogleDrive(150 MB)下载注释文件，格式为${root}文件夹下的zip文件。运行下面的命令将其解压缩。</p><p>您也可以使用下表中的链接下载预先训练好的权重。您可以将它们放在model目录下。最后，您的目录树应该如下所示。</p><p>${ROOT}├──Data/├──实验/├──lib/├──Models/├──Output/├──Refiner/├──SAMPLE_IMAGE/├──脚本/├──demo.ipynb├──自述文件.md└──要求.txt。</p><p>您将需要Human3.6M数据来训练或测试我们的模型。对于Human3.6M数据，请从Human 3.6M数据集下载。您需要创建帐户才能获得下载权限。下载视频文件后，您可以运行我们的脚本来提取图像。然后运行ln-s&lt；path_to_extracted_h36M_image&gt；${root}/data/h36m/image创建指向图像文件夹的软链接。目前您可以使用我们在步骤4中提供的注释文件，但我们将在清理和正确测试后不久发布注释准备脚本。</p><p>如果要根据MPII数据预先训练EpipolarPose模型，请从MPII人体姿势数据集(12.9 GB)下载图像文件。将其解压缩到${root}/data/mpii目录下。如果您已经拥有MPII数据集，则可以创建指向图像的软链接：ln-s&lt；path_to_mpii_image&gt；${root}/data/mpii/images。</p><p>在训练过程中，我们使用了合成遮挡。如果您想使用它，请按照他们的repo中的说明下载Pascal VOC数据集，并更新配置文件中的VOC参数。</p><p>${ROOT}|──Data/├─├──mpii/|└─├──annot/|└──Image/|└─├──h36M/└─├──annot/└──Image/├──s1/└──s5/.。</p><p>自监督(2DGT)：使用数据集提供的地面真实2D关键点的三角剖分进行训练。</p><p>自我监督+精细化：用精细化模块进行培训。有关此设置的详细信息，请参阅Refiner/Readme.md。</p><p>要从头开始训练EpipolarPose模型，您需要在MPII数据集上预先训练该模型。</p><p>要使用自监督模型运行验证脚本，请使用预先训练的权重的路径更新实验的MODEL.RESUME字段/h36m/Valid-ss.yaml，然后运行：</p><p>要在验证集上运行完全受监督的模型，请使用预先训练的权重的路径更新MODEL.RESUME实验字段/h36m/valid.yaml，然后运行：</p><p>@inProcestions{kocabas2019eppoll，作者={Kocabas，Muhammed and Karagoz，Salih and Akbas，Emre}，title={使用多视图几何进行3D人体姿势的自我监督学习}，booktitle={IEEE计算机视觉与模式识别会议(CVPR)}，月={6}，年={2019}}。</p><p>我们感谢作者发布了他们的代码。也请考虑引用他们的作品。</p><p>此代码可免费用于非商业用途，并可在这些条件下重新分发。有关详细信息，请参阅许可证。第三方数据集和软件受其各自的许可证约束。</p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://github.com/mkocabas/EpipolarPose">https://github.com/mkocabas/EpipolarPose</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/姿态/">#姿态</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/pose/">#pose</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/谷歌/">#谷歌</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy;2012-2021 diglog.com </div></div></body></html>