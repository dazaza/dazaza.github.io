<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>é¢‘åŸŸå›¾åƒå‹ç¼©ä¸æ»¤æ³¢</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">é¢‘åŸŸå›¾åƒå‹ç¼©ä¸æ»¤æ³¢</h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2020-11-07 11:23:58</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2020/11/ba20b2ca998cfddefca72488e5196223.png"><img src="http://img2.diglog.com/img/2020/11/ba20b2ca998cfddefca72488e5196223.png" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>Over 4 years ago I wrote a short blog post on images in the frequency domain:  https://blog.demofox.org/2016/07/28/fourier-transform-and-inverse-of-images/</p><p>4å¹´å¤šå‰ï¼Œæˆ‘å†™äº†ä¸€ç¯‡å…³äºé¢‘åŸŸå›¾åƒçš„ç®€çŸ­åšå®¢æ–‡ç« ï¼šhttps://blog.demofox.org/2016/07/28/fourier-transform-and-inverse-of-images/ã€‚</p><p> Itâ€™s time to revisit the topic a bit and add some more things.</p><p>ç°åœ¨æ˜¯æ—¶å€™å†å›é¡¾ä¸€ä¸‹è¿™ä¸ªè¯é¢˜ï¼Œå¹¶è¡¥å……ä¸€äº›ä¸œè¥¿äº†ã€‚</p><p> If you are curious about how the Fourier transform works, which can transform images or other data into the frequency domain, give this a read:  https://blog.demofox.org/2016/08/11/understanding-the-discrete-fourier-transform/</p><p>å¦‚æœä½ æƒ³çŸ¥é“å‚…é‡Œå¶å˜æ¢æ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Œå®ƒå¯ä»¥å°†å›¾åƒæˆ–å…¶ä»–æ•°æ®è½¬æ¢åˆ°é¢‘åŸŸï¼Œè¯·é˜…è¯»ä»¥ä¸‹å†…å®¹ï¼šhttps://blog.demofox.org/2016/08/11/understanding-the-discrete-fourier-transform/ã€‚</p><p>   When you transform an image into the frequency domain, you get a complex number (with a real and imaginary component) per pixel that you can use to get information about the frequencies (literal sine and cosine waves) that go into making the image. One piece of information is the â€œphaseâ€ or starting angle of that wave. You get the phase by using atan2(imaginary, real). The other piece of information is the â€œamplitudeâ€ of that wave, or how large the wave is in the image. The amplitude is the length of the 2d vector (real, imaginary).</p><p>å½“æ‚¨å°†å›¾åƒå˜æ¢åˆ°é¢‘åŸŸæ—¶ï¼Œæ‚¨ä¼šå¾—åˆ°æ¯ä¸ªåƒç´ çš„å¤æ•°(å…·æœ‰å®éƒ¨å’Œè™šéƒ¨)ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨è¯¥å¤æ•°æ¥è·å–æœ‰å…³åˆ¶ä½œå›¾åƒçš„é¢‘ç‡(æ–‡å­—æ­£å¼¦æ³¢å’Œä½™å¼¦æ³¢)çš„ä¿¡æ¯ã€‚ä¸€æ¡ä¿¡æ¯æ˜¯è¯¥æ³¢çš„â€œç›¸ä½â€æˆ–èµ·å§‹è§’ã€‚æ‚¨å¯ä»¥ä½¿ç”¨atan2(è™šæ•°ï¼Œå®æ•°)æ¥è·å¾—ç›¸ä½ã€‚å¦ä¸€æ¡ä¿¡æ¯æ˜¯è¯¥æ³¢çš„â€œæŒ¯å¹…â€ï¼Œæˆ–è€…è¯´è¯¥æ³¢åœ¨å›¾åƒä¸­æœ‰å¤šå¤§ã€‚æŒ¯å¹…æ˜¯2Då‘é‡(å®æ•°ã€è™šæ•°)çš„é•¿åº¦ã€‚</p><p> A quick and easy way to do image compression then, is to convert an image to frequency space, find the lowest amplitude frequencies and throw them away â€“ literally zero out the complex number. If you throw enough of them away, itâ€™ll take less data to describe the frequency content of an image, than the pixels of the image, and youâ€™ll have compressed the image.</p><p>é‚£ä¹ˆï¼Œè¿›è¡Œå›¾åƒå‹ç¼©çš„ä¸€ä¸ªå¿«é€Ÿè€Œç®€å•çš„æ–¹æ³•æ˜¯å°†å›¾åƒè½¬æ¢åˆ°é¢‘ç‡ç©ºé—´ï¼Œæ‰¾åˆ°æœ€ä½çš„æŒ¯å¹…é¢‘ç‡ï¼Œç„¶åä¸¢å¼ƒå®ƒä»¬--å­—é¢æ„æ€æ˜¯å°†å¤æ•°æ¸…é›¶ã€‚å¦‚æœä½ ä¸¢å¼ƒäº†è¶³å¤Ÿå¤šçš„å›¾åƒï¼Œé‚£ä¹ˆæè¿°å›¾åƒçš„é¢‘ç‡å†…å®¹æ‰€éœ€çš„æ•°æ®å°±ä¼šæ¯”å›¾åƒçš„åƒç´ å°‘ï¼Œè¿™æ ·ä½ å°±å¯ä»¥å‹ç¼©å›¾åƒäº†ã€‚</p><p> The more aggressive you are at throwing away frequencies though, the more the image quality will degrade. This is â€œlossyâ€ compression and is a simplified version of how jpg image compression works. Lossy compression is in contrast to lossless compression like you find in png files, which use something more like a .zip compression algorithm to perfectly encode all the source data.</p><p>ä¸è¿‡ï¼Œä½ åœ¨ä¸¢å¼ƒé¢‘ç‡æ–¹é¢è¶Šç§¯æï¼Œå›¾åƒè´¨é‡å°±ä¼šä¸‹é™å¾—è¶Šå¤šã€‚è¿™æ˜¯ä¸€ç§â€œæœ‰æŸâ€å‹ç¼©ï¼Œæ˜¯jpgå›¾åƒå‹ç¼©æ–¹å¼çš„ç®€åŒ–ç‰ˆæœ¬ã€‚æœ‰æŸå‹ç¼©ä¸PNGæ–‡ä»¶ä¸­çš„æ— æŸå‹ç¼©å½¢æˆå¯¹æ¯”ï¼ŒPNGæ–‡ä»¶ä½¿ç”¨æ›´åƒ.zipå‹ç¼©ç®—æ³•æ¥å®Œç¾åœ°ç¼–ç æ‰€æœ‰æºæ•°æ®ã€‚</p><p> In the code that goes with this post, the DoTestZeroing() function throws out the lowest 10% amplitude frequencies, then the lowest 20%, then 30% and so on up to 90%. At each stage, it writes all complex frequency values out into a binary file, which can then be compressed using .zip as a method for realizing the image compression. As the data gets more zeros, it gets more compressible.</p><p>åœ¨æœ¬æ–‡é™„å¸¦çš„ä»£ç ä¸­ï¼ŒDoTestZeroing()å‡½æ•°æŠ›å‡ºæœ€ä½10%çš„æŒ¯å¹…é¢‘ç‡ï¼Œç„¶åæ˜¯æœ€ä½çš„20%ï¼Œç„¶åæ˜¯30%ï¼Œä»¥æ­¤ç±»æ¨ï¼Œç›´åˆ°90%ã€‚åœ¨æ¯ä¸ªé˜¶æ®µï¼Œå®ƒå°†æ‰€æœ‰å¤é¢‘ç‡å€¼å†™å‡ºåˆ°ä¸€ä¸ªäºŒè¿›åˆ¶æ–‡ä»¶ä¸­ï¼Œç„¶åå¯ä»¥ä½¿ç”¨.zipä½œä¸ºå®ç°å›¾åƒå‹ç¼©çš„æ–¹æ³•æ¥å‹ç¼©è¯¥æ–‡ä»¶ã€‚éšç€æ•°æ®å˜å¾—æ›´å¤šé›¶ï¼Œå®ƒå˜å¾—æ›´å¯å‹ç¼©ã€‚</p><p> The top row in the image below shows an original 512Ã—1024 image, the DFT amplitude information, and the DFT phase information. The bottom row shows the same, but for an image which has had itâ€™s lower 90% amplitude frequencies thrown away. The DFT data is 8MB for both (uncompressed), and compresses to 7.7MB for the top picture, but only 847KB for the bottom picture. The inverse DFT was used to turn the modified frequency data on the bottom back into an image.</p><p>ä¸‹å›¾é¡¶è¡Œæ˜¾ç¤ºäº†åŸå§‹512Ã—1024å›¾åƒã€DFTå¹…åº¦ä¿¡æ¯å’ŒDFTç›¸ä½ä¿¡æ¯ã€‚æœ€ä¸‹é¢ä¸€è¡Œæ˜¾ç¤ºçš„æ˜¯ç›¸åŒçš„ï¼Œä½†å¯¹äºå·²ç»ä¸¢å¼ƒäº†è¾ƒä½90%æŒ¯å¹…é¢‘ç‡çš„å›¾åƒã€‚ä¸¤è€…(æœªå‹ç¼©)çš„DFTæ•°æ®éƒ½æ˜¯8MBï¼Œé¡¶éƒ¨å›¾ç‰‡å‹ç¼©åˆ°7.7MBï¼Œä½†åº•éƒ¨å›¾ç‰‡åªå‹ç¼©åˆ°847KBã€‚åˆ©ç”¨é€†DFTå°†ä¿®æ”¹åçš„åº•éƒ¨é¢‘ç‡æ•°æ®æ¢å¤ä¸ºå›¾åƒã€‚</p><p>  Here is another image which is 512Ã—512 and has DFT which is 4MB uncompressed. The top imageâ€™s DFT data compresses to 3.83MB, while the bottom compresses to 438KB.</p><p>è¿™æ˜¯å¦ä¸€å¹…512Ã—512çš„å›¾åƒï¼Œå…¶DFTæ˜¯4MBæœªå‹ç¼©çš„ã€‚ä¸Šå›¾çš„DFTæ•°æ®å‹ç¼©åˆ°3.83MBï¼Œä¸‹å›¾å‹ç¼©åˆ°438KBã€‚</p><p>  While fairly effective, this is also a pretty naive way of doing frequency based image compression!</p><p>è™½ç„¶ç›¸å½“æœ‰æ•ˆï¼Œä½†å¯¹äºåŸºäºé¢‘ç‡çš„å›¾åƒå‹ç¼©æ¥è¯´ï¼Œè¿™ä¹Ÿæ˜¯ä¸€ç§ç›¸å½“å¹¼ç¨šçš„æ–¹å¼ï¼</p><p> More sophisticated methods use the â€œDiscrete Cosine Transformâ€ or DCT instead of the DFT because it tends to make more of the frequency magnitudes zero, consolidating the data into fewer important frequencies, which means itâ€™s already smaller before you start throwing away frequencies. DCT and DFT also pretend that the images go on forever, instead of just stopping at the edge. DFT acts as if those images repeat in a tiled fashion, while DCT acts as if they are mirrored at each repeat, which can also be a nice property for image quality.</p><p>æ›´å¤æ‚çš„æ–¹æ³•ä½¿ç”¨â€œç¦»æ•£ä½™å¼¦å˜æ¢â€æˆ–DCTè€Œä¸æ˜¯DFTï¼Œå› ä¸ºå®ƒå€¾å‘äºä½¿æ›´å¤šçš„é¢‘ç‡å¹…åº¦ä¸ºé›¶ï¼Œå°†æ•°æ®åˆå¹¶åˆ°è¾ƒå°‘çš„é‡è¦é¢‘ç‡ï¼Œè¿™æ„å‘³ç€åœ¨ä½ å¼€å§‹ä¸¢å¼ƒé¢‘ç‡ä¹‹å‰ï¼Œå®ƒå·²ç»å¾ˆå°äº†ã€‚DCTå’ŒDFTè¿˜å‡è£…å›¾åƒæ°¸è¿œåœ¨ç»§ç»­ï¼Œè€Œä¸æ˜¯ä»…ä»…åœç•™åœ¨è¾¹ç¼˜ã€‚DFTçš„ä½œç”¨å°±åƒæ˜¯ä»¥å¹³é“ºçš„æ–¹å¼é‡å¤è¿™äº›å›¾åƒï¼Œè€ŒDCTçš„ä½œç”¨å°±åƒå®ƒä»¬åœ¨æ¯æ¬¡é‡å¤æ—¶éƒ½è¢«é•œåƒä¸€æ ·ï¼Œè¿™ä¹Ÿæ˜¯å›¾åƒè´¨é‡çš„ä¸€ä¸ªå¾ˆå¥½çš„å±æ€§ã€‚</p><p> Other methods break an image up into blocks before doing frequency based compression. Also, you can use wavelets to compress images, or principle component analysis or singular value decomposition. You can also fit your image with â€œwhateverâ€ basis functions you want, using L1 norm regularization to promote the coefficients of your fitting to be zero, to make the fit data be less sparse, just like DCT does compared to DFT.</p><p>å…¶ä»–æ–¹æ³•åœ¨è¿›è¡ŒåŸºäºé¢‘ç‡çš„å‹ç¼©ä¹‹å‰å°†å›¾åƒåˆ†è§£æˆå—ã€‚æ­¤å¤–ï¼Œæ‚¨è¿˜å¯ä»¥ä½¿ç”¨å°æ³¢æ¥å‹ç¼©å›¾åƒï¼Œæˆ–è€…ä½¿ç”¨ä¸»æˆåˆ†åˆ†ææˆ–å¥‡å¼‚å€¼åˆ†è§£ã€‚ä½ ä¹Ÿå¯ä»¥ç”¨ä½ æƒ³è¦çš„â€œä»»ä½•â€åŸºå‡½æ•°æ¥æ‹Ÿåˆä½ çš„å›¾åƒï¼Œä½¿ç”¨L1èŒƒæ•°æ­£åˆ™åŒ–å°†ä½ çš„æ‹Ÿåˆç³»æ•°æå‡ä¸ºé›¶ï¼Œä½¿æ‹Ÿåˆæ•°æ®ä¸é‚£ä¹ˆç¨€ç–ï¼Œå°±åƒDCTå’ŒDFTç›¸æ¯”æ‰€åšçš„é‚£æ ·ã€‚</p><p> Another thing you can do is use compressed sensing to skip a couple steps: You take a couple randomized but roughly evenly spaced samples from the image (blue noise or LDS are going to be good options here), and then you can eg find Fourier basis coefficients (DFT!) that match the sparse/irregular data samples you took. This is like throwing out low frequencies, but without having to DFT the whole data set, and then throw things out. It starts with sparse data and then fits it.</p><p>ä½ å¯ä»¥åšçš„å¦ä¸€ä»¶äº‹æ˜¯ä½¿ç”¨å‹ç¼©ä¼ æ„Ÿè·³è¿‡å‡ ä¸ªæ­¥éª¤ï¼šä½ ä»å›¾åƒä¸­å–å‡ ä¸ªéšæœºä½†å¤§è‡´å‡åŒ€çš„æ ·æœ¬(è“è‰²å™ªå£°æˆ–LDå°†æ˜¯å¾ˆå¥½çš„é€‰æ‹©)ï¼Œç„¶åä½ å°±å¯ä»¥ä¾‹å¦‚æ±‚å‡ºå‚…ç«‹å¶åŸºç³»æ•°(DFTï¼)ã€‚ä¸ä½ é‡‡é›†çš„ç¨€ç–/ä¸è§„åˆ™æ•°æ®æ ·æœ¬ç›¸åŒ¹é…ã€‚è¿™å°±åƒæ‰”æ‰ä½é¢‘ï¼Œä½†ä¸å¿…å¯¹æ•´ä¸ªæ•°æ®é›†è¿›è¡ŒDFTï¼Œç„¶åå†æ‰”æ‰ã€‚å®ƒä»ç¨€ç–æ•°æ®å¼€å§‹ï¼Œç„¶åå†è¿›è¡ŒåŒ¹é…ã€‚</p><p> Bart Wronski has several write ups on his blog in this area, so give them a read if you are interested:  https://bartwronski.com/2020/08/30/compressing-pbr-texture-sets-with-sparsity-and-dictionary-learning/</p><p>å·´ç‰¹Â·æ²ƒä¼¦æ–¯åŸº(Bart Wronski)åœ¨ä»–çš„åšå®¢ä¸Šæœ‰å‡ ç¯‡å…³äºè¿™ä¸€é¢†åŸŸçš„æ–‡ç« ï¼Œå¦‚æœä½ æ„Ÿå…´è¶£ï¼Œè¯·é˜…è¯»å®ƒä»¬ï¼šhttps://bartwronski.com/2020/08/30/compressing-pbr-texture-sets-with-sparsity-and-dictionary-learning/ã€‚</p><p> This is a great read showing how to fit data using L1 regularization and all the related information you might be interested in:  https://www.analyticsvidhya.com/blog/2017/06/a-comprehensive-guide-for-linear-ridge-and-lasso-regression/</p><p>è¿™æ˜¯ä¸€æœ¬å¾ˆæ£’çš„è¯»ç‰©ï¼Œå±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨L1æ­£åˆ™åŒ–æ¥æ‹Ÿåˆæ•°æ®ï¼Œä»¥åŠæ‚¨å¯èƒ½æ„Ÿå…´è¶£çš„æ‰€æœ‰ç›¸å…³ä¿¡æ¯ï¼šhttps://www.analyticsvidhya.com/blog/2017/06/a-comprehensive-guide-for-linear-ridge-and-lasso-regression/ã€‚</p><p> This video is a great overview of the random grab bag of other things I mentioned:  https://www.youtube.com/watch?v=aHCyHbRIz44&amp;feature=youtu.be</p><p>è¿™ä¸ªè§†é¢‘å¾ˆå¥½åœ°æ¦‚è¿°äº†æˆ‘æåˆ°çš„å…¶ä»–ä¸œè¥¿çš„éšæœºæŠ“åŒ…ï¼šhttps://www.youtube.com/watch?v=aHCyHbRIz44&ampï¼›feature=youtu.be</p><p>  In my previous post on this topic I showed how you could throw away frequencies that were farther than a certain distance from the center to low pass filter an image, aka blur it. I also showed how if you threw away frequencies closer than a certain distance, it would high pass filter an image, aka sharpen it.</p><p>åœ¨æˆ‘ä¸Šä¸€ç¯‡å…³äºè¿™ä¸ªä¸»é¢˜çš„æ–‡ç« ä¸­ï¼Œæˆ‘å±•ç¤ºäº†å¦‚ä½•ä¸¢å¼ƒè·ç¦»å›¾åƒä¸­å¿ƒä¸€å®šè·ç¦»çš„é¢‘ç‡ï¼Œå¯¹å›¾åƒè¿›è¡Œä½é€šæ»¤æ³¢ï¼Œä¹Ÿå°±æ˜¯æ¨¡ç³Šå›¾åƒã€‚æˆ‘è¿˜å±•ç¤ºäº†ï¼Œå¦‚æœä½ æ‰”æ‰æ¯”ä¸€å®šè·ç¦»æ›´è¿‘çš„é¢‘ç‡ï¼Œå®ƒä¼šå¯¹å›¾åƒè¿›è¡Œé«˜é€šæ»¤æ³¢ï¼Œä¹Ÿå°±æ˜¯é”åŒ–å›¾åƒã€‚</p><p> That throwing away of frequency data based on distance is the same as multiplying the frequency data by a mask which has a 1.0 in some places and a 0.0 in others. You can generalize this to multiply frequencies by any number. In the below I restrict the multiplications to be between 0 and 1, but you could definitely go to larger numbers or even go to negative numbers if you wanted.</p><p>ä¸¢å¼ƒåŸºäºè·ç¦»çš„é¢‘ç‡æ•°æ®ç­‰åŒäºå°†é¢‘ç‡æ•°æ®ä¹˜ä»¥æ©ç ï¼Œæ©ç åœ¨æŸäº›åœ°æ–¹ä¸º1.0ï¼Œåœ¨å…¶ä»–åœ°æ–¹ä¸º0.0ã€‚æ‚¨å¯ä»¥å°†å…¶æ¦‚æ‹¬ä¸ºå°†é¢‘ç‡ä¹˜ä»¥ä»»ä½•æ•°å­—ã€‚åœ¨ä¸‹é¢æˆ‘å°†ä¹˜æ³•é™åˆ¶åœ¨0åˆ°1ä¹‹é—´ï¼Œä½†æ˜¯å¦‚æœä½ æ„¿æ„ï¼Œä½ ç»å¯¹å¯ä»¥é€‰æ‹©æ›´å¤§çš„æ•°å­—ï¼Œç”šè‡³æ˜¯è´Ÿæ•°ã€‚</p><p> The below shows the patterns that the images are multiplied by in this section. Top row left to right is a low pass filter, then a stronger low pass filter (gets rid of more high frequencies than the other) and lastly is a notch filter or â€œband stopâ€ filter. The bottom row is the complement, such that you get the bottom by subtracting the image from white (1.0). Left to right, the bottom row is a high pass filter, then a weaker high pass filter (lets more low frequencies in) and then a band pass filter which only lets certain frequencies through.</p><p>ä¸‹é¢æ˜¾ç¤ºäº†åœ¨è¿™ä¸€éƒ¨åˆ†ä¸­å›¾åƒç›¸ä¹˜çš„æ¨¡å¼ã€‚é¡¶è¡Œä»å·¦åˆ°å³æ˜¯ä¸€ä¸ªä½é€šæ»¤æ³¢å™¨ï¼Œç„¶åæ˜¯ä¸€ä¸ªæ›´å¼ºçš„ä½é€šæ»¤æ³¢å™¨(å»æ‰äº†æ›´å¤šçš„é«˜é¢‘)ï¼Œæœ€åæ˜¯ä¸€ä¸ªé™·æ³¢æ»¤æ³¢å™¨æˆ–â€œå¸¦é˜»â€æ»¤æ³¢å™¨ã€‚æœ€ä¸‹é¢çš„ä¸€è¡Œæ˜¯è¡¥ç ï¼Œè¿™æ ·ä½ å°±å¯ä»¥ä»ç™½è‰²(1.0)ä¸­å‡å»å›¾åƒå¾—åˆ°åº•éƒ¨ã€‚ä»å·¦åˆ°å³ï¼Œæœ€ä¸‹é¢ä¸€è¡Œæ˜¯ä¸€ä¸ªé«˜é€šæ»¤æ³¢å™¨ï¼Œç„¶åæ˜¯ä¸€ä¸ªè¾ƒå¼±çš„é«˜é€šæ»¤æ³¢å™¨(è®©æ›´å¤šçš„ä½é¢‘è¿›å…¥)ï¼Œç„¶åæ˜¯ä¸€ä¸ªåªå…è®¸ç‰¹å®šé¢‘ç‡é€šè¿‡çš„å¸¦é€šæ»¤æ³¢å™¨ã€‚</p><p>  First up is the â€œLoki and Alanâ€ picture. Frequencies and actual picture values filtered from the pictures on the top are present in the pictures on the bottom and vice versa. In this way, blurring compared to sharpening (and edge detection) are two sides of the same coin. It just matters which part you throw away and which part you keep.</p><p>é¦–å…ˆå…³æ³¨çš„æ˜¯â€œæ´›åŸºå’Œè‰¾ä¼¦â€çš„ç…§ç‰‡ã€‚ä»é¡¶éƒ¨çš„å›¾ç‰‡ä¸­è¿‡æ»¤å‡ºçš„é¢‘ç‡å’Œå®é™…å›¾åƒå€¼å‡ºç°åœ¨åº•éƒ¨çš„å›¾ç‰‡ä¸­ï¼Œåä¹‹äº¦ç„¶ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ¨¡ç³Šå’Œé”åŒ–(å’Œè¾¹ç¼˜æ£€æµ‹)æ˜¯ä¸€æšç¡¬å¸çš„ä¸¤é¢ã€‚é‡è¦çš„æ˜¯ä½ æ‰”æ‰äº†å“ªéƒ¨åˆ†ï¼Œä¿ç•™äº†å“ªéƒ¨åˆ†ã€‚</p><p>  Here is what the frequency magnitudes look like. Note that each image has the magnitudes put through a log function, and also normalized to be 1.0 max. This is why even though the high pass filters (and band pass) darken the middle, it doesnâ€™t seem like it. The renormalization obscures that fact a bit, and the middle is brightest (largest amplitudes) which we saw when throwing out the lowest amplitudes in the last section.</p><p>è¿™æ˜¯é¢‘ç‡çš„å¤§å°çœ‹èµ·æ¥æ˜¯ä»€ä¹ˆæ ·å­ã€‚è¯·æ³¨æ„ï¼Œæ¯å¹…å›¾åƒéƒ½æœ‰ç»è¿‡å¯¹æ•°å‡½æ•°çš„å¹…å€¼ï¼Œå¹¶ä¸”ä¹Ÿå½’ä¸€åŒ–ä¸º1.0maxã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆå³ä½¿é«˜é€šæ»¤æ³¢å™¨(å’Œå¸¦é€š)ä¼šä½¿ä¸­é—´éƒ¨åˆ†å˜æš—ï¼Œä½†çœ‹èµ·æ¥å¹¶ä¸æ˜¯è¿™æ ·ã€‚é‡æ•´åŒ–ç¨å¾®æ©ç›–äº†è¿™ä¸€äº‹å®ï¼Œä¸­é—´æ˜¯æœ€äº®çš„(æŒ¯å¹…æœ€å¤§)ï¼Œè¿™æ˜¯æˆ‘ä»¬åœ¨æœ€åä¸€éƒ¨åˆ†ä¸­æŠ›å‡ºæœ€ä½æŒ¯å¹…æ—¶çœ‹åˆ°çš„ã€‚</p><p>  Here are the same filters applied to the scenery image. The top right image has some strange patterns in it if you look closely (click the image to view the full size in another tab).</p><p>ä»¥ä¸‹æ˜¯åº”ç”¨äºé£æ™¯å›¾åƒçš„ç›¸åŒæ»¤é•œã€‚å¦‚æœä½ ä»”ç»†è§‚å¯Ÿï¼Œå³ä¸Šè§’çš„å›¾ç‰‡ä¸­æœ‰ä¸€äº›å¥‡æ€ªçš„å›¾æ¡ˆ(ç‚¹å‡»å›¾ç‰‡å¯ä»¥åœ¨å¦ä¸€ä¸ªé€‰é¡¹å¡ä¸­æŸ¥çœ‹å®Œæ•´å°ºå¯¸)ã€‚</p><p>   In the last section, we made â€œimagesâ€ by using a distance function, to make values to multiply the frequencies by to filter out certain frequencies.</p><p>åœ¨æœ€åä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªè·ç¦»å‡½æ•°æ¥åˆ¶ä½œâ€œå›¾åƒâ€ï¼Œä½¿å€¼ä¹˜ä»¥ç‰¹å®šçš„é¢‘ç‡ï¼Œä»è€Œæ»¤é™¤ç‰¹å®šçš„é¢‘ç‡ã€‚</p><p> In this section, we are going to take two images, put them into frequency space, multiply them together, take them out of frequency space, and see what kind of results come out.</p><p>åœ¨è¿™ä¸€éƒ¨åˆ†ï¼Œæˆ‘ä»¬å°†æ‹æ‘„ä¸¤å¹…å›¾åƒï¼Œå°†å®ƒä»¬æ”¾å…¥é¢‘ç‡ç©ºé—´ï¼Œç›¸ä¹˜ï¼Œå†ä»é¢‘ç‡ç©ºé—´ä¸­å–å‡ºï¼Œçœ‹çœ‹ä¼šäº§ç”Ÿä»€ä¹ˆæ ·çš„ç»“æœã€‚</p><p> There is something called the â€œconvolution theoremâ€ which tells us that multiplication in the frequency domain, is the same as convolution between the images. Convolution is an expensive operation, because you have to loop through all the pixels of one image, and at each pixel, loop through the pixels of the other image, and do some multiplications and additions. Convolution is so slow, that it can actually be quicker to take two images you want convolved to frequency domain, multiply them together, and then take them out of frequency space to be images again.</p><p>æœ‰ä¸€ç§å«åšâ€œå·ç§¯å®šç†â€çš„ä¸œè¥¿å‘Šè¯‰æˆ‘ä»¬ï¼Œé¢‘åŸŸä¸­çš„ä¹˜æ³•ä¸å›¾åƒä¹‹é—´çš„å·ç§¯æ˜¯ä¸€æ ·çš„ã€‚å·ç§¯æ˜¯ä¸€ç§æ˜‚è´µçš„æ“ä½œï¼Œå› ä¸ºæ‚¨å¿…é¡»å¾ªç¯éå†ä¸€å¹…å›¾åƒçš„æ‰€æœ‰åƒç´ ï¼Œå¹¶åœ¨æ¯ä¸ªåƒç´ å¤„å¾ªç¯éå†å¦ä¸€å¹…å›¾åƒçš„åƒç´ ï¼Œç„¶åè¿›è¡Œä¸€äº›ä¹˜æ³•å’ŒåŠ æ³•è¿ç®—ã€‚å·ç§¯çš„é€Ÿåº¦éå¸¸æ…¢ï¼Œæ‰€ä»¥æŠŠä½ æƒ³è¦å·ç§¯åˆ°é¢‘åŸŸçš„ä¸¤å¹…å›¾åƒç›¸ä¹˜åœ¨ä¸€èµ·ï¼Œç„¶åæŠŠå®ƒä»¬ä»é¢‘ç‡ç©ºé—´ä¸­æ‹¿å‡ºæ¥å†æ¬¡æˆä¸ºå›¾åƒï¼Œå®é™…ä¸Šå¯èƒ½ä¼šæ›´å¿«ã€‚</p><p> Convolution is used in graphics for things like blurs, sharpening, or applying bokeh for depth of field, so speeding it up can be a big help! Convolution is also used in audio for things like reverberation which makes audio sound like it was played inside of a cave or a big cathedral.</p><p>å·ç§¯åœ¨å›¾å½¢ä¸­è¢«ç”¨äºæ¨¡ç³Šã€é”åŒ–æˆ–åº”ç”¨bokehæ¥è·å¾—æ™¯æ·±ï¼Œæ‰€ä»¥åŠ é€Ÿå®ƒä¼šæœ‰å¾ˆå¤§çš„å¸®åŠ©ï¼å·ç§¯ä¹Ÿè¢«ç”¨äºéŸ³é¢‘ä¸­ï¼Œæ¯”å¦‚æ··å“ï¼Œå®ƒä½¿éŸ³é¢‘å¬èµ·æ¥åƒæ˜¯åœ¨æ´ç©´æˆ–å¤§æ•™å ‚é‡Œæ’­æ”¾çš„å£°éŸ³ã€‚</p><p> Technical note: the â€œkernelâ€ image needs to be centered at pixel (0,0), not the center of the image. Also, the kernel image should be normalized so that summing up all of itâ€™s pixels adds up to 1.0. You also need to zero pad (add a black pixel border to) both the source image and kernel image to be the size of source+kernel+1 on the x and y axis before DFTâ€™ing so they are the same size, and to avoid wrapping problems. After you are done multiplying and inverse DFTâ€™ing, you can remove the black border again.</p><p>æŠ€æœ¯è¯´æ˜ï¼šâ€œå†…æ ¸â€å›¾ç‰‡éœ€è¦åœ¨åƒç´ (0ï¼Œ0)å¤„å±…ä¸­ï¼Œè€Œä¸æ˜¯å›¾ç‰‡çš„ä¸­å¿ƒã€‚å¦å¤–ï¼Œå†…æ ¸å›¾åƒåº”è¯¥è¢«è§„æ ¼åŒ–ï¼Œè¿™æ ·å®ƒçš„æ‰€æœ‰åƒç´ åŠ èµ·æ¥å°±æ˜¯1.0ã€‚åœ¨è¿›è¡ŒDFTä¹‹å‰ï¼Œæ‚¨è¿˜éœ€è¦å°†æºå›¾åƒå’Œå†…æ ¸å›¾åƒéƒ½å¡«é›¶(æ·»åŠ é»‘è‰²åƒç´ è¾¹æ¡†)ä¸ºxå’Œyè½´ä¸Šçš„æº+å†…æ ¸+1çš„å¤§å°ï¼Œä»¥ä½¿å®ƒä»¬çš„å¤§å°ç›¸åŒï¼Œå¹¶é¿å…åŒ…è£…é—®é¢˜ã€‚åœ¨å®Œæˆä¹˜æ³•å’Œé€†DFTåï¼Œå¯ä»¥å†æ¬¡ç§»é™¤é»‘è‰²è¾¹æ¡†ã€‚</p><p> Here are the 4 images we are going to use as kernel images: A star, a plus, a circle, and a blob.</p><p>ä»¥ä¸‹æ˜¯æˆ‘ä»¬å°†ç”¨ä½œå†…æ ¸å›¾åƒçš„4ä¸ªå›¾åƒï¼šä¸€ä¸ªæ˜Ÿæ˜Ÿã€ä¸€ä¸ªåŠ å·ã€ä¸€ä¸ªåœ†åœˆå’Œä¸€ä¸ªæ–‘ç‚¹ã€‚</p><p>      You can see that the images somehow take on the qualities of the kernelâ€¦ the star one is very angular, the plus one is very â€œplus likeâ€ and the circular one is very circular. Note how the blob acts a lot like a low pass filter! In frequency space, it does actually look like one, so that makes sense:</p><p>æ‚¨å¯ä»¥çœ‹åˆ°ï¼Œè¿™äº›å›¾åƒä»¥æŸç§æ–¹å¼å‘ˆç°å‡ºå†…æ ¸â€¦çš„å“è´¨ã€‚æ˜Ÿå½¢çš„å¾ˆæœ‰æ£±è§’ï¼Œæ­£çš„å¾ˆâ€œæ­£åƒâ€ï¼Œåœ†å½¢çš„å¾ˆåœ†ã€‚è¯·æ³¨æ„ï¼Œæ–‘ç‚¹çš„è¡Œä¸ºéå¸¸åƒä¸€ä¸ªä½é€šæ»¤æ³¢å™¨ï¼åœ¨é¢‘ç‡ç©ºé—´ä¸­ï¼Œå®ƒçœ‹èµ·æ¥ç¡®å®åƒä¸€ä¸ªï¼Œæ‰€ä»¥è¿™æ˜¯æœ‰é“ç†çš„ï¼š</p><p>    If you think the above looks weird when doing convolution on images, you should give a listen to convolution being used in audio. When used for reverb it sounds good, and sounds correct, but if you use it to convolve arbitrary audio samples together, you can get some really interesting and bizarre sounds! You can hear that here:  https://blog.demofox.org/2015/03/23/diy-synth-convolution-reverb-1d-discrete-convolution-of-audio-samples/</p><p>å¦‚æœä½ è§‰å¾—åœ¨å›¾åƒä¸Šåšå·ç§¯çœ‹èµ·æ¥å¾ˆå¥‡æ€ªï¼Œä½ åº”è¯¥å¬å¬éŸ³é¢‘ä¸­ä½¿ç”¨çš„å·ç§¯ã€‚å½“ç”¨äºæ··å“æ—¶ï¼Œå®ƒå¬èµ·æ¥å¾ˆå¥½å¬ï¼Œè€Œä¸”å¬èµ·æ¥å¾ˆæ­£ç¡®ï¼Œä½†æ˜¯å¦‚æœä½ ç”¨å®ƒæŠŠä»»æ„çš„éŸ³é¢‘æ ·æœ¬å·ç§¯åœ¨ä¸€èµ·ï¼Œä½ å¯ä»¥å¾—åˆ°ä¸€äº›éå¸¸æœ‰è¶£å’Œå¥‡æ€ªçš„å£°éŸ³ï¼ä½ å¯ä»¥åœ¨è¿™é‡Œå¬åˆ°ï¼šhttps://blog.demofox.org/2015/03/23/diy-synth-convolution-reverb-1d-discrete-convolution-of-audio-samples/ã€‚</p><p> The dark border around the image is an artifact from adding a black border around the images to make them the right size (zero padding). If you instead just make the convolution kernel image as large as the image you are convolving (and that is already a power of 2, since this FFT requires that), youâ€™d get the below, which has part of the image â€œwrappingâ€ across from the other side.</p><p>å›¾åƒå‘¨å›´çš„é»‘è‰²è¾¹æ¡†æ˜¯é€šè¿‡åœ¨å›¾åƒå‘¨å›´æ·»åŠ é»‘è‰²è¾¹æ¡†ä»¥ä½¿å…¶å¤§å°åˆé€‚(é›¶å¡«å……)è€Œäº§ç”Ÿçš„ç‘•ç–µã€‚å¦‚æœä½ åªæ˜¯æŠŠå·ç§¯å†…æ ¸å›¾åƒåšå¾—å’Œä½ è¦å·ç§¯çš„å›¾åƒä¸€æ ·å¤§(è¿™å·²ç»æ˜¯2çš„å¹‚äº†ï¼Œå› ä¸ºè¿™æ˜¯FFTçš„è¦æ±‚)ï¼Œä½ ä¼šå¾—åˆ°ä¸‹é¢çš„å›¾åƒï¼Œå®ƒçš„ä¸€éƒ¨åˆ†å›¾åƒä»å¦ä¸€é¢â€œåŒ…è£¹â€è¿‡æ¥ã€‚</p><p>  If you used the DCT (discrete cosine transform) instead, it would MIRROR the texture instead of wrapping it, so youâ€™d get more similar pixels to what should be there most of the time, compared to DFT which wraps. Another way to solve this problem though is if you are doing convolution in image space, instead of frequency space, is you can throw away any samples that go outside of the valid area of the images. You want to sum up the weight of the samples you actually took though in this case, and divide the final convolution sum by that weight, to normalize it. That will make pixels near the border have higher weights than they should, but it can be a less jarring artifact than the black border, wrapping, or mirroring artifacts.</p><p>å¦‚æœä½ ä½¿ç”¨DCT(ç¦»æ•£ä½™å¼¦å˜æ¢)ï¼Œå®ƒä¼šé•œåƒçº¹ç†è€Œä¸æ˜¯åŒ…è£¹å®ƒï¼Œæ‰€ä»¥ä½ ä¼šå¾—åˆ°æ›´å¤šä¸å¤§å¤šæ•°æ—¶å€™åº”è¯¥å­˜åœ¨çš„åƒç´ ç›¸ä¼¼çš„åƒç´ ï¼Œè€Œä¸æ˜¯åŒ…è£¹çš„DFTã€‚ä¸è¿‡ï¼Œè§£å†³è¿™ä¸ªé—®é¢˜çš„å¦ä¸€ç§æ–¹æ³•æ˜¯ï¼Œå¦‚æœä½ åœ¨å›¾åƒç©ºé—´è€Œä¸æ˜¯é¢‘ç‡ç©ºé—´è¿›è¡Œå·ç§¯ï¼Œä½ å¯ä»¥ä¸¢å¼ƒä»»ä½•è¶…å‡ºå›¾åƒæœ‰æ•ˆåŒºåŸŸçš„æ ·æœ¬ã€‚ä½ éœ€è¦æŠŠä½ å®é™…é‡‡é›†çš„æ ·æœ¬çš„é‡é‡ç›¸åŠ ï¼Œç„¶åå°†æœ€ç»ˆçš„å·ç§¯å’Œé™¤ä»¥è¿™ä¸ªé‡é‡ï¼Œä»¥ä½¿å…¶å½’ä¸€åŒ–ã€‚è¿™å°†ä½¿è¾¹ç•Œé™„è¿‘çš„åƒç´ å…·æœ‰æ¯”å…¶åº”æœ‰çš„æ›´é«˜çš„æƒé‡ï¼Œä½†ä¸é»‘è‰²è¾¹æ¡†ã€åŒ…è£¹æˆ–é•œåƒç‘•ç–µç›¸æ¯”ï¼Œå®ƒå¯èƒ½ä¸æ˜¯é‚£ä¹ˆåˆºè€³çš„ç‘•ç–µã€‚</p><p> Truth be told, many of the operations in this article can be done in a handful of lines of python. I find a lot of value in implementing things myself though, as it helps me internalize the ideas to better understand when and how to use them, and how to avoid problems/mysteries that come up when things are used as black boxes. I feel the tide turning though after a recent look at the sea of algorithms relating to SVD,PCA and finding eigenvectors. That is some crazy stuff, and way too much for a single person to deal with, while still trying to be competent in other topics ğŸ˜›</p><p>è¯´å®è¯ï¼Œæœ¬æ–‡ä¸­çš„è®¸å¤šæ“ä½œéƒ½å¯ä»¥åœ¨å‡ è¡ŒPythonä»£ç ä¸­å®Œæˆã€‚ä¸è¿‡ï¼Œæˆ‘å‘ç°è‡ªå·±å®ç°è¿™äº›ä¸œè¥¿å¾ˆæœ‰ä»·å€¼ï¼Œå› ä¸ºå®ƒå¸®åŠ©æˆ‘å°†æƒ³æ³•å†…åŒ–ï¼Œä»¥ä¾¿æ›´å¥½åœ°ç†è§£ä½•æ—¶ä»¥åŠå¦‚ä½•ä½¿ç”¨å®ƒä»¬ï¼Œä»¥åŠå¦‚ä½•é¿å…å½“ä¸œè¥¿è¢«ç”¨ä½œé»‘åŒ£å­æ—¶å‡ºç°çš„é—®é¢˜/è°œå›¢ã€‚ä¸è¿‡ï¼Œåœ¨æœ€è¿‘ç ”ç©¶äº†ä¸å¥‡å¼‚å€¼åˆ†è§£(SVD)ã€ä¸»æˆåˆ†åˆ†æ(PCA)å’Œå¯»æ‰¾ç‰¹å¾å‘é‡ç›¸å…³çš„å¤§é‡ç®—æ³•ä¹‹åï¼Œæˆ‘æ„Ÿè§‰æ½®æµå‘ç”Ÿäº†å˜åŒ–ã€‚è¿™æ˜¯ä¸€äº›ç–¯ç‹‚çš„äº‹æƒ…ï¼Œå¯¹äºä¸€ä¸ªäººæ¥è¯´å¤ªéš¾å¤„ç†äº†ï¼ŒåŒæ—¶ä»ç„¶è¯•å›¾åœ¨å…¶ä»–è¯é¢˜ä¸Šèƒœä»»ğŸ˜›</p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://blog.demofox.org/2020/11/04/frequency-domain-image-compression-and-filtering/">https://blog.demofox.org/2020/11/04/frequency-domain-image-compression-and-filtering/</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/å›¾åƒå‹ç¼©/">#å›¾åƒå‹ç¼©</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/domain/">#domain</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/å›¾åƒ/">#å›¾åƒ</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/è®¾è®¡/">#è®¾è®¡</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/æ¸¸æˆ/">#æ¸¸æˆ</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/åˆ›æ„/">#åˆ›æ„</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/è‹¹æœ/">#è‹¹æœ</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/æ‘„å½±/">#æ‘„å½±</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/è½¯ä»¶/">#è½¯ä»¶</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/ç¾å›½/">#ç¾å›½</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/å›¾ç‰‡/">#å›¾ç‰‡</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/æ‰‹æœº/">#æ‰‹æœº</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/è§†é¢‘/">#è§†é¢‘</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/å¹¿å‘Š/">#å¹¿å‘Š</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/å…è´¹/">#å…è´¹</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/è°·æ­Œ/">#è°·æ­Œ</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/ç½‘ç«™/">#ç½‘ç«™</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/å¾®è½¯/">#å¾®è½¯</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/ä¸‹è½½/">#ä¸‹è½½</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/éŸ³ä¹/">#éŸ³ä¹</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/linux/">#linux</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/åšå®¢/">#åšå®¢</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/ç¨‹åº/">#ç¨‹åº</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/è‰ºæœ¯/">#è‰ºæœ¯</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy; 2020 diglog.com </div></div></body></html>