<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>用Kuhn Poker将反事实的遗憾降至最低</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">用Kuhn Poker将反事实的遗憾降至最低</h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2020-05-26 04:53:27</div><div class="page_narrow text-break page_content"><p>如果您有意见，请在Twitter(@vpj)上找到我，或者在Github repo中打开一个问题。</p><p>库恩扑克是一种双人3牌投注游戏，玩家从王牌、国王牌和皇后牌中各拿到一张牌(没有花色)，每包只有三张牌，所以少了一张牌。王牌击败国王和王后，国王击败皇后-就像正常的纸牌排名一样。</p><p>两个玩家都下注$S$筹码(盲目押注$S$筹码)，看过牌后，第一个玩家可以通过或下注$1$筹码。</p><p>如果第一个玩家下注，第二个玩家可以下注(即叫牌)$1$筹码或传球(即折叠)。如果第二个玩家下注，且牌较高的玩家赢得赌注。</p><p>这个游戏是重复进行的，一个好的策略将优化长期效用(或赢利)。</p><p>KAP-玩家1得到K，玩家2获得A。玩家1传球。2号玩家没有下注机会，2号玩家赢得了2美元筹码。</p><p>QKBP-1号玩家得到Q号，2号玩家得到K号，1号玩家下注一个筹码。玩家2传球(折叠)。1号博弈者得到$2S+1$的赌注，因为2号博弈者放弃了。</p><p>QAbb-1号玩家得到Q，2号玩家得到A，1号玩家下注一个筹码。2号玩家也会下注(打电话)。2号玩家赢得2美元+2美元的赌注。</p><p>根据纳什定理，该博弈存在纳什均衡，即存在两个参与者的组合策略，使得两个参与者都不能通过改变她的策略来增加效用。</p><p>如果第一个玩家因为1.和2而得了K，那么他只有在下注的情况下才会输。因此，如果第一名选手得了K，他就应该及格。</p><p>如果第一个玩家有一个Q，他有时应该虚张声势并下注。比方说，如果第一个玩家得到了Q，他可能用$p_1$下注。</p><p>类似地，如果第二个玩家得到K，他将以概率$p_2$下注(如果第一个玩家确实下注了)。</p><p>那么第一个牌手(AK，AQ，KA，KQ，QA，QK)的总效用是。</p><p>$$\BEGIN{ALIGN}U_1=\frac{1}{6}\BIG[&amp；+(1+S)p_2+S(1-p_2)\Label{Ak}\Tag{Ak}\\&amp；+S\Label{aq}\Tag{Aq}\\&amp；-S\Label{Ka}\Tag{Ka}\\&amp；+S\Label{Kq}\Tag{Kq}\\&amp；-(1+S)p_1-S(1-p_1)\Label{qa}\Tag{QA}\\&amp；-(1+S)p_1 p_2+S p_1(1-p_2)-S(1-p_1)\BIG]\Label{qk}\tag{qk}\\=\frac{1}{6}\BIG[&amp；+S+p_2\\&amp；+S\\&amp；-S-p_1\\&amp；-p_1 p_2-2 S p_1 p_2+2 S p_1-S\BIG]\\=\frac{1}{6}\BIG[&amp；+p_2-p_1-p_1 p_2-2 S p_2+2 S p_1\BIG]\\=\frac{1}{6}\BIG[&amp；+p_1(2 S-1-p_2-2 S p_2)+p_2\BIG]\Label{a}\Tag{1}\\=\frac{1}{6}\BIG[&amp；+p_2(1-p_1-2 Sp_1)-p_1+2 S p_1\BIG]\Label{b}\Tag{2}\End{Align}$$。</p><p>从$(2)$，$1-p_1-2 S p_1\gtrless 0\Equiv\frac{1}{1+2 S}\gtrless p_1$。</p><p>案例1：如果$\frac{1}{1+2S}&lt；p_1$，第二个玩家将选择$p_2=1$，第一个玩家的最大效用为$\frac{1}{6}[1-2 p_1]=\frac{1}{6}\frac{2 S-1}{1+2 S}$</p><p>案例2：如果$\frac{1}{1+2 S}&gt；p_1$，第二个玩家将选择$p_2=0$，第一个玩家的最大效用为$\frac{1}{6}p_1(2 S-1)=\frac{1}{6}\frac{2 S-1}{1+2 S}$。</p><p>案例3：如果$\frac{1}{1+2 S}=p_1$，则该实用程序将独立于$p_2$，第一个玩家的最大效用将为$\frac{1}{6}p_1(2 S-1)=\frac{1}{6}\frac{2 S-1}{1+2 S}$。</p><p>在这三种情况下，第一个玩家的最佳策略都是$p_1=\frac{1}{1+2S}$。</p><p>类似于$(1)$，第二方的最佳策略是$p_2=\frac{2S-1}{1+2S}$。</p><p>在这一点上，任何一方都不能通过改变策略来增加自己的效用，因此这是纳什均衡。</p><p>从键入导入列表，newtype，dict，cast将Altair导入为alt导入Numpy作为NP从labml导入手电筒从labml导入分析从labml导入记录器，实验，monit，跟踪器从labml导入文本.logger从matplotlib导入pylot作为PLT。</p><p>$S$，Blinds，是每位玩家在看牌前需要下注的筹码数量。</p><p>P_1，P_2=NP。网格(Range(0,100，5)，Range(0,100，5))p_1，p_2=p_1/100，p_2/100p_1=火炬。张量(p_1，Requires_grad=True)p_2=Torch。张量(p_2，Requires_grad=True)u_1=1/6*(p_2-p_1-p_1*p_2-2*百叶窗*p_1*p_2+2*百叶窗*p_1)</p><p>def PLOT_Matrix()：x=p_1。分离()。Numpy()。Ravel()#*100 y=p_2。分离()。Numpy()。RAVEL()#*100 z=u_1。分离()。Numpy()。RAVEL()data=[]for i in range(len(X))：data。APPEND({&#39；p1&#39；：x[i]，&#39；p2&#39；：y[i]，&#39；U1&#39；：Z[i]})source=alt。DATA(VALUES=DATA)返回ALT。图表(来源)。mark_rect()。编码(x=&#39；p1：n&#39；，y=alt.。y(&#39；p2：N&#39；，Sort=&#39；降序&#39；)，color=&#39；U1：q&39；)Plot_Matrix()。</p><p>def lot_grads()：U_1。SUM()。向后(RETAIN_GRAPH=TRUE)p_1_grad=p_1。格拉德。克隆()p_1。格拉德。零p2。格拉德。ZERO_()(-u_1)。SUM()。向后(RETAIN_GRAPH=TRUE)p_2_grad=p_2。格拉德。克隆()p_1。格拉德。零p2。格拉德。ZERO_()_，AX=PLT。子图(FigSize=(9，9))箭图=AX。箭筒(p_1。DETACH()，p_2。DETACH()，p_1_grad，p_2_grad)plt.。show()Plot_grads()。</p><p>当$S=1$时，纳什均衡位于$(0.33，0.33)$附近，梯度似乎围绕着它。</p><p>反事实后悔最小化利用后悔匹配来寻找最小化当前遗憾的策略，在大量迭代中的平均策略将收敛到纳什均衡。</p><p>$a$，动作是玩家或凭运气进行的动作。这要么是打赌(p代表传球，b代表下注)，要么是发出的牌(A，K，Q)。</p><p>$h$，History，是当前游戏的历史，也就是玩家发出的牌和采取的动作。我们表示$h$是一个字符串，其中前两个字母是发给两个玩家的牌，其余是下注动作。</p><p>KA-玩家1得到K，玩家2得到A，这是玩家1采取行动的机会。</p><p>KAP-玩家1得到K，玩家2获得A。玩家1传球。游戏结束了。这是一份终结性的历史记录。</p><p>KAB-博弈者1得到K，博弈者2得到A，博弈者1下注筹码。这是玩家采取行动的机会。</p><p>KAbp-博弈者1得到K，博弈者2得到A，博弈者1下注筹码。2号玩家传球。游戏结束了。这是一份终结性的历史记录。</p><p>KABB-博弈者1得到K，博弈者2得到A，博弈者1下注筹码。2号玩家通过下注筹码来叫牌。游戏结束了。这是一份终结性的历史记录。</p><p>$i$，InfoSet`是一个信息集。它代表玩家可用的信息。这类似于代理的状态。在库恩扑克的情况下，它是他们手中的卡片和投注信息。</p><p>类信息集：遗憾：DICT[Action，Float]策略：DICT[Action，Float]Cumulative_Strategy：DICT[Action，Float]Average_Strategy：DICT[Action，Float]def__init__(self，key：str)：Self。KEY=KEY SELF。后悔={a：0表示操作中(自我)}n_操作=len(操作(自我))自我。策略={a：1/n_Actions for a In Actions(Self)}Self。Cumulative_Strategy={a：0，用于In Actions(Self)}自身。Average_Strategy={a：0 for a in Actions(Self)}def__repr__(Self)：return repr(sel.。策略)INFO_SETS：dict[字符串，信息集]={}。</p><p>KA-Player 1是当前玩家。他可以看到他的卡K，所以信息集是K。</p><p>KAB-玩家2是当前玩家。他可以看到他的卡a和投注历史b，所以信息集是Ab。</p><p>def info_set(h：历史记录)-&gt；InfoSet：i=Player(H)Visible=h[i]+h[2：]如果不可见，则不在INFO_SETS中：INFO_SETS[Visible]=InfoSet(Visible)返回INFO_SETS[Visible]</p><p>$A(I)$，Actions，给出玩家在由$i$表示的当前状态下可以采取的动作集。</p><p>函数IS_CHANGE检查下一个动作是否是机会动作，而SAMPLE_CHANGE对某个机会动作的动作进行采样。这是用来发牌的。</p><p>定义为_Chance(h：历史)-&gt；bool：Return len(H)&lt；2 def Sample_Chance(h：历史)-&gt；操作：While True：R=NP。随机的。Randint(len(Chance))Chance=h中c的机会[r]：if c==Chance：Chance=None Break If Chance不是None：return cast(Action，Chance)。</p><p>$\sigma_i^t(I)$，策略是玩家$i$在信息集合$i$的训练迭代$t$时的策略。它给出了A(I)$中动作$a\的概率。</p><p>$u_i(Z)$，TERMINAL_UTILITY是玩家$i$在终端游戏历史记录$z$的效用。终端游戏历史记录是已经完成的游戏的历史记录。如果给定的历史记录是终端，则返回IS_TERMINAL，并且。</p><p>def is_Terminal(h：历史)：if len(H)&lt；=2：如果h[-1]==&#39；p&#39；：如果h[-2：]==&#39；则返回True如果h[-2：]==&#39；bb&#39；：返回True返回False def Terminal_Utility(h：History，i：Player)-&gt；Float：Winner=-1+2*(h[0]&lt；h[1])Utility=0 if h[-2：]==&#39；BP&#39；：Utility=Blinds elif h[-2：]==&#39；bb&39；：Utility=Winner*(1+Blinds)Elif h[-1]==&#39；p&#39；：Utility=Winner*Blinds if i==PLALES[0]：Return Utility ELSE：Return-Utility。</p><p>博弈者$i$的预期效用为$h$，而博弈者的策略为$\sigma$，</p><p>$$u_i(\sigma，h)=\sum_{z\in Z，h\sqset z}\pi^\sigma(h，z)u_i(Z)$\pi^\sigma(h，z)$是具有$\sigma$策略的玩家从$h$到达$z$的概率。</p><p>如果$u_i(\sigma_{i\to a}，h)$总是在当前信息集中执行操作$a$，则$u_i是实用程序。</p><p>$$\BEGIN{ALIGN}u_i(\sigma_{i\to a}，h)&amp；=u_i(\sigma，ha)\\u_i(\sigma，h)&amp；=\sum_{a\in A(I)}\sigma(i，a)u_i(\sigma_{i\to a}，h)\end{Align}$$。</p><p>$\pi_{-i}^\sigma(H)$是如果玩家$i$采取了所有导致$h$的动作，概率为$1$，则达到$h$的概率。</p><p>历史$h$没有采取行动的反事实遗憾是$$r_i(h，a)=v_i(\sigma_{i\to a}，h)-v_i(\sigma，h)$$。</p><p>在信息集合$i$处未采取行动的反事实遗憾为$$r_i(i，a)=\sum_{h\in i}r_i(h，a)$$。</p><p>直到$T$的所有迭代的累积反事实遗憾是，$$R_i^T(i，a)=\sum_{t=1}^T r_i^t(i，a)$$。</p><p>def UPDATE_REGREADS(i：infoSet，v：Float，va：dict[Action，Float]，i：Player)：对于操作中的(I)：遗憾(I)[a]=遗憾(I)[a]+(va[a]-v)。</p><p>策略计算采用HART和Mas-Collell的遗憾匹配。$$\BEGIN{ALIGN}R_i^{T，+}(i，a)&amp；=\max(R_i^T(i，a)，0)\\sigma_i^{T+1}(i，a)&amp；=\Begin{Cases}\frac{R_i^{T，+}(i，a)}{\sum_{a&#39；\in A(I)}R_i^{T，+}(i，a；)}，&amp；\text{if$\sum_{a；\in A(I)}R_i^{T，+}(i，a；)&gt；0$}\frac{1}{|A(I)|}&amp；\text{否则}\end{case}\end{ign}$</p><p>定义CALCULATE_NEW_STARTICAL(i：InfoSet)：r_plus={a：max(r，0)，表示遗憾(I)中的a，r。Items()}r_plus_sum=sum(r表示r_plus中的r。值())n_action=len(action(I))，用于操作(I)中的a：if r_plus_sum&gt；0：Strategy(I)[a]=r_plus[a]/r_plus_sum Else：Strategy(I)[a]=1/n_action。</p><p>玩家$I$从迭代到$T$的平均策略是，$$\bar{\sigma}_i^T(i，a)=\frac{\sum_{t=1}^T\pi_i^{\sigma^t}(I)\sigma_i^T(i，a)}{\sum_{t=1}^T\pi_i^{\sigma^t}(I)}$$。</p><p>$\pi_i^\sigma$是达到$ℎ$的概率，如果除$𝑖$之外的所有玩家都采取了导致$ℎ$的操作，概率为$1$。</p><p>定义UPDATE_CURSORATION_STARTICAL(i：InfoSet，pi_i：Float)：用于输入操作(I)：i.。Cumulative_Strategy[a]+=pi_i*Strategy(I)[a]def Calculate_Average_Strategy(i：InfoSet)：Strategy_sum=sum(i..。Cumulative_Strategy[a]for a In Actions(I))n_Actions=len(Actions(I))for a In Actions(I)：if Strategy_sum&gt；0：i。平均策略[a]=i。Cumulative_Strategy[a]/Strategy_sum否则：i.。Average_Strategy[a]=1/n_Actions。</p><p>这是主要的递归反事实遗憾最小化函数，它递归地探索博弈树并计算新的策略。cfr返回$u_i(\sigma，h)$。</p><p>def cfr(h：History，i：player，pi：dict[Player，Float])-&gt；Float：IF IS_TERMINAL(H)：RETURN TERMINAL_UTILITY(h，i)elIF IS_Chance(H)：A=sample_Chance(H)return CFR(h+a，i，pi)i=info_set(H)pi_neg_i=1 for j，pi_j in pi。Items()：if j！=player(H)：pi_neg_i*=pi_j ua={}u=0，对于a in action(I)：pi_next=pi。copy()pi_next[player(H)]=Strategy(I)[a]ua[a]=cfr(h+a，i，pi_next)u+=Strategy(I)[a]*ua[a]va={a：Pi_neg_i*uA[a]用于动作(I)}v=pi_neg_i*u如果player(H)==i：update_refresses(i，v，va，i)update_cumulative_Strategy(i，pi[i])返回u。</p><p>我们为插图迭代了大约$5,000$迭代。平均策略在大约25,000美元的迭代后完全稳定下来。</p><p>def solve()：跟踪器。为t设置_scalar(&#39；&#39；)，单位为monit。LOOP(5_000)：对于播放器中的i：对于INFO_SETS中的i，cfr(&#39；&#39；，i，{p：1 for p in player})。VALUES()：Calculate_new_Strategy(I)Calculate_Average_Strategy(I)if t==9：for a in Actions：Tracker。set_scalar(f&#39；策略。{I.key}。{a}&#39；，is_print=false)跟踪器。设置标量(f&#39；Average_Strategy。{I.key}。{a}&#39；，is_print=false)跟踪器。设置标量(f&#39；抱歉。{I.key}。{a}&#39；，is_print=false)if(t+1)%10==0：用于In Actions(I)：Tracker。保存({f&#39；策略。{I.key}。{a}&#39；：Strategy(I)[a]，f&##；Average_Strategy。{I.key}。{a}&#39；：i.。平均策略[a]，后悔。{I.key}。{a}&#39；：抱歉(I)[a]})记录器。日志(&#39；平均策略&#39；，文本。标题)记录器。检查({k：i.。INFO_SETS中k，i的Average_Strategy。项目()})</p><p>kuhn_poker：90a456ee9b1c11eaaf7bf218981c2492[脏]：&#34；拼写错误&34；平均策略K：{&#39；p&#39；：0.9982164090368609，&#39；b&#39；：0.0017835909631391202}qb：{&#39；p&#39；：0.9997039668442865，&#39；b&#39；b&#39：0.0002960331557134399}A：{&#39；p&#39；：0.0006207324643078833，&#39；b。第#39；页：0.6255611876080304，第#39；页：0.3744388123919696}Ab：{&#39；第#39；页：0.00031486146095717883，&#39；第#39；页：0.9996851385390428}q：{&#39；第#39；页；：0.6573929386464191，#39；第#39；页：0.3426070613535808}共6件。</p><p>我们可以看到占主导地位的策略(当第一个玩家得到A，当第二个玩家得到A时)很早就确定了。</p><p>然而，第一个玩家用Q下注，第二个玩家用K下注的策略需要时间才能收敛。</p><p>平均策略在收敛时在纳什均衡附近振荡，目前的策略$\sigma_i^T(i，a)$是循环的，而平均策略$\sigma}_i^T(i，a)$在收敛时在纳什均衡附近振荡，而目前的策略$\sigma_i^T(i，a)$是循环的。</p><p>我们可以在散布图上更清楚地看到他们。在这里，$sigma_i^T(i，a)$似乎在移动。</p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="http://blog.varunajayasiri.com/ml/kuhn_poker.html">http://blog.varunajayasiri.com/ml/kuhn_poker.html</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/poker/">#poker</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/regret/">#regret</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/玩家/">#玩家</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/谷歌/">#谷歌</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy;2012-2021 diglog.com </div></div></body></html>