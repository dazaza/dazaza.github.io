<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>关于YOLOv5争议的回应</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">关于YOLOv5争议的回应</h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2020-06-15 00:03:08</div><div class="page_narrow text-break page_content"><p>我们感谢机器学习社区的反馈，我们重新发布关于我们的方法的更多细节。</p><p>6月10日，Roboflow团队发表了一篇名为“YOLOv5在这里，分享YOLOv5与YOLOv4的基准和比较”的博文。我们的使命是让任何开发人员都能解决他们在计算机视觉方面的问题，所以当Glenn Jocher(Ultralytics)在6月9日发布YOLOv5存储库时，我们迅速行动起来，更广泛地分享了它的创造。</p><p>这篇帖子在Hacker News、Reddit甚至GitHub上引起了热烈的讨论-但坦率地说，不是因为我们预期的原因(比如它的小体积和快速的推理速度)。</p><p>这篇帖子分享了我们对这两个问题的看法，并澄清了与我们最初的帖子在推理速度方面的不公平比较。</p><p>我们博客上的许多评论者认为Glenn Jocher不应该给实现命名，因为(1)他不是YOLO的原始作者，(2)他没有发表论文，和/或(3)实现不够新颖。</p><p>下面，我们向机器学习社区提供上下文和请求，以获得更好的命名约定。</p><p>YOLO&34；指的是约瑟夫·雷德蒙(Joseph Redmon)在2016年5月的论文“你只看一次：统一的实时物体检测”(You Only Look Only：Unified，Real-Time Object Detection)中介绍的一系列模型，你只看一次。</p><p>雷德蒙随后在2017年12月的一篇题为“YOLO9000：更好、更快、更强”的论文中介绍了YOLOv2。他和他的导师还在2018年4月发表了“YOLOv3：增量改进”一书。</p><p>从那时起，谁(如果有人)应该继续使用这个名称来指代新的模型体系结构就变得不清楚了。有些人认为YOLOv3是最后一个YOLO。</p><p>值得注意的是，Glenn Jocher(与Joseph Redmon无关)在PyTorch中创建了一个流行的YOLOv3实现。</p><p>然后，在2020年4月23日，阿列克谢·博奇科夫斯基(Alexey Bochkovski)出版了YOLOv4。值得一提的是，约瑟夫·雷德蒙在推特上赞扬了博奇科夫斯基为“暗网”所做的大量工作，并表示这并不重要我对其实施和品牌的看法。</p><p>我怎么想并不重要！在这一点上，@alexeyab84有了经典的暗网和yolo版本，他在里面投入了大量的工作，每个人都在使用它，而不是我的哈哈。https://t.co/FcnQPiySr7。</p><p>-乔·雷德蒙(@pjreddie)2020年4月25日。</p><p>2020年5月29日，格伦·约彻(Glenn Jocher)创建了一个名为YOLOv5的存储库，其中不包含任何模型代码。2020年6月9日，他在YOLOv3实现中添加了一条名为“YOLOv5问候”的提交消息。</p><p>Jocher的YOLOv5实现在几个值得注意的方面与以前的版本不同。首先，乔彻(还没有)在获释的同时发表论文。其次，Jocher在PyTorch中原生实现了YOLOv5，而YOLO家族以前的所有型号都利用了Darknet。</p><p>值得注意的是，Jocher还创建了马赛克数据增强，并将其包含在他的YOLOv3存储库中，这是YOLOv4中利用的许多新颖数据增强之一。他在YOLOv4的论文中得到了承认。</p><p>约彻的YOLOv5存储库远不是他第一次参与YOLO项目：他已经为他的YOLOv3实现做出了2379次承诺，Bochkovski引用了这一点。</p><p>坦率地说，Roboflow团队并不知道。我们也不应该成为命名名称的仲裁者！</p><p>我们不隶属于Ultralytics或其他研究人员。我们是一家初创公司，使开发人员无需成为机器学习专家即可使用计算机视觉，并且我们支持广泛的开源模型体系结构，供团队尝试他们的数据：https://models.roboflow.ai。</p><p>除此之外，我们只是粉丝。我们对这一领域的发展速度感到惊讶，我们做了一些基准，我们认为其他人可能会发现这些基准和我们一样令人兴奋。我不想在命名争议中偏袒任何一方。我们的核心重点是帮助开发人员将数据放入任何模型中，无论其名称如何！</p><p>然而，我们认识到，作为一个扩大模型体系结构识别的组织，我们应该使用与机器学习社区使用的名称一致的名称。</p><p>因此，我们将继续倾听并深思熟虑地参与。我们要求机器学习社区也这样做。让我们感谢在PyTorch中本机实现YOLO所做的艰苦工作，不管它的名字是什么。让我们找一个感觉合适的名字--无论是YOLOv5、FastYOLO、YOLOv4-Accelerated，还是其他名字。可以肯定地说：我们期待着下一个YOLO。当(如果)名称更改时，我们将更新对它的引用。</p><p>每当发布新的模型体系结构时，评估其性能以确定模型的质量是很重要的。在研究界，模型以相同的图像为基准，就像上下文中的通用对象(Common Object in Context，COCO)数据集。在生产环境中，团队将针对他们自己的领域问题测试模型，他们可能会考虑不同的首要因素。(例如，即使模型更精确，如果它不能执行实时性能，它也可能不适合系统。)。</p><p>正如所提到的，在Roboflow，我们的目标是使团队能够快速、轻松地在他们自己的特定于其领域的自定义数据集上利用计算机视觉模型。</p><p>同样，我们比较模型的目的是给出一个在用户自己的自定义数据集上使用这两个模型的示例演示。他们应该期望每个实施培训多长时间？它们有多准确？推论有多快？在生产环境中建立给定模型的挑战有多大？理想情况下，这种比较应该很容易适应用户自己的数据集，这样他们也可以做出自己的判断。</p><p>这不能替代对COCO的正式基准测试。Bochkovski在他对GitHub上的YOLOv4和YOLOv5的分析中非常清楚地说明了这一点，并发现我们Roboflow在比较帧率和默认模型大小的方式上存在不一致之处，下面我们已经更彻底地解决了这一问题。</p><p>我们对像阿列克谢·博奇科夫斯基这样的研究人员所做的工作深表敬意，我们感谢他们继续推动这一领域向前发展。事实上，我们构建Roboflow的原因与他发表YOLOv4论文的原因非常相似：</p><p>这项工作的主要目标是设计快速的目标探测器在生产系统中的运行速度和并行计算的优化，而不是低计算量的理论指标(BFLOP)。我们希望设计的对象可以很容易地训练和使用。例如，任何使用传统GPU进行训练和测试的人都可以获得实时、高质量和令人信服的目标检测结果。</p><p>我们实现了使用Darknet存储库和Ultralytics的YOLOv5存储库时编译的默认模型。正如Bochkovski所指出的，这将编译YOLOv4(大YOLOv4&34；和小YOLOv5&34；YOLOv4&34；)。</p><p>在帖子发表后，我们看到了一些(有效的)批评，我们征求了社区中那些人的建议，以最好的方式来支持和澄清我们发布的结果。</p><p>在深入研究之前，重要的是要承认这两个框架都完成了使计算机能够识别对象的令人印象深刻的壮举，这里提出的许多考虑因素都处于边缘位置。</p><p>这两个模型似乎都在我们的样本数据集上发挥了最大的性能，因此报告了类似的准确性能。YOLOv5在样例任务上训练得更快，并且批处理推理(实现默认使用)会产生实时结果。虽然YOLOv4的训练速度较慢，但当两个批处理推理大小都设置为1时，速度会更快。因为YOLOv5是在PyTorch中实现的，而YOLOv4是在Darknet中实现的，所以YOLOv5可能更容易投入生产，而YOLOv4可能是继续进行高精度研究的地方。</p><p>如果您是一名希望将接近实时的对象检测快速整合到您的项目中的开发人员，YOLOv5是一个很好的选择。如果您是一名追求最先进技术的计算机视觉工程师，并且不怕更多的自定义配置，那么Darknet中的YOLOv4仍然是最准确的。</p><p>重要的是，我们已经使您可以轻松地在您自己的数据集上尝试此实验：</p><p>编写本编写的其余部分是为了指导您在自己的数据集上完成此比较。</p><p>所有的比较都是在Google Colab中进行的，在Pro层，它配备了一致的硬件：NVIDIA Tesla P100。这也使您能够轻松地复制我们的结果。(它的代价是无法通过特定的CUDA工具包版本控制实现较低级别的优化。)。</p><p>如果您想使用我们在测试中使用的完全相同的笔记本来测试这些结果，您可以在以下位置找到它们：</p><p>在我们的评估中，我们使用了血细胞计数和检测数据集。该数据集由三类(红细胞、白细胞和血小板)的364幅图像组成。</p><p>如前所述，我们的数据集旨在表示在野外可能遇到的示例自定义任务，而不是官方的COCO基准。上面链接的笔记本使您可以在自己的任务中重复此实验。</p><p>在开始培训之前，我们首先安装YOLOv4 Darknet和YOLOv5环境。即使是严格的COCO比较，通常也会忽略设置环境(除了提供Requirements.txt和偶尔的AMI之外)，如果主要目标是可访问性，我们发现这是一个重要的比较点。</p><p>NVCC：NVIDIA(R)CUDA编译器驱动程序版权所有(C)2005-2019 NVIDIA Corporation基于Sun_JUL_28_19：07：16_PDT_2019CUDA编译工具，版本10.1，V10.1.243。</p><p>然后我们需要安装cuDNN来支持Darknet使用的深度学习功能。为此，我们导航到NVIDIA的网站并提取正确的cuDNN文件，以使用我们的CUDA驱动程序进行配置。在本例中，即为cuDNN 10.1。我们读入并安装。遗憾的是，NVIDIA不允许发布cuDNN链接，因此如果您要跟随，您需要转到NVIDIA的网站进行下载。</p><p>/usr/localcuda/include/cudnn.hcuda/NVIDIA_SLA_cuDNN_Support.txtcuda/lib64/libcudnn.socuda/lib64/libcudnn.so.7cuda/lib64/libcudnn.so.7.6.5cuda/lib64/libcudnn_static.a#define CUDNN_MAJOR 7#DEFINE CUDNN_MINOR 6#DEFINE CUDNN_PATCHLEVEL 5--#DEFINE CUDNN_VERSION(CUDNN_MAJOR*1000+CUDNN_MINOR*100+CUDNN_PATCHLEVEL)#INCLUDE&#34；Driver_tyes.h&#34；</p><p>配置生成文件。在访问Google Colab之前，我们将Makefile配置为具有以下配置：</p><p>我们首先克隆存储库！pip install-U-r yolov5/requirements.txt，然后检查手电筒设置：</p><p>YOLOv4使用了YOLO Darknet框架中的传统数据标注。Train.txt和valid.txt指定带有.txt注释的.jpg文件的位置。最后，在训练中调用.Data文件来指定所有这些内容的位置，以及类标签和保存训练权重的位置：</p><p>以OPEN(&#39；data/obj.data&#39；，&#39；w&#39；)作为out：out.write(&#39；class=3\n&#39；)out.write(&#39；Train=data/Train.txt\n&39；)out.write(&#39；Valid=data/valid.txt\n&#39；)out.write(&#39；name=data/obj.ames\n&39；)。</p><p>YOLOv5使用类似的格式，但有一些警告。训练和有效文件夹将放置在yolov5存储库旁边。在每个中，都应该是一个图像目录，其中包含一个附带的标签目录。data.yml文件将这些目录链接在一起：</p><p>Roboflow支持下载这两种格式，您可以拖放上传任何格式的数据集(COCO、PASCAL VOC、TensorFlow CSV等)。并将它们正确格式化成YOLOv4或YOLOv5。</p><p>YOLOv4和YOLOv5都分别指定了培训配置文件.cfg和.yaml。在重写网络体系结构时，这两个培训文件都要求我们为您的自定义数据集指定num_class。</p><p>在Darknet配置中，我们指定了有关培训作业的更多信息，包括Batch_Size、Subditions、max_Batches和Steps。在“暗网”中，你可以使用这些参数，通过最大限度地耗尽GPU上的内存来加快你的训练时间。</p><p>掩码=6，7，8锚点=12，16，19，36，40，28，36，75，76，55，72,146,142,110,192,243,459,401class=3num=9jitter=0.3忽略阈值=.7true_Thresh=1Random=1scale_x_y=1.05iou_thresh=0.213cls_normalizer=1.0iou_normalizer=0.07iou_loss=ciounms_kind=greedynmsbeta_nms=0.6max_delta=5。</p><p>#yolov5 Head：[[-1，3，Bottle eckCSP，[1024，false]]，#11[-1，1，nn.Conv2d，[na*(NC+5)，1，1，0]]，#12(P5/32-Large)[-2，1，nn.Upsample，[NONE，2，&#39；NEAREST&#39；NEAREST&#39；]，[[-1，6]，1，Conat，[1]]，#CAT Backbone P4[-1，1，Conv，[512，1，1]]，[-1，3，BotchieckCSP，[512，False]]，[-1，1，n.Conv2d，[NA*(NC+5)，1，1，0]]，#17(P4/16-Medium)[-2，1，n.Upsample，[。]，[[-1，4]，1，Conat，[1]]，#CAT Backbone P3[-1，1，Conv，[256，1，1]]，[-1，3，BotchieckCSP，[256，False]]，[-1，1，nn.Conv2d，[NA*(NC+5)，1，1，0]]，#22(P3/8-Small)[]，1，检测，[NC，锚]]。</p><p>这两个配置文件都允许在体系结构级别灵活地转移模型实验。YOLOv4 Darknet提供了更多的灵活性，因此可能是一个更好的研究地点。</p><p>在YOLOv4 Darknet中，您可以根据迭代次数max_batches(而不是纪元)设置训练长度。对于自定义对象，存储库中的建议是2000 x num_class。有了这个设置，YOLOv4 Darknet在我们的示例数据集上花费了惊人的14小时。然而，它在此之前很久就达到了最大验证评估；我们看到1300次迭代的最大验证评估，这花费了大约3.5小时才能达到。</p><p>对于这两个网络，我们查看最大验证图@0.5。我们发现，对于我们的任务，它们在这个指标(0.91MAP)中的表现相似。</p><p>这并不反映COCO数据集的网络性能。实际情况是，基于此特定自定义数据集，这两个网络可能都接近此特定自定义任务的最高性能。</p><p>在本地运行Darknet时，你可以生成一个很好的训练图，但在Colab上就不那么容易实现了。您可以输出日志，然后对其进行解析，但我们在这里没有说到这里。</p><p>计算图(平均精度).76检测_计数=4265，唯一真值计数=967类_id=0，名称=血小板，AP=88.87%(TP=73，FP=30)class_id=1，名称=RBC，AP=85.28%(TP=763，FP=635)class_id=2，名称=WBC，AP=98.03%(TP=72，FP=2)对于conf_Thresh=0.25，精度=0.58，F1-SCORE=0.71CONF_THRESHOLD=0.25，TP=908，FP=667，FN=59，平均IOU=47.79%IOU阈值=50，每次唯一召回使用的曲线下面积平均精度(MAP@0.5)=0.907268，或90.73%总检测时间：3秒Set-Points标志：`-Points 101‘对于MS COCO`-Points 11`对于PascalVOC2007(取消注释。您的自定义数据集Mean_Average_Precision(MAP@0.5)=0.907268。</p><p>博奇科夫斯基暗示，我们可能会期待这两款车型在Micrsofot Coco上的表现也是如此：</p><p>他们比较了Microsoft Coco上精度极低的小型超分析器-YOLOv5版本YOLOv5s(27MB)和Microsoft Coco上精度极高的大型YOLOv4(245MB)模型YOLOv5s(27MB)和非常高精度41%-43%AP的模型大小。</p><p>因此，在数据集更大或任务更具挑战性的情况下，YOLOv4的表现可能会更好。同样，在您自己的自定义数据集上测试这些结果也是值得的。</p><p>当我们查看重量文件时，这里的文件大小是我们观察到的。.weight是来自Darknet资料库的自定义YOLOv4检测器，.pt是来自Ultralytics资料库的自定义YOLOv5s检测器。YOLOv4具有250MB的重量文件，而YOLOv5S具有27MB的重量文件。</p><p>值得一提的是：Bochkovski强调他的Darknet存储库的默认YOLOv4架构构建了大YOLOv4(245MB)，而YOLOv5实现构建了一个小YOLOv5(YOLOv5s)。最大的YOLOv5是YOLOv5l，它的重量是192MB。</p><p>最后，我们将两种网络下的推理时间与指定的环境配置(Tesla P100)进行了比较。这就是AlexeyAB正确地指出我们最初的帖子进行了不公平的比较，没有将苹果与苹果进行比较的地方。我们对此深表歉意；我们的意图不是为了误导，直到AlexeyAB指出这一点后，我们才意识到默认的推理设置是不同的。</p><p>在单个图像(批次大小为1)上，YOLOv4推论需要33毫秒(30 FPS)，YOLOv5S推论需要20毫秒(10 FPS)。</p><p>当您批量推理时，YOLOv5s推理速度为7毫秒(140 FPS)。输出将总推理时间除以正在处理的图像数量。Ultralytics YOLOv5实现默认使用此设置，因此如果您从存储库中实现，则默认情况下您将拥有140 FPS的批处理推理。</p><p>我们想不出如何让YOLOv4在我们的笔记本上进行批量推理。如果你知道怎么做，请让我们知道，我们会更新这篇帖子。</p><p>图1/36../test/images/BloodImage_00038_jpg.rf.63da20f3f5538d0d2be8c4633c7034a1.jpg：416x416 1个平台、22个RBC、1个WBC，完成。(0.007s)图像2/36../test/images/BloodImage_00044_jpg.rf.b0e2369642c5a7fa434ed8defa79e2ba.jpg：416x416 2平板，13个红细胞，2个白细胞，完成。(0.007s)图像3/36../test/images/BloodImage_00062_jpg.rf.e965ee152eea462d82706a2709abfe00.jpg：416x416 1平板，14个红细胞，1个白细胞，完成。(0.007s)图像4/36../test/images/BloodImage_00090_jpg.rf.4fd1da847d2857b6092003c41255ea4c.jpg：416x416 3平板，12个红细胞，1个白细胞，完成。(0.007s)图像5/36../test/images/BloodImage_00099_jpg.rf.5b178d758af2a97d3df8e5f87b1f344a.jpg：416x416 1平板，16个红细胞，1个白细胞，完成。(0.007s)图像6/36../test/images/BloodImage_00112_jpg.rf.f8d86689750221da637a054843c72822.jpg：416x416 1平板，15个红细胞，1个白细胞，完成。(0.007s)图像7/36../test/images/BloodImage_00113_jpg.rf.a6d6a75c0ebfc703ecff95e2938be34d.jpg：416x416 1平板，15个红细胞，1个白细胞，完成。(0.007s)图像8/36../test/images/BloodImage_00120_jpg.rf.6742a4da047e1226a181d2de2978ce6d.jpg：416x416 9 RBC，1 WBC，完成。(0.007s)图像9/36../test/images/BloodImage_00133_jpg.rf.06c3705fcfe2fcaee19e1a076e511508.jpg：416x416 8 RBC，1 WBC，完成。(0.007s)。</p><p>Roboflow致力于使每个开发人员都能使用计算机视觉来解决他们的问题，而不管他们的领域是什么。我们已经看到数以千计的人建造了像新冠肺炎胸部扫描翻译器、寿司探测器、飞机部件维修识别器等工具。</p><p>我们将继续监控哪个型号名称最适合Glenn Jocher的YOLOv5实施，我们希望我们详细的YOLOv4 vs YOLOv5方法能够验证我们是如何实现我们的结果的。我们还希望它在创建比较时将易用性作为一个考虑因素来突出显示。</p><p>由衷地，我们对一路上的反馈深表感谢。正如一位机器学习研究人员写给我们的：</p><p>最后，我们邀请您尝试YOLOv4和YOLOv5(或者我们的社区决定怎么称呼它！)。并得出您自己的结论：</p><p>想成为第一个了解新的计算机视觉教程和内容(如我们的合成数据集创建指南)的人吗？订阅我们的更新📬。</p><p>RoboFlow通过自动批注质量保证、通用批注格式转换(如Pascal VOC XML到COCO JSON和创建TFRecords)、团队共享和版本控制，以及与流行的开源计算机视觉模型的轻松集成，加速了您的计算机视觉工作流程。获得圣彼得堡。</p><p>..</p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://blog.roboflow.ai/yolov4-versus-yolov5/">https://blog.roboflow.ai/yolov4-versus-yolov5/</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/争议/">#争议</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/yolov5/">#yolov5</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/谷歌/">#谷歌</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy;2012-2021 diglog.com </div></div></body></html>