<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>æ•°å­—åŒ–æ—§çš„8mmèƒ¶å¸¦Digitizing Old 8mm Tapes</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">Digitizing Old 8mm Tapes<br/>æ•°å­—åŒ–æ—§çš„8mmèƒ¶å¸¦</h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2020-11-25 05:59:35</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2020/11/7716878903f8890b32b7b39426e85ebd.png"><img src="http://img2.diglog.com/img/2020/11/7716878903f8890b32b7b39426e85ebd.png" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>Itâ€™s astounding to think back and consider how much technological progress has occurred in just the past 15 years. Most folks today carry a smartphone in their pocket everywhere they go, and a great many of those smartphones have powerful cameras built in capable of recording multiple hours in high definition. Pair this ability with low-cost video editing softwareâ€” some of which comes at no cost at allâ€”and far more people today have the tools to practice shooting, editing, compositing, and rendering professional-looking videos on a modest budget.</p><p>å›é¡¾è¿‡å»ï¼Œæ€è€ƒè¿‡å»15å¹´ä¸­å‘ç”Ÿäº†å¤šå°‘æŠ€æœ¯è¿›æ­¥ï¼ŒçœŸæ˜¯ä»¤äººæƒŠè®¶ã€‚å¦‚ä»Šï¼Œå¤§å¤šæ•°äººéšå¤„æºå¸¦å£è¢‹ä¸­çš„æ™ºèƒ½æ‰‹æœºï¼Œå…¶ä¸­è®¸å¤šæ™ºèƒ½æ‰‹æœºéƒ½å†…ç½®äº†åŠŸèƒ½å¼ºå¤§çš„ç›¸æœºï¼Œèƒ½å¤Ÿä»¥é«˜æ¸…æ™°åº¦è®°å½•å¤šä¸ªå°æ—¶ã€‚å°†æ­¤åŠŸèƒ½ä¸ä½æˆæœ¬è§†é¢‘ç¼–è¾‘è½¯ä»¶ï¼ˆå…¶ä¸­æœ‰ä¸€äº›å®Œå…¨å…è´¹ï¼‰ç»“åˆä½¿ç”¨ï¼Œå¦‚ä»Šï¼Œè¶Šæ¥è¶Šå¤šçš„äººæŒæ¡äº†ä»¥é€‚åº¦çš„é¢„ç®—ç»ƒä¹ æ‹æ‘„ï¼Œç¼–è¾‘ï¼Œåˆæˆå’Œæ¸²æŸ“å…·æœ‰ä¸“ä¸šå¤–è§‚çš„è§†é¢‘çš„å·¥å…·ã€‚</p><p> My personal experience with photography began around age 7 shooting on  110 film using a small â€œspyâ€ camera I got as a gift. My dadâ€™s  Sony CCD-V5 was bulky, heavy, and probably expensive when he bought it around 1987, so he was reluctant to let me or my sister operate it under his supervision, let alone borrow it to make our own films by ourselves. As a consequence, my sister and I kept ourselves entertained by making audio recordings on much cheaper audio cassette hardware and tapesâ€”we produced an episodic â€œradio showâ€ starring our stuffed animals long before the podcast was invented. Though my sister and I took good care of our audio equipment, Dad stuck to his guns when it came to who got to use the camcorder, but he would sometimes indulge us when we had a full production planned, scripted, and rehearsed.  Video8 tapes were expensive, too, and for the most part Dad reserved their use for important events like concerts, school graduations, birthdays, and family holidays.</p><p> æˆ‘ä¸ªäººçš„æ‘„å½±ç»éªŒå§‹äº7å²å·¦å³ï¼Œå½“æ—¶æˆ‘ä½¿ç”¨ç¤¼ç‰©ä½œä¸ºç¤¼ç‰©çš„å°å‹â€œé—´è°â€ç›¸æœºæ‹æ‘„110å¼ èƒ¶å·ã€‚æˆ‘çˆ¶äº²çš„ç´¢å°¼CCD-V5ä½“ç§¯å¤§ï¼Œç¬¨é‡ï¼Œå¹¶ä¸”åœ¨1987å¹´å·¦å³è´­ä¹°æ—¶å¾ˆæ˜‚è´µï¼Œå› æ­¤ä»–ä¸æ„¿æ„è®©æˆ‘æˆ–å§å§åœ¨ä»–çš„ç›‘ç£ä¸‹æ“ä½œå®ƒï¼Œæ›´ä¸ç”¨è¯´å€Ÿç”¨å®ƒè‡ªå·±åˆ¶ä½œè‡ªå·±çš„ç”µå½±äº†ã€‚ç»“æœï¼Œæˆ‘å’Œæˆ‘å§å§åœ¨ä¾¿å®œå¾—å¤šçš„å½•éŸ³å¸¦ç¡¬ä»¶å’Œç£å¸¦ä¸Šå½•éŸ³ï¼Œä½¿è‡ªå·±ä¿æŒäº†å¨±ä¹â€”åœ¨æ’­å®¢å‘æ˜å‡ºæ¥ä¹‹å‰ï¼Œæˆ‘ä»¬å°±åˆ¶ä½œäº†ç”±åŠ¨ç‰©å¡«å……ç‰©ä¸»æ¼”çš„å¶å‘æ€§â€œå¹¿æ’­èŠ‚ç›®â€ã€‚å°½ç®¡æˆ‘å’Œå§å§éƒ½å¾ˆå¥½åœ°ç…§é¡¾äº†æˆ‘ä»¬çš„éŸ³é¢‘è®¾å¤‡ï¼Œä½†æ˜¯å½“æ¶‰åŠåˆ°è°è¦ä½¿ç”¨ä¾¿æºå¼æ‘„å½•æœºæ—¶ï¼Œçˆ¸çˆ¸è¿˜æ˜¯åšæŒäº†ä¸‹æ¥ï¼Œä½†æ˜¯å½“æˆ‘ä»¬è®¡åˆ’å¥½å®Œæ•´çš„åˆ¶ä½œï¼Œæ’ç»ƒå’Œæ’ç»ƒæ—¶ï¼Œä»–æœ‰æ—¶ä¼šæ²‰è¿·äºæˆ‘ä»¬ã€‚ Video8ç£å¸¦ä¹Ÿå¾ˆæ˜‚è´µï¼Œåœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œçˆ¸çˆ¸å°†å…¶ä¿ç•™ç”¨äºé‡è¦æ´»åŠ¨ï¼Œä¾‹å¦‚éŸ³ä¹ä¼šï¼Œå­¦æ ¡æ¯•ä¸šï¼Œç”Ÿæ—¥å’Œå®¶åº­å‡æœŸã€‚</p><p>  I went off to college and spent a  lot of time lurking the  originaltrilogy.com forums. It was here that not only did I learn a lot about the making and technical background of the Star Wars films (a topic I could blog about ad nauseum), but I also picked up a lot about video editing, codecs, post-production techniques, and preservation. OT.com was and still is home to a community of video hobbyists and professionals, most of whom share a common love for the  unreleased â€œoriginal unalteredâ€ versions of the Star Wars trilogy. As such, many tips were/are shared as to how to produce the best â€œfan preservationsâ€ of Star Wars and other classic films given the materials available, sacrificing the least amount of quality.</p><p>  æˆ‘å»ä¸Šå¤§å­¦ï¼ŒèŠ±äº†å¾ˆå¤šæ—¶é—´æ½œå…¥originaltrilogy.comè®ºå›ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä¸ä»…å­¦åˆ°äº†å¾ˆå¤šæœ‰å…³ã€Šæ˜Ÿçƒå¤§æˆ˜ã€‹ç”µå½±çš„åˆ¶ä½œå’ŒæŠ€æœ¯èƒŒæ™¯çš„çŸ¥è¯†ï¼ˆæˆ‘å¯ä»¥åœ¨åšå®¢ä¸Šå‘è¡¨æœ‰å…³å¹¿å‘Šæ¶ä½œå‰§çš„è¯é¢˜ï¼‰ï¼Œè€Œä¸”è¿˜å­¦åˆ°äº†å¾ˆå¤šæœ‰å…³è§†é¢‘ç¼–è¾‘ï¼Œç¼–è§£ç å™¨å’ŒåæœŸåˆ¶ä½œæŠ€æœ¯çš„çŸ¥è¯†ã€‚ ï¼Œå¹¶ä¿å­˜ã€‚ OT.comæ›¾ç»æ˜¯ï¼Œç°åœ¨ä»ç„¶æ˜¯ä¸€ä¸ªè§†é¢‘çˆ±å¥½è€…å’Œä¸“ä¸šäººå£«ç¤¾åŒºçš„ä½æ‰€ï¼Œå…¶ä¸­å¤§å¤šæ•°äººå¯¹æœªå‘è¡Œçš„â€œæ˜Ÿçƒå¤§æˆ˜â€ä¸‰éƒ¨æ›²â€œåŸå§‹ä¸”æœªæ›´æ”¹â€ç‰ˆæœ¬æœ‰ç€å…±åŒçš„çˆ±å¥½ã€‚å› æ­¤ï¼Œåœ¨å¯ç”¨çš„ææ–™ä¸‹ï¼Œå¦‚ä½•åˆ¶ä½œå‡ºã€Šæ˜Ÿçƒå¤§æˆ˜ã€‹å’Œå…¶ä»–ç»å…¸ç”µå½±çš„æœ€ä½³â€œç²‰ä¸ä¿æŠ¤å“â€ï¼Œåˆ†äº«äº†è®¸å¤šæŠ€å·§ï¼Œå´ç‰ºç‰²äº†æœ€å°‘çš„è´¨é‡ã€‚</p><p> I bought my dad a  Sony HDR-CX100 camcorder some years ago to supplement his by that time affinity for digital still camerasâ€”he took it to Vienna and Salzburg soon after and has since transitioned to shooting digital video mostly on his iPhone. But the 8mm tapes chronicling my familyâ€™s milestones over the first 25 years of my life continued to sit, undisturbed, in my folksâ€™ cool, dry basement. My dad has recordings on them going as far back as 1988 that Iâ€™ve found so far. These recordings are over 30 years old, so the tapes must be at least that age.</p><p> å‡ å¹´å‰ï¼Œæˆ‘ä¸ºçˆ¸çˆ¸ä¹°äº†ä¸€å°Sony HDR-CX100æ‘„å½•æœºï¼Œä»¥è¡¥å……ä»–å¯¹æ•°ç ç›¸æœºçš„å…´è¶£ã€‚ä»–ä¸ä¹…åå°†å®ƒå¸¦åˆ°äº†ç»´ä¹Ÿçº³å’Œè¨å°”èŒ¨å ¡ï¼Œæ­¤åè½¬ä¸ºä¸»è¦åœ¨ä»–çš„iPhoneä¸Šæ‹æ‘„æ•°ç è§†é¢‘ã€‚ä½†æ˜¯ï¼Œè®°å½•æˆ‘äººç”Ÿå¤´25å¹´çš„é‡Œç¨‹ç¢‘çš„8æ¯«ç±³å½•åƒå¸¦ç»§ç»­å®‰ç¨³åœ°ååœ¨äººä»¬å‡‰çˆ½å¹²ç‡¥çš„åœ°ä¸‹å®¤ä¸­ã€‚æˆ‘çˆ¶äº²æœ‰å…³äºä»–ä»¬çš„å½•éŸ³ï¼Œå¯ä»¥è¿½æº¯åˆ°æˆ‘å‘ç°çš„1988å¹´ã€‚è¿™äº›å½•éŸ³å·²æœ‰30å¤šå¹´çš„å†å²ï¼Œå› æ­¤ç£å¸¦å¿…é¡»è‡³å°‘æ˜¯è¯¥å¹´é¾„ã€‚</p><p> 8mm video tape  does not last forever, but making analog copies of video tape incurs generational loss each time a copy is dubbed. On the other hand, a digital file can be copied as many times as one wants without any quality loss. All I need is the right capture hardware, appropriate capture software, enough digital storage, and a way to play back the source tapes, and I can preserve one lossless digital capture of each tape indefinitely. The last 8mm camcorder my dad boughtâ€”a  Sony CCD-TR917â€”still has clean, working heads and can route playback of our existing library of tapes through its S-video and stereo RCA outputs. This provides me with the best possible quality given how they were originally shot.</p><p> 8mmçš„å½•åƒå¸¦ä¸ä¼šæ°¸è¿œæŒç»­ä¸‹å»ï¼Œä½†æ˜¯æ¯æ¬¡å¤åˆ¶ä¸€ä¸ªå½•åƒå¸¦æ—¶ï¼Œåˆ¶ä½œå½•åƒå¸¦çš„æ¨¡æ‹Ÿå‰¯æœ¬éƒ½ä¼šé€ æˆä¸–ä»£çš„æŸå¤±ã€‚å¦ä¸€æ–¹é¢ï¼Œæ•°å­—æ–‡ä»¶å¯ä»¥è¢«å¤åˆ¶å¤šæ¬¡ï¼Œè€Œä¸ä¼šé€ æˆè´¨é‡æŸå¤±ã€‚æˆ‘æ‰€éœ€è¦çš„å°±æ˜¯æ­£ç¡®çš„æ•è·ç¡¬ä»¶ï¼Œåˆé€‚çš„æ•è·è½¯ä»¶ï¼Œè¶³å¤Ÿçš„æ•°å­—å­˜å‚¨ä»¥åŠä¸€ç§å›æ”¾æºç£å¸¦çš„æ–¹æ³•ï¼Œå¹¶ä¸”æˆ‘å¯ä»¥æ— é™æœŸåœ°ä¿ç•™æ¯ä¸ªç£å¸¦çš„æ— æŸæ•°å­—æ•è·ã€‚æˆ‘çˆ¶äº²æœ€åè´­ä¹°çš„8æ¯«ç±³ä¾¿æºå¼æ‘„åƒæœºâ€“ Sony CCD-TR917 â€“ä»ç„¶å…·æœ‰æ¸…æ´çš„å·¥ä½œå¤´ï¼Œå¹¶ä¸”å¯ä»¥é€šè¿‡Sè§†é¢‘å’Œç«‹ä½“å£°RCAè¾“å‡ºè·¯ç”±æˆ‘ä»¬ç°æœ‰çš„ç£å¸¦åº“ã€‚é‰´äºæœ€åˆçš„æ‹æ‘„æ–¹å¼ï¼Œè¿™ä¸ºæˆ‘æä¾›äº†æœ€å¥½çš„è´¨é‡ã€‚</p><p>  Generally with modern analog-to-digital preservation, you want to losslessly capture the raw source at a reasonably high sample rate with as little processing done to the source material as possible, from the moment it hits the playback heads to the instant itâ€™s written to disk. Any cleanup can be done in post-production software; in fact, as digital restoration technology improves, it is ideal to have a raw, lossless original available to revisit with improved techniques. For this project, I am using my dadâ€™s aforementioned  Sony CCD-TR917 camcorder attached directly to the S-video and stereo audio inputs of a  Blackmagic Intensity Pro PCIe card. The capturing PC is running Debian Linux and is plugged into the same circuit as the camcorder to avoid possible ground loop noise.</p><p>  é€šå¸¸ï¼Œå¯¹äºç°ä»£çš„æ¨¡æ•°ä¿å­˜ï¼Œæ‚¨å¸Œæœ›ä»¥åˆç†çš„é«˜é‡‡æ ·ç‡æ— æŸæ•è·åŸå§‹èµ„æºï¼Œè€Œå¯¹åŸå§‹ææ–™çš„å¤„ç†å°½å¯èƒ½å°‘ï¼Œä»å…¶åˆ°è¾¾æ’­æ”¾ç£å¤´çš„é‚£ä¸€åˆ»åˆ°å†™å…¥è¯¥åˆ»çš„é‚£ä¸€åˆ»ã€‚ç£ç›˜ã€‚ä»»ä½•æ¸…ç†éƒ½å¯ä»¥åœ¨åæœŸåˆ¶ä½œè½¯ä»¶ä¸­å®Œæˆï¼›å®é™…ä¸Šï¼Œéšç€æ•°å­—æ¢å¤æŠ€æœ¯çš„æ”¹è¿›ï¼Œç†æƒ³çš„æƒ…å†µæ˜¯æ‹¥æœ‰åŸå§‹çš„ï¼Œæ— æŸçš„åŸä»¶ï¼Œä»¥ä¾¿é€šè¿‡æ”¹è¿›çš„æŠ€æœ¯è¿›è¡Œé‡æ–°è®¿é—®ã€‚å¯¹äºè¿™ä¸ªé¡¹ç›®ï¼Œæˆ‘ä½¿ç”¨çš„æ˜¯æˆ‘çˆ¶äº²æåˆ°çš„Sony CCD-TR917ä¾¿æºå¼æ‘„åƒæœºï¼Œè¯¥æ‘„åƒæœºç›´æ¥è¿æ¥åˆ°Blackmagic Intensity Pro PCIeå¡çš„Sè§†é¢‘å’Œç«‹ä½“å£°éŸ³é¢‘è¾“å…¥ã€‚æ•è·PCè¿è¡Œçš„æ˜¯Debian Linuxï¼Œå¹¶æ’å…¥äº†ä¸æ‘„åƒæœºç›¸åŒçš„ç”µè·¯ä¸­ï¼Œä»¥é¿å…å¯èƒ½çš„æ¥åœ°ç¯è·¯å™ªå£°ã€‚</p><p> Since my Debian box is headless, Iâ€™m not interested in bringing up a full X installation just to grab some videos. Therefore I use the open source, command-line based  bmdtools suiteâ€”specifically bmdcaptureâ€”to do the raw captures from my Intensity Pro card. I do have to pull down the  DeckLink SDK in order to build bmdcapture, which does have some minor X-related dependencies, but I have to pull down the DeckLink software anyway for Linux drivers. I invoke the following from a shell before starting playback on the camcorder:</p><p> ç”±äºæˆ‘çš„Debianç›’å­æ˜¯æ— å¤´çš„ï¼Œå› æ­¤æˆ‘ä¸æƒ³ä¸ºäº†è·å–ä¸€äº›è§†é¢‘è€Œè¿›è¡Œå®Œæ•´çš„Xå®‰è£…ã€‚å› æ­¤ï¼Œæˆ‘ä½¿ç”¨åŸºäºå‘½ä»¤è¡Œçš„å¼€æºbmdtoolså¥—ä»¶ï¼ˆç‰¹åˆ«æ˜¯bmdcaptureï¼‰æ¥è¿›è¡ŒIntensity Proå¡çš„åŸå§‹æ•è·ã€‚æˆ‘ç¡®å®å¿…é¡»ä¸‹æ‹‰DeckLink SDKæ‰èƒ½æ„å»ºbmdcaptureï¼Œbmdcaptureç¡®å®å…·æœ‰ä¸€äº›ä¸Xç›¸å…³çš„å°ä¾èµ–æ€§ï¼Œä½†æ˜¯æ— è®ºå¦‚ä½•æˆ‘éƒ½å¿…é¡»ä¸‹æ‹‰DeckLinkè½¯ä»¶ä»¥ç”¨äºLinuxé©±åŠ¨ç¨‹åºã€‚åœ¨å¼€å§‹åœ¨ä¾¿æºå¼æ‘„åƒæœºä¸Šæ’­æ”¾ä¹‹å‰ï¼Œæˆ‘ä»å¤–å£³è°ƒç”¨ä»¥ä¸‹å†…å®¹ï¼š</p><p> $ ./bmdcapture -C 0 -m 0 -M 4 -A 1 -V 6 -d 0 -n 230000 -f &lt;output&gt;.nut</p><p>$ ./bmdcapture -C 0 -m 0 -M 4 -A 1 -V 6 -d 0 -n 230000 -f  .nut</p><p>  -m 0: Capture using mode 0; that is, 525i59.94 NTSC, or 720Ã—486 pixels at 29.97 FPS</p><p>  -m 0ï¼šä½¿ç”¨æ¨¡å¼0æ•è·ï¼›å³525i59.94 NTSCæˆ–720Ã—486åƒç´ ï¼ˆ29.97 FPSï¼‰</p><p> -M 4: Set a queue size of up to 4GB. Without this, bmdcapture can run out of memory before the entire tape is captured to disk.</p><p> -M 4ï¼šå°†é˜Ÿåˆ—å¤§å°è®¾ç½®ä¸ºæœ€å¤§4GBã€‚å¦‚æœä¸è¿™æ ·åšï¼Œåœ¨å°†æ•´ä¸ªç£å¸¦æ•è·åˆ°ç£ç›˜ä¹‹å‰ï¼Œbmdcaptureå¯èƒ½ä¼šè€—å°½å†…å­˜ã€‚</p><p> -A 1: Use the â€œAnalog (RCA or XLR)â€ audio input. In my case, stereo RCA.</p><p> -A 1ï¼šä½¿ç”¨â€œæ¨¡æ‹Ÿï¼ˆRCAæˆ–XLRï¼‰â€éŸ³é¢‘è¾“å…¥ã€‚å°±æˆ‘è€Œè¨€ï¼Œæ˜¯ç«‹ä½“å£°RCAã€‚</p><p> -V 6: Use the â€œS-Videoâ€ video input. The S-video input on the Intensity Pro is provided as  an RCA pair for chroma (â€œB-Y Inâ€) and luma/sync (â€œY Inâ€);  an adapter cable is necessary to convert to the standard miniDIN-4 connector.</p><p> -V 6ï¼šä½¿ç”¨â€œ S-Videoâ€è§†é¢‘è¾“å…¥ã€‚ Intensity Proä¸Šçš„Sè§†é¢‘è¾“å…¥ä»¥è‰²åº¦ï¼ˆâ€œ B-Y Inâ€ï¼‰å’Œäº®åº¦/åŒæ­¥ï¼ˆâ€œ Y Inâ€ï¼‰çš„RCAå¯¹çš„å½¢å¼æä¾›ï¼›å¿…é¡»ä½¿ç”¨é€‚é…å™¨ç”µç¼†æ‰èƒ½è½¬æ¢ä¸ºæ ‡å‡†miniDIN-4è¿æ¥å™¨ã€‚</p><p> -d 0: Fill in dropped frames with a black frame. The Sony CCD-TR917 has a built-in  TBC (which I leave enabled since I donâ€™t own a separate TBC), but owing to the age of the tapes, there is an occasional frame drop.</p><p> -d 0ï¼šç”¨é»‘æ¡†å¡«å……æ‰çš„å¸§ã€‚ Sony CCD-TR917å…·æœ‰å†…ç½®çš„TBCï¼ˆç”±äºæˆ‘æ²¡æœ‰å•ç‹¬çš„TBCï¼Œæˆ‘å°†å…¶å¯ç”¨ï¼‰ï¼Œä½†æ˜¯ç”±äºç£å¸¦çš„ä½¿ç”¨å¹´é™ï¼Œå¶å°”ä¼šæ‰è½å¸§ã€‚</p><p> -n 230000: Capture 230000 frames. At 29.97 FPS, thatâ€™s almost 7675 seconds, which is a little over two hours. Should be enough even for full tapes.</p><p> -n 230000ï¼šæ•è·230000å¸§ã€‚åœ¨29.97 FPSæ—¶ï¼Œå°†è¿‘7675ç§’ï¼Œè¿™æ˜¯ä¸¤ä¸ªå¤šå°æ—¶ã€‚å³ä½¿æ˜¯å®Œæ•´çš„ç£å¸¦ä¹Ÿåº”è¯¥è¶³å¤Ÿäº†ã€‚</p><p> -f &lt;output&gt;.nut: Write to  &lt;output&gt;.nut in the  NUT container format by default, substituting the tapeâ€™s label for  &lt;output&gt;. The  README.md provided with bmdtools suggests sticking with the default, and since FFmpeg has no trouble converting from NUT and Iâ€™ve had no trouble capturing to that format, I leave the output file format alone.</p><p>-f  .nutï¼šé»˜è®¤æƒ…å†µä¸‹ï¼Œä»¥NUTå®¹å™¨æ ¼å¼å†™å…¥ .nutï¼Œç”¨ç£å¸¦çš„æ ‡ç­¾ä»£æ›¿ã€‚ bmdtoolséšé™„çš„README.mdå»ºè®®ä½¿ç”¨é»˜è®¤è®¾ç½®ï¼Œå¹¶ä¸”ç”±äºFFmpegä»NUTè½¬æ¢æ²¡æœ‰é—®é¢˜ï¼Œå¹¶ä¸”æˆ‘ä¹Ÿæ²¡æœ‰æ•è·åˆ°è¯¥æ ¼å¼çš„éº»çƒ¦ï¼Œå› æ­¤æˆ‘ä¸ç†ä¼šè¾“å‡ºæ–‡ä»¶æ ¼å¼ã€‚</p><p> Once I have my lossless capture, I compress the .nut file using bzip2, getting the file size down to up to a quarter of the original size depending on how much of the tape is filled. I then create parity data on the .bz2 archive  using the par2 utility, and put my compressed capture and parity files somewhere safe for long-term archival storage. ğŸ™‚</p><p> è¿›è¡Œæ— æŸæ•è·åï¼Œæˆ‘å°†ä½¿ç”¨bzip2å‹ç¼©.nutæ–‡ä»¶ï¼Œæ ¹æ®å¡«å……çš„ç£å¸¦é‡ï¼Œå°†æ–‡ä»¶å¤§å°å‡å°åˆ°åŸå§‹å¤§å°çš„å››åˆ†ä¹‹ä¸€ã€‚ç„¶åï¼Œæˆ‘ä½¿ç”¨par2å®ç”¨ç¨‹åºåœ¨.bz2å½’æ¡£æ–‡ä»¶ä¸Šåˆ›å»ºå¥‡å¶æ ¡éªŒæ•°æ®ï¼Œå¹¶å°†å‹ç¼©çš„æ•è·å’Œå¥‡å¶æ ¡éªŒæ–‡ä»¶æ”¾åœ¨å®‰å…¨çš„ä½ç½®ä»¥è¿›è¡Œé•¿æœŸå½’æ¡£å­˜å‚¨ã€‚ ğŸ™‚</p><p> My Windows-based Intel NUC is where I do most of my video post-production work. It lacks a PCIe slot, so I canâ€™t capture there, but thatâ€™s fine because at this point my workflow is purely digital and I only have to worry about moving files around. My tools of choice here are AviSynth 2.6 and VirtualDub 1.10.4, but since AviSynth/VirtualDub are designed to work with AVI containers, I first convert my capture from the NUT container to the AVI container using FFmpeg:</p><p> æˆ‘åŸºäºWindowsçš„Intel NUCæ˜¯æˆ‘å¤§éƒ¨åˆ†è§†é¢‘åæœŸåˆ¶ä½œå·¥ä½œçš„åœ°æ–¹ã€‚å®ƒæ²¡æœ‰PCIeæ’æ§½ï¼Œæ‰€ä»¥æˆ‘ä¸èƒ½åœ¨é‚£å„¿æ•æ‰ï¼Œä½†è¿™å¾ˆå¥½ï¼Œå› ä¸ºæ­¤æ—¶æˆ‘çš„å·¥ä½œæµç¨‹æ˜¯çº¯æ•°å­—çš„ï¼Œæˆ‘åªéœ€è¦æ‹…å¿ƒæ–‡ä»¶ç§»åŠ¨ã€‚æˆ‘åœ¨è¿™é‡Œé€‰æ‹©çš„å·¥å…·æ˜¯AviSynth 2.6å’ŒVirtualDub 1.10.4ï¼Œä½†æ˜¯ç”±äºAviSynth / VirtualDubè®¾è®¡ç”¨äºAVIå®¹å™¨ï¼Œå› æ­¤æˆ‘é¦–å…ˆä½¿ç”¨FFmpegå°†æ•è·å†…å®¹ä»NUTå®¹å™¨è½¬æ¢ä¸ºAVIå®¹å™¨ï¼š</p><p>   -i &lt;output&gt;.nut: Use  &lt;output&gt;.nut as the input file. FFmpeg is smart and will auto-detect its file format when opened.</p><p>   -i  .nutï¼šä½¿ç”¨ .nutä½œä¸ºè¾“å…¥æ–‡ä»¶ã€‚ FFmpegå¾ˆèªæ˜ï¼Œæ‰“å¼€åä¼šè‡ªåŠ¨æ£€æµ‹å…¶æ–‡ä»¶æ ¼å¼ã€‚</p><p> -vcodec copy: Copy the video stream from the input fileâ€™s container to the output fileâ€™s container; do not re-encode.</p><p> -vcodecå¤åˆ¶ï¼šå°†è§†é¢‘æµä»è¾“å…¥æ–‡ä»¶çš„å®¹å™¨å¤åˆ¶åˆ°è¾“å‡ºæ–‡ä»¶çš„å®¹å™¨ï¼›ä¸è¦é‡æ–°ç¼–ç ã€‚</p><p> -acodec copy: Likewise for the audio stream, copy from the input fileâ€™s container to the output file; do not re-encode.</p><p> -acodec copyï¼šåŒæ ·ï¼Œå¯¹äºéŸ³é¢‘æµï¼Œä»è¾“å…¥æ–‡ä»¶çš„å®¹å™¨å¤åˆ¶åˆ°è¾“å‡ºæ–‡ä»¶ï¼›ä¸è¦é‡æ–°ç¼–ç ã€‚</p><p> &lt;output&gt;.avi: Write to  &lt;output&gt;.avi, again substituting my tapeâ€™s label for  &lt;output&gt; in both the input and output filenames.</p><p>  .aviï¼šå†™å…¥ .aviï¼Œå†æ¬¡ç”¨ç£å¸¦çš„æ ‡ç­¾æ›¿æ¢è¾“å…¥å’Œè¾“å‡ºæ–‡ä»¶åä¸­çš„ã€‚</p><p>  Now that I have an AVI source file, I can open it in VirtualDub. Owing to its namesake, VirtualDubâ€™s interface is reminiscent of a dual cassette deck ready to â€œdubâ€ from one container to another. It isnâ€™t as user-friendly as, say, Premiere or Resolve when it comes to editing and compositing, but what it lacks in usability it gains in flexibility. In particular, VirtualDub is designed to run a designated range of source video through one or more â€œfilters,â€ encoding to one of several output codecs available at the userâ€™s discretion via Video for Windows and/or DirectShow. If no filters are applied, VirtualDub can trim a video (and its audio)  without re-encodingâ€”great for preparing source footage clips for later editing or other processing.</p><p>ç°åœ¨æœ‰äº†AVIæºæ–‡ä»¶ï¼Œå¯ä»¥åœ¨VirtualDubä¸­æ‰“å¼€å®ƒã€‚ç”±äºå…·æœ‰ç›¸åŒçš„åç§°ï¼ŒVirtualDubçš„ç•Œé¢è®©äººæƒ³èµ·äº†ä¸€ä¸ªåŒç›’å¼å½•éŸ³å¸¦ï¼Œå¯ä»¥å°†å…¶ä»ä¸€ä¸ªå®¹å™¨â€œå¤åˆ¶â€åˆ°å¦ä¸€ä¸ªå®¹å™¨ã€‚åœ¨ç¼–è¾‘å’Œåˆæˆæ–¹é¢ï¼Œå®ƒä¸åƒPremiereæˆ–Resolveé‚£æ ·æ–¹ä¾¿ç”¨æˆ·ä½¿ç”¨ï¼Œä½†æ˜¯å®ƒç¼ºä¹å¯ç”¨æ€§ï¼Œå› æ­¤å…·æœ‰çµæ´»æ€§ã€‚ç‰¹åˆ«æ˜¯ï¼ŒVirtualDubæ—¨åœ¨é€šè¿‡ä¸€ä¸ªæˆ–å¤šä¸ªâ€œè¿‡æ»¤å™¨â€è¿è¡ŒæŒ‡å®šèŒƒå›´çš„æºè§†é¢‘ï¼Œå¹¶æ ¹æ®ç”¨æˆ·çš„æ„æ„¿é€šè¿‡Windows Videoå’Œ/æˆ–DirectShowç¼–ç ä¸ºå‡ ç§è¾“å‡ºç¼–è§£ç å™¨ä¹‹ä¸€ã€‚å¦‚æœæœªåº”ç”¨è¿‡æ»¤å™¨ï¼Œåˆ™VirtualDubå¯ä»¥ä¿®æ•´è§†é¢‘ï¼ˆåŠå…¶éŸ³é¢‘ï¼‰è€Œæ— éœ€é‡æ–°ç¼–ç -éå¸¸é€‚åˆå‡†å¤‡æºç´ æç‰‡æ®µï¼Œä»¥ä¾›ä»¥åç¼–è¾‘æˆ–å…¶ä»–å¤„ç†ã€‚</p><p>  Though the Sony CCD-TR917 has a built-in video noise reduction feature, I explicitly turn it off before capturing, because one of the filters I have for VirtualDub is  â€œNeat Videoâ€ by ABSoft. Itâ€™s the temporal version of their  â€œNeat Imageâ€ Photoshop filter for still images, which I used most recently to prepare a number of stills for Richard Mossâ€™s  The Secret History of Mac Gaming. Itâ€™s a very intelligent program that has a lot of knobs and dials to really tune in the noise profile you want to filter out, so I was equally delighted to find that ABSoftâ€™s magic works on videos too. Luckily they offer a plugin built to work with VirtualDub, so I didnâ€™t hesitate to buy it as a sure improvement over the mid-90s noise reduction technology built in to the camcorder.</p><p>  å°½ç®¡Sony CCD-TR917å…·æœ‰å†…ç½®çš„è§†é¢‘é™å™ªåŠŸèƒ½ï¼Œä½†æˆ‘åœ¨æ•è·ä¹‹å‰ä¼šå…ˆå°†å…¶å…³é—­ï¼Œå› ä¸ºæˆ‘ä¸ºVirtualDubé…å¤‡çš„æ»¤é•œä¹‹ä¸€æ˜¯ABSoftçš„â€œ Neat Videoâ€ã€‚è¿™æ˜¯ä»–ä»¬ç”¨äºé™æ­¢å›¾åƒçš„â€œ Neat Imageâ€ Photoshopæ»¤é•œçš„ä¸´æ—¶ç‰ˆæœ¬ï¼Œæˆ‘æœ€è¿‘ç”¨å®ƒæ¥ä¸ºRichard Mossçš„ã€Š Macæ¸¸æˆçš„ç§˜å¯†å†å²ã€‹å‡†å¤‡è®¸å¤šé™æ­¢å›¾åƒã€‚è¿™æ˜¯ä¸€ä¸ªéå¸¸æ™ºèƒ½çš„ç¨‹åºï¼Œå®ƒå…·æœ‰è®¸å¤šæ—‹é’®å’Œè½¬ç›˜ï¼Œå¯ä»¥çœŸæ­£è°ƒå‡ºæ‚¨è¦è¿‡æ»¤çš„å™ªå£°è½®å»“ï¼Œå› æ­¤ï¼Œæˆ‘åŒæ ·é«˜å…´åœ°å‘ç°ABSoftçš„é­”åŠ›ä¹Ÿå¯ä»¥åœ¨è§†é¢‘ä¸Šä½¿ç”¨ã€‚å¹¸è¿çš„æ˜¯ï¼Œä»–ä»¬æä¾›äº†ä¸€ä¸ªå¯ä¸VirtualDubä¸€èµ·ä½¿ç”¨çš„æ’ä»¶ï¼Œå› æ­¤ï¼Œæˆ‘æ¯«ä¸çŠ¹è±«åœ°è´­ä¹°äº†å®ƒï¼Œä»¥ç¡®ä¿å¯¹90å¹´ä»£ä¸­æœŸæ‘„å½•ä¸€ä½“æœºå†…ç½®çš„é™å™ªæŠ€æœ¯çš„æ”¹è¿›ã€‚</p><p> Most of the aforementioned features can be done in high-end NLE applications such as  Resolveâ€”indeed I have used Resolve to edit several video projects of my own. What makes VirtualDub the â€œkiller appâ€ for me is its use of Windowsâ€™s built-in video playback library, and therefore its ability to work with AviSynth scripts. AviSynth is a library that can be installed on Windows PCs that grants the ability to interpret AviSynth â€œscriptâ€ files (with the .avs extension) as AVI files anywhere Windows is prompted to play one using its built-in facilities. The basic  AviSynth scripting language is procedural, without loops or conditionals, but it does retain the ability to work with multiple variables at runtime and organize frequently-called sequences into subroutines. Its most common use is to form a filter chain starting with one or more source clips, ending with a final output clip. When â€œplayed back,â€ the filter chain is evaluated for each frame, but this is transparent to Windows, which instead just sees a complete movie as though itâ€™s already rendered to an AVI container.</p><p> å‰é¢æåˆ°çš„å¤§å¤šæ•°åŠŸèƒ½éƒ½å¯ä»¥åœ¨é«˜ç«¯NLEåº”ç”¨ç¨‹åºï¼ˆä¾‹å¦‚Resolveï¼‰ä¸­å®Œæˆï¼Œå®é™…ä¸Šæˆ‘å·²ç»ä½¿ç”¨Resolveç¼–è¾‘äº†è‡ªå·±çš„å¤šä¸ªè§†é¢‘é¡¹ç›®ã€‚å¯¹æˆ‘æ¥è¯´ï¼Œä½¿VirtualDubæˆä¸ºâ€œæ€æ‰‹çº§åº”ç”¨â€çš„åŸå› æ˜¯å®ƒä½¿ç”¨äº†Windowsçš„å†…ç½®è§†é¢‘æ’­æ”¾åº“ï¼Œå› æ­¤èƒ½å¤Ÿä½¿ç”¨AviSynthè„šæœ¬ã€‚ AviSynthæ˜¯ä¸€ä¸ªå¯ä»¥å®‰è£…åœ¨Windows PCä¸Šçš„åº“ï¼Œå®ƒå…·æœ‰å°†AviSynthâ€œè„šæœ¬â€æ–‡ä»¶ï¼ˆå¸¦æœ‰.avsæ‰©å±•åï¼‰è§£é‡Šä¸ºAVIæ–‡ä»¶çš„ä»»ä½•åŠŸèƒ½ï¼Œå¯ä»¥åœ¨ä»»ä½•æç¤ºWindowsä½¿ç”¨å…¶å†…ç½®åŠŸèƒ½æ’­æ”¾Windowsæ–‡ä»¶çš„åœ°æ–¹æ’­æ”¾ã€‚åŸºæœ¬çš„AviSynthè„šæœ¬è¯­è¨€æ˜¯è¿‡ç¨‹æ€§çš„ï¼Œæ²¡æœ‰å¾ªç¯æˆ–æ¡ä»¶çš„ï¼Œä½†å®ƒç¡®å®ä¿ç•™äº†åœ¨è¿è¡Œæ—¶ä½¿ç”¨å¤šä¸ªå˜é‡å¹¶å°†ç»å¸¸è°ƒç”¨çš„åºåˆ—ç»„ç»‡åˆ°å­ä¾‹ç¨‹ä¸­çš„èƒ½åŠ›ã€‚å®ƒæœ€å¸¸è§çš„ç”¨é€”æ˜¯å½¢æˆä¸€ä¸ªè¿‡æ»¤é“¾ï¼Œä»ä¸€ä¸ªæˆ–å¤šä¸ªæºç‰‡æ®µå¼€å§‹ï¼Œåˆ°æœ€åä¸€ä¸ªè¾“å‡ºç‰‡æ®µç»“æŸã€‚å½“â€œæ’­æ”¾â€æ—¶ï¼Œå°†é’ˆå¯¹æ¯ä¸ªå¸§è¯„ä¼°æ»¤é•œé“¾ï¼Œä½†è¿™å¯¹Windowsæ˜¯é€æ˜çš„ï¼ŒWindowsåªä¼šçœ‹åˆ°å®Œæ•´çš„ç”µå½±ï¼Œå°±åƒå·²ç»å°†å…¶æ¸²æŸ“åˆ°AVIå®¹å™¨ä¸€æ ·ã€‚</p><p> Combined with VirtualDub, AviSynth allows me to write tiny scripts to do trims and conversions with frame-accurate precision, then render these edits to a final output video. Though AviSynth should be able to invoke VirtualDub plugins from its scripting language, I couldnâ€™t figure out how to get it to work with Neat Video, so I did the next best thing: I created a pair of AviSynth scripts; one to feed  to Neat Video, and one to process the output  from Neat Video. The first script looks like this:</p><p> ä¸VirtualDubç»“åˆä½¿ç”¨ï¼ŒAviSynthå…è®¸æˆ‘ç¼–å†™å¾®å°çš„è„šæœ¬ä»¥ç²¾ç¡®åˆ°å¸§çš„ç²¾åº¦è¿›è¡Œä¿®å‰ªå’Œè½¬æ¢ï¼Œç„¶åå°†è¿™äº›ç¼–è¾‘å‘ˆç°ä¸ºæœ€ç»ˆçš„è¾“å‡ºè§†é¢‘ã€‚å°½ç®¡AviSynthåº”è¯¥èƒ½å¤Ÿä»å…¶è„šæœ¬è¯­è¨€è°ƒç”¨VirtualDubæ’ä»¶ï¼Œä½†æˆ‘æ— æ³•å¼„æ¸…æ¥šå¦‚ä½•ä½¿å…¶ä¸Neat Videoä¸€èµ·ä½¿ç”¨ï¼Œæ‰€ä»¥æˆ‘åšäº†ä¸‹ä¸€ä¸ªæœ€å¥½çš„äº‹æƒ…ï¼šæˆ‘åˆ›å»ºäº†ä¸€å¯¹AviSynthè„šæœ¬ï¼›ä¸€å°é¦ˆå…¥Neat Videoï¼Œå¦ä¸€å°å¤„ç†Neat Videoçš„è¾“å‡ºã€‚ç¬¬ä¸€ä¸ªè„šæœ¬å¦‚ä¸‹æ‰€ç¤ºï¼š</p><p>  Absent of an explicit input argument, each AviSynth instruction receives the output of the previous instruction as its input. The Neat Video plugin for VirtualDub  expects its input to be encoded as 8-bit RGB. VirtualDub will automatically convert the source video to what Neat Video expects if not already in the proper format. Since Iâ€™m not sure exactly  how VirtualDub does its automatic conversion, I want to retain control over the process so I do the conversion myself from YUV to RGB using the Rec.601 matrix. I know that my source video is from an interlaced analog NTSC source; VirtualDub doesnâ€™t know that unless I explicitly say so.</p><p>  ç”±äºæ²¡æœ‰æ˜ç¡®çš„è¾“å…¥å‚æ•°ï¼Œæ¯æ¡AviSynthæŒ‡ä»¤éƒ½ä¼šæ¥æ”¶å‰ä¸€æ¡æŒ‡ä»¤çš„è¾“å‡ºä½œä¸ºå…¶è¾“å…¥ã€‚ç”¨äºVirtualDubçš„Neat Videoæ’ä»¶æœŸæœ›å…¶è¾“å…¥è¢«ç¼–ç ä¸º8ä½RGBã€‚ VirtualDubå°†è‡ªåŠ¨å°†æºè§†é¢‘è½¬æ¢ä¸ºNeat VideoæœŸæœ›çš„æ ¼å¼ï¼ˆå¦‚æœæ ¼å¼ä¸æ­£ç¡®ï¼‰ã€‚ç”±äºæˆ‘ä¸ç¡®å®šVirtualDubåˆ°åº•å¦‚ä½•è¿›è¡Œè‡ªåŠ¨è½¬æ¢ï¼Œå› æ­¤æˆ‘æƒ³ä¿ç•™å¯¹è¯¥è¿‡ç¨‹çš„æ§åˆ¶æƒï¼Œæ‰€ä»¥æˆ‘è‡ªå·±ä½¿ç”¨Rec.601çŸ©é˜µä»YUVåˆ°RGBè¿›è¡Œè½¬æ¢ã€‚æˆ‘çŸ¥é“æˆ‘çš„æºè§†é¢‘æ¥è‡ªéš”è¡Œæ¨¡æ‹ŸNTSCæºã€‚é™¤éæˆ‘æ˜ç¡®å£°æ˜ï¼Œå¦åˆ™VirtualDubä¸ä¼šçŸ¥é“ã€‚</p><p>  I render this intermediate video to an AVI container using the Huffyuv codec. Huffyuv is a lossless codec, meaning it can compress the video without any generational loss. Despite its name, Huffyuv is perfectly capable of keeping my video encoded as RGB. I canâ€™t do further AviSynth processing on the result from Neat Video until I load it into my second AviSynth script, so Iâ€™m happy that its output can be unchanged from one script to the next.</p><p>  æˆ‘ä½¿ç”¨Huffyuvç¼–è§£ç å™¨å°†æ­¤ä¸­é—´è§†é¢‘æ¸²æŸ“åˆ°AVIå®¹å™¨ã€‚ Huffyuvæ˜¯ä¸€ç§æ— æŸç¼–è§£ç å™¨ï¼Œè¿™æ„å‘³ç€å®ƒå¯ä»¥å‹ç¼©è§†é¢‘è€Œä¸ä¼šé€ æˆä»»ä½•ä»£é™…æŸå¤±ã€‚å°½ç®¡åç§°å¦‚æ­¤ï¼Œä½†Huffyuvå®Œå…¨èƒ½å¤Ÿå°†æˆ‘çš„è§†é¢‘ç¼–ç ä¸ºRGBã€‚åœ¨å°†Neat Videoçš„ç»“æœåŠ è½½åˆ°ç¬¬äºŒä¸ªAviSynthè„šæœ¬ä¹‹å‰ï¼Œæˆ‘æ— æ³•å¯¹å…¶è¿›è¡Œè¿›ä¸€æ­¥çš„AviSynthå¤„ç†ï¼Œå› æ­¤ï¼Œæˆ‘å¾ˆé«˜å…´å…¶è¾“å‡ºå¯ä»¥åœ¨ä¸€ä¸ªè„šæœ¬ä¸ä¸‹ä¸€ä¸ªè„šæœ¬ä¹‹é—´ä¿æŒä¸å˜ã€‚</p><p>  Colors reproduced by mixing photons can be broken down into three â€œprimary colors.â€ We all learned about these in grade school:   red,   green, and   blue. Red and blue make   purple, blue and green make   turquoise, all three make   white, and so on.</p><p>  æ··åˆå…‰å­æ‰€äº§ç”Ÿçš„é¢œè‰²å¯ä»¥åˆ†è§£ä¸ºä¸‰ç§â€œåŸè‰²â€ã€‚æˆ‘ä»¬éƒ½åœ¨å°å­¦å­¦ä¹ è¿‡è¿™äº›ï¼šçº¢è‰²ï¼Œç»¿è‰²å’Œè“è‰²ã€‚çº¢è‰²å’Œè“è‰²ä»£è¡¨ç´«è‰²ï¼Œè“è‰²å’Œç»¿è‰²ä»£è¡¨é’ç»¿è‰²ï¼Œæ‰€æœ‰ä¸‰ä¸ªä»£è¡¨ç™½è‰²ï¼Œä¾æ­¤ç±»æ¨ã€‚</p><p> On TV screens, things are a bit more complicated. Way back when, probably before you were born, TV signals in the United States only came in black and white, and TVs only had one electron gun responsible for generating the entire picture. The picture signal mostly comprised of a varying voltage level per 525 lines indicating how bright or dark the picture should be at that point in that particular line. The history of the NTSC standard used to transmit analog television in the United States is well-documented elsewhere on the Internet, but the important fact here is that in 1953, color information was added to the TV signal broadcast to televisions conforming to the NTSC standard.</p><p>åœ¨ç”µè§†å±å¹•ä¸Šï¼Œæƒ…å†µè¦å¤æ‚ä¸€äº›ã€‚è¿½æº¯åˆ°å¤§æ¦‚åœ¨æ‚¨å‡ºç”Ÿä¹‹å‰ï¼Œç¾å›½çš„ç”µè§†ä¿¡å·åªæœ‰é»‘ç™½ä¿¡å·ï¼Œè€Œç”µè§†åªæœ‰ä¸€æ”¯ç”µå­æªè´Ÿè´£ç”Ÿæˆæ•´ä¸ªå›¾åƒã€‚å›¾åƒä¿¡å·ä¸»è¦ç”±æ¯525è¡Œå˜åŒ–çš„ç”µå‹ç”µå¹³ç»„æˆï¼ŒæŒ‡ç¤ºè¯¥å›¾åƒåœ¨è¯¥ç‰¹å®šè¡Œä¸­è¯¥ç‚¹çš„äº®æˆ–æš—ç¨‹åº¦ã€‚åœ¨ç¾å›½ï¼Œç”¨äºä¼ è¾“æ¨¡æ‹Ÿç”µè§†çš„NTSCæ ‡å‡†çš„å†å²åœ¨äº’è”ç½‘ä¸Šçš„å…¶ä»–åœ°æ–¹éƒ½æœ‰å……åˆ†çš„æ–‡çŒ®è®°è½½ï¼Œä½†é‡è¦çš„æ˜¯ï¼Œåœ¨1953å¹´ï¼Œå‘å¹¿æ’­åˆ°ç¬¦åˆNTSCæ ‡å‡†çš„ç”µè§†çš„ç”µè§†ä¿¡å·ä¸­æ·»åŠ äº†é¢œè‰²ä¿¡æ¯ã€‚ ã€‚</p><p> One of the challenges in adding color to what was heretofore a strictly monochrome-only signal was that millions of black and white TVs were already in active use in the United States. A TV set was extremely expensive even by the early 1950s, so rendering all the active sets obsolete by introducing a new color standard would have proven quite unpopular. The solutionâ€”similar to how FM stereo radio was later standardized in 1961â€”was to add color as a completely optional, but still integral, signal of monochrome TV. The original black and white signalâ€”now known as â€œlumaâ€â€”would continue to be used to determine the brightness or â€œluminanceâ€ of the picture at any particular point on the screen, while the new color streamâ€”known as â€œchromaâ€â€”would only transmit the color or â€œchrominanceâ€ information for that point. Existing black and white TVs would only know about the original â€œlumaâ€ signal, and so would continue to interpret it as a monochrome picture, whereas new color TVs would be aware of and overlay the new â€œchromaâ€ stream on top of the original â€œlumaâ€ stream to produce a rich, vibrant, color picture. All of this information still had to fit into a relatively limited bandwidth signal, designed in the early 1940s to be transmitted through the air with graceful degradation in poor conditions.</p><p> åœ¨è¿„ä»Šä»…æ˜¯å•è‰²ä¿¡å·çš„åŸºç¡€ä¸Šå¢åŠ è‰²å½©çš„æŒ‘æˆ˜ä¹‹ä¸€æ˜¯ï¼Œç¾å›½å·²ç»æœ‰æ•°ç™¾ä¸‡å°é»‘ç™½ç”µè§†æœºæŠ•å…¥ä½¿ç”¨ã€‚å³ä½¿åˆ°1950å¹´ä»£åˆæœŸï¼Œç”µè§†æœºä¹Ÿéå¸¸æ˜‚è´µï¼Œå› æ­¤é€šè¿‡å¼•å…¥æ–°çš„è‰²å½©æ ‡å‡†è€Œä½¿æ‰€æœ‰æœ‰æºç”µè§†æœºè¿‡æ—¶çš„åšæ³•å°†è¢«è¯æ˜ä¸å—æ¬¢è¿ã€‚è¯¥è§£å†³æ–¹æ¡ˆç±»ä¼¼äºFMç«‹ä½“å£°æ”¶éŸ³æœºåæ¥åœ¨1961å¹´è¿›è¡Œæ ‡å‡†åŒ–çš„æ–¹å¼ï¼Œæ˜¯å°†è‰²å½©æ·»åŠ ä¸ºå•è‰²ç”µè§†çš„å®Œå…¨å¯é€‰ä½†ä»ä¸å¯æˆ–ç¼ºçš„ä¿¡å·ã€‚åŸå§‹çš„é»‘ç™½ä¿¡å·ï¼ˆç°åœ¨ç§°ä¸ºâ€œäº®åº¦â€ï¼‰å°†ç»§ç»­ç”¨äºç¡®å®šå±å¹•ä¸Šä»»ä½•ç‰¹å®šç‚¹ä¸Šå›¾ç‰‡çš„äº®åº¦æˆ–â€œäº®åº¦â€ï¼Œè€Œæ–°çš„è‰²å½©æµï¼ˆç§°ä¸ºâ€œè‰²åº¦â€ï¼‰åªä¼šä¼ é€è¯¥ç‚¹çš„é¢œè‰²æˆ–â€œè‰²åº¦â€ä¿¡æ¯ã€‚ç°æœ‰çš„é»‘ç™½ç”µè§†åªä¼šçŸ¥é“åŸå§‹çš„â€œ lumaâ€ä¿¡å·ï¼Œå› æ­¤ä¼šç»§ç»­å°†å…¶è§£é‡Šä¸ºå•è‰²å›¾ç‰‡ï¼Œè€Œæ–°çš„å½©è‰²ç”µè§†å°†æ„è¯†åˆ°å¹¶è¦†ç›–æ–°çš„â€œ chromaâ€æµï¼Œå¹¶å°†å…¶è¦†ç›–åœ¨åŸå§‹â€œ lumaâ€æµäº§ç”Ÿä¸°å¯Œï¼Œå……æ»¡æ´»åŠ›çš„å½©è‰²å›¾ç‰‡ã€‚æ‰€æœ‰è¿™äº›ä¿¡æ¯ä»ç„¶å¿…é¡»é€‚åˆä¸€ä¸ªç›¸å¯¹æœ‰é™çš„å¸¦å®½ä¿¡å·ï¼Œè¯¥ä¿¡å·åœ¨1940å¹´ä»£åˆè®¾è®¡ä¸ºå¯ä»¥é€šè¿‡ç©ºä¸­ä¼ è¾“ï¼Œåœ¨æ¶åŠ£çš„æ¡ä»¶ä¸‹ä¼šé€æ¸è¡°å‡ã€‚</p><p>  The developers of early color computer monitors, by contrast, needed not worry about maintaining backward compatibility with black and white American television nor did they need to concern themselves with adopting a signal format that was almost 50 years old by that point. It should be of little surprise then, naturally, that computer monitors generate color closer to how we learned in grade school. Computer monitors in particular translate a signal describing separate intensities of red, green, and blue to a screen made up of triads of red, green, and blue dots of light. This signal describing whatâ€™s known as â€œ  R  G  Bâ€ color (for   Red,   Green, and   Blue) comes both from that aforementioned color theory of mixing primaries, but also historically from those individual color signals more or less directly driving the respective voltages of three electron guns inside a color CRT. Despite both color TVs and computer monitors having three electron guns for mixing red, green, and blue primary colors, the way that color information is  encoded before entering the TV is a main differentiator.</p><p>  ç›¸æ¯”ä¹‹ä¸‹ï¼Œæ—©æœŸå½©è‰²è®¡ç®—æœºæ˜¾ç¤ºå™¨çš„å¼€å‘äººå‘˜æ— éœ€æ‹…å¿ƒä¸é»‘ç™½ç¾å›½ç”µè§†ä¿æŒå‘åå…¼å®¹æ€§ï¼Œä¹Ÿä¸å¿…æ‹…å¿ƒé‡‡ç”¨é‚£æ—¶å·²å°†è¿‘50å¹´çš„ä¿¡å·æ ¼å¼ã€‚é‚£ä¹ˆè‡ªç„¶è€Œç„¶åœ°ï¼Œè®¡ç®—æœºæ˜¾ç¤ºå™¨äº§ç”Ÿçš„è‰²å½©æ›´æ¥è¿‘æˆ‘ä»¬åœ¨å°å­¦æ—¶æ‰€å­¦çš„çŸ¥è¯†å°±ä¸è¶³ä¸ºå¥‡äº†ã€‚ç‰¹åˆ«æ˜¯è®¡ç®—æœºç›‘è§†å™¨å°†æè¿°çº¢è‰²ï¼Œç»¿è‰²å’Œè“è‰²çš„å•ç‹¬å¼ºåº¦çš„ä¿¡å·è½¬æ¢ä¸ºç”±çº¢è‰²ï¼Œç»¿è‰²å’Œè“è‰²å…‰ç‚¹ç»„æˆçš„ä¸‰è”ä½“ç»„æˆçš„å±å¹•ã€‚æè¿°æ‰€è°“çš„â€œ RGBâ€é¢œè‰²ï¼ˆç”¨äºçº¢è‰²ï¼Œç»¿è‰²å’Œè“è‰²ï¼‰çš„ä¿¡å·ä¸ä»…æ¥è‡ªä¸Šè¿°æ··åˆåŸè‰²çš„é¢œè‰²ç†è®ºï¼Œè€Œä¸”å†å²ä¸Šä¹Ÿæ¥è‡ªé‚£äº›æˆ–å¤šæˆ–å°‘ç›´æ¥é©±åŠ¨ä¸‰æ”¯ç”µå­æªå„è‡ªç”µå‹çš„é¢œè‰²ä¿¡å·åœ¨å½©è‰²CRTä¸­ã€‚å°½ç®¡å½©è‰²ç”µè§†å’Œè®¡ç®—æœºç›‘è§†å™¨éƒ½å…·æœ‰ç”¨äºæ··åˆçº¢è‰²ï¼Œç»¿è‰²å’Œè“è‰²åŸè‰²çš„ä¸‰ä¸ªç”µå­æªï¼Œä½†æ˜¯åœ¨è¿›å…¥ç”µè§†ä¹‹å‰å¯¹é¢œè‰²ä¿¡æ¯è¿›è¡Œç¼–ç çš„æ–¹æ³•æ˜¯ä¸»è¦åŒºåˆ«ã€‚</p><p> Whereas RGB is the encoding scheme by which discrete Red, Green, and Blue values are represented, color TV uses something more akin to whatâ€™s known as â€œYUV.â€ YUV doesnâ€™t really stand for anythingâ€”the â€œYâ€ component represents Luma, and the â€œUVâ€ represents a coordinate into a 2D color plane, where  (1, 1) is   magenta,  (-1, -1) is   green, and  (0, 0) is   gray (the â€œdefaultâ€ value for when only the â€œYâ€ component is present, such as on black and white TVs). In NTSC, quadrature amplitude modulation is used to convey both of the UV components on top of the Y componentâ€™s frequencyâ€”I donâ€™t know exactly what quadrature amplitude modulation is either, but suffice it to say itâ€™s a fancy way of conveying two streams of information over one signal. ğŸ™‚</p><p> RGBæ˜¯è¡¨ç¤ºç¦»æ•£çš„çº¢è‰²ï¼Œç»¿è‰²å’Œè“è‰²å€¼çš„ç¼–ç æ–¹æ¡ˆï¼Œè€Œå½©è‰²ç”µè§†åˆ™ä½¿ç”¨ç±»ä¼¼äºâ€œ YUVâ€çš„åç§°ã€‚ YUVå¹¶ä¸ä»£è¡¨ä»»ä½•ä¸œè¥¿ï¼Œâ€œ Yâ€åˆ†é‡ä»£è¡¨äº®åº¦ï¼Œâ€œ UVâ€ä»£è¡¨äºŒç»´å½©è‰²å¹³é¢ä¸­çš„åæ ‡ï¼Œå…¶ä¸­ï¼ˆ1ï¼Œ1ï¼‰ä¸ºæ´‹çº¢è‰²ï¼Œï¼ˆ-1ï¼Œ-1ï¼‰ä¸ºç»¿è‰²ï¼Œ ï¼ˆ0ï¼Œ0ï¼‰ä¸ºç°è‰²ï¼ˆå½“ä»…å­˜åœ¨â€œ Yâ€åˆ†é‡æ—¶ï¼ˆä¾‹å¦‚åœ¨é»‘ç™½ç”µè§†ä¸Šï¼‰çš„â€œé»˜è®¤â€å€¼ï¼‰ã€‚åœ¨NTSCä¸­ï¼Œæ­£äº¤å¹…åº¦è°ƒåˆ¶ç”¨äºåœ¨Yåˆ†é‡çš„é¢‘ç‡ä¹‹ä¸Šä¼ è¾“ä¸¤ä¸ªUVåˆ†é‡-æˆ‘ä¹Ÿä¸ç¡®åˆ‡çŸ¥é“æ­£äº¤å¹…åº¦è°ƒåˆ¶æ˜¯ä»€ä¹ˆï¼Œä½†æ˜¯å¯ä»¥è¯´è¿™æ˜¯ä¸€ç§ä¼ è¾“ä¸¤ç§æµçš„ç†æƒ³æ–¹æ³•ã€‚ä¸€ä¸ªä¿¡å·çš„ä¿¡æ¯ã€‚ ğŸ™‚</p><p> An interesting quirk of how the human visual system works is that we have evolved to be much more sensitive to changes in brightness than in color. Some  very  smart people have sciencey explanations as to why this is, but ultimately we can thank our early ancestors for this traitâ€”being able to detect the subtlest of movements even in low light made us expert hunters. Indeed, when the lights are mostly off, most of us can still do a pretty good job of navigating our surroundings (read: hunting for the fridge) despite there being limited dynamic range in the brightness of what we  can see.</p><p> å…³äºäººç±»è§†è§‰ç³»ç»Ÿå¦‚ä½•å·¥ä½œçš„ä¸€ä¸ªæœ‰è¶£çš„æ€ªç™–æ˜¯ï¼Œæˆ‘ä»¬å·²ç»è¿›åŒ–ä¸ºå¯¹äº®åº¦å˜åŒ–æ¯”å¯¹é¢œè‰²å˜åŒ–æ›´æ•æ„Ÿã€‚ä¸€äº›éå¸¸èªæ˜çš„äººå¯¹è¿™æ˜¯ä¸ºä»€ä¹ˆæœ‰ç§‘å­¦çš„è§£é‡Šï¼Œä½†æœ€ç»ˆæˆ‘ä»¬å¯ä»¥æ„Ÿè°¢æˆ‘ä»¬çš„æ—©æœŸç¥–å…ˆçš„è¿™ç§ç‰¹å¾-å³ä½¿åœ¨ä½å…‰ä¸‹ä¹Ÿèƒ½å¤Ÿæ£€æµ‹åˆ°æœ€ç»†å¾®çš„åŠ¨ä½œï¼Œè¿™ä½¿æˆ‘ä»¬æˆä¸ºä¸“ä¸šçš„çŒäººã€‚ç¡®å®ï¼Œå½“ç¯å…‰å¤§éƒ¨åˆ†ä¸äº®æ—¶ï¼Œå°½ç®¡å¯è§å…‰çš„åŠ¨æ€èŒƒå›´æœ‰é™ï¼Œæˆ‘ä»¬å¤§å¤šæ•°äººä»ç„¶å¯ä»¥å¾ˆå¥½åœ°å¯¼èˆªå‘¨å›´çš„ç¯å¢ƒï¼ˆé˜…è¯»ï¼šå¯»æ‰¾å†°ç®±ï¼‰ã€‚</p><p> Note that having a higher sensitivity to brightness vs. color does not mean humans are better at seeing in black and white. It merely means that we notice the difference between something   bright and something   dark better than we can tell if something is   one shade of red vs.   a different shade of red. In addition, humans are more sensitive to   orange/  blue than we are to   purple/  green. These facts actually came in very handy when trying to figure out how to fit a good-enough-looking color TV signal into the bandwidth already reserved (and used) for American television. Because we are not as sensitive to color, the designers of NTSC color TV could get away with transmitting  less color information than whatâ€™s in the luma signal. By reducing the amount of bandwidth for the purple/green range, color in NTSC can still be satisfactorily reproduced, though the designers of NTSC adopted a variant of YUV to accomplish this called â€œYIQ.â€ In YIQ, the Y component is still Luma, but the â€œIQâ€ represents a new coordinate into the same 2D color plane as YUV, just rotated slightly so that the purple/green spectrum falls on the axis with a smaller range. Nowadays with the higher bandwidth digital TV provides, we no longer need to encode using YIQ, but due again to the way our vision system responds to color and the technical benefits it provides, TV/video is still encoded using YUV, albeit will a fuller chroma representation.</p><p> è¯·æ³¨æ„ï¼Œå¯¹äº®åº¦å’Œé¢œè‰²å…·æœ‰è¾ƒé«˜çš„æ•æ„Ÿæ€§å¹¶ä¸æ„å‘³ç€äººç±»åœ¨é»‘ç™½æ–¹é¢çš„è§†åŠ›ä¼šæ›´å¥½ã€‚è¿™ä»…æ„å‘³ç€æˆ‘ä»¬æ³¨æ„åˆ°æ˜äº®çš„äº‹ç‰©å’Œé»‘æš—çš„äº‹ç‰©ä¹‹é—´çš„åŒºåˆ«è¦å¥½äºæˆ‘ä»¬åˆ†è¾¨äº‹ç‰©æ˜¯çº¢è‰²çš„é˜´å½±è¿˜æ˜¯çº¢è‰²çš„é˜´å½±ã€‚æ­¤å¤–ï¼Œäººç±»å¯¹æ©™è‰²/è“è‰²æ¯”å¯¹ç´«è‰²/ç»¿è‰²æ›´æ•æ„Ÿã€‚å½“è¯•å›¾å¼„æ¸…æ¥šå¦‚ä½•å°†è¶³å¤Ÿå¥½çœ‹çš„å½©è‰²ç”µè§†ä¿¡å·æ”¾å…¥ç¾å›½ç”µè§†å·²ç»é¢„ç•™ï¼ˆå’Œä½¿ç”¨ï¼‰çš„å¸¦å®½ä¸­æ—¶ï¼Œè¿™äº›äº‹å®å®é™…ä¸Šéå¸¸æœ‰ç”¨ã€‚ç”±äºæˆ‘ä»¬å¯¹é¢œè‰²çš„æ•æ„Ÿæ€§ä¸é«˜ï¼Œå› æ­¤NTSCå½©è‰²ç”µè§†çš„è®¾è®¡äººå‘˜å¯ä»¥é¿å…ä¼ è¾“æ¯”äº®åº¦ä¿¡å·å°‘çš„é¢œè‰²ä¿¡æ¯ã€‚é€šè¿‡å‡å°‘ç´«è‰²/ç»¿è‰²èŒƒå›´çš„å¸¦å®½é‡ï¼Œå°½ç®¡NTSCçš„è®¾è®¡äººå‘˜é‡‡ç”¨YUVçš„å˜ä½“æ¥å®ç°è¿™ä¸€ç›®æ ‡ï¼Œä½†ä»å¯ä»¥ä»¤äººæ»¡æ„åœ°é‡ç°NTSCä¸­çš„é¢œè‰²ï¼Œç§°ä¸ºâ€œ YIQâ€ã€‚åœ¨YIQä¸­ï¼ŒYåˆ†é‡ä»ç„¶æ˜¯Lumaï¼Œä½†æ˜¯â€œ IQâ€ä»£è¡¨ä¸YUVç›¸åŒçš„2Då½©è‰²å¹³é¢ä¸­çš„æ–°åæ ‡ï¼Œåªæ˜¯ç¨å¾®æ—‹è½¬å³å¯ä½¿ç´«è‰²/ç»¿è‰²å…‰è°±è½åœ¨è¾ƒå°èŒƒå›´çš„è½´ä¸Šã€‚å¦‚ä»Šï¼Œéšç€æ•°å­—ç”µè§†æä¾›æ›´é«˜çš„å¸¦å®½ï¼Œæˆ‘ä»¬ä¸å†éœ€è¦ä½¿ç”¨YIQè¿›è¡Œç¼–ç ï¼Œä½†æ˜¯å†æ¬¡ç”±äºè§†è§‰ç³»ç»Ÿå¯¹é¢œè‰²çš„å“åº”æ–¹å¼åŠå…¶æ‰€æä¾›çš„æŠ€æœ¯ä¼˜åŠ¿ï¼Œå°½ç®¡è§†é¢‘/è§†é¢‘å°†æ›´åŠ é¥±æ»¡ï¼Œä½†ä»ç„¶ä½¿ç”¨YUVå¯¹å…¶è¿›è¡Œç¼–ç è‰²åº¦è¡¨ç¤ºã€‚</p><p>  Each pixel on a modern computer screen is represented by at least three discrete values for   Red,   Green, and   Blue. Though NTSC defines 525 lines per frame (~480 visible), being an  analog standard means there really isnâ€™t such a thing as â€œpixelsâ€ horizontally. However, most capture cards are configured to sample 720 points along each line of NTSC video, forming what we would call 720 â€œpixelsâ€ per line. But two important details must be noted:</p><p>  ç°ä»£è®¡ç®—æœºå±å¹•ä¸Šçš„æ¯ä¸ªåƒç´ è‡³å°‘ç”±çº¢è‰²ï¼Œç»¿è‰²å’Œè“è‰²çš„ä¸‰ä¸ªç¦»æ•£å€¼è¡¨ç¤ºã€‚å°½ç®¡NTSCæ¯å¸§å®šä¹‰525è¡Œï¼ˆå¯è§480è¡Œï¼‰ï¼Œä½†ä½œä¸ºæ¨¡æ‹Ÿæ ‡å‡†æ„å‘³ç€å®é™…ä¸Šæ²¡æœ‰æ°´å¹³çš„â€œåƒç´ â€ä¹‹ç±»çš„ä¸œè¥¿ã€‚ä½†æ˜¯ï¼Œå¤§å¤šæ•°æ•è·å¡éƒ½é…ç½®ä¸ºæ²¿NTSCè§†é¢‘çš„æ¯è¡Œé‡‡æ ·720ä¸ªç‚¹ï¼Œå½¢æˆæ¯è¡Œ720ä¸ªâ€œåƒç´ â€ã€‚ä½†æ˜¯å¿…é¡»æ³¨æ„ä¸¤ä¸ªé‡è¦çš„ç»†èŠ‚ï¼š</p><p> Though 720 samples are enough to effectively capture the entire line, only 704 of them are typically visible and furthermore, NTSC TV is designed for a 4:3 aspect ratio. That is, if the picture is 480 square dots vertically, then it must be  (480 * 4) / 3 == 640 square dots horizontally, or the picture will appear squished and everything will look â€œfat.â€ A captured NTSC frame at 720Ã—480 will need  horizontal scaling plus cropping to 640Ã—480 to be displayed with the correct aspect ratio on a computer screen with square dots.</p><p>å°½ç®¡720ä¸ªæ ·æœ¬è¶³ä»¥æœ‰æ•ˆåœ°æ•è·æ•´ä¸ªçº¿æ¡ï¼Œä½†é€šå¸¸åªæœ‰704ä¸ªæ ·æœ¬å¯è§ï¼Œè€Œä¸”NTSCç”µè§†çš„å®½é«˜æ¯”ä¸º4ï¼š3ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œå¦‚æœå›¾ç‰‡å‚ç›´ä¸º480æ–¹å½¢ç‚¹ï¼Œé‚£ä¹ˆæ°´å¹³å¿…é¡»ä¸ºï¼ˆ480 * 4ï¼‰/ 3 == 640æ–¹å½¢ç‚¹ï¼Œå¦åˆ™å›¾ç‰‡çœ‹èµ·æ¥ä¼šè¢«å‹æ‰ï¼Œå¹¶ä¸”æ‰€æœ‰å†…å®¹çœ‹èµ·æ¥éƒ½æ˜¯â€œèƒ–â€ã€‚åœ¨720Ã—480å¤„æ•è·çš„NTSCå¸§å°†éœ€è¦æ°´å¹³ç¼©æ”¾å¹¶è£å‰ªä¸º640Ã—480ï¼Œä»¥åœ¨å…·æœ‰æ­£æ–¹å½¢ç‚¹çš„è®¡ç®—æœºå±å¹•ä¸Šä»¥æ­£ç¡®çš„çºµæ¨ªæ¯”æ˜¾ç¤ºã€‚</p><p> 720 samples are enough to capture each line of the  luma component. The chroma component is a whole other story.</p><p> 720ä¸ªæ ·æœ¬è¶³ä»¥æ•è·äº®åº¦åˆ†é‡çš„æ¯ä¸€è¡Œã€‚è‰²åº¦åˆ†é‡æ˜¯å¦å¤–ä¸€ä¸ªæ•…äº‹ã€‚</p><p> Remember how the luma and chroma components are encoded separately, but that some of the chroma information can be discarded to save space and weâ€™re not likely to notice? Turns out, computers can use that technique too to reduce bandwidth usage and save disk space. RGB is just how your computer talks to its display, but thereâ€™s no rule that says computer video  files need to be encoded as RGB. We can encode them as YUV, too, and this is where the term  chroma subsampling comes in.</p><p> è¿˜è®°å¾—äº®åº¦å’Œè‰²åº¦åˆ†é‡æ˜¯å¦‚ä½•åˆ†åˆ«ç¼–ç çš„ï¼Œä½†æ˜¯å¯ä»¥ä¸¢å¼ƒæŸäº›è‰²åº¦ä¿¡æ¯ä»¥èŠ‚çœç©ºé—´ï¼Œæˆ‘ä»¬ä¸å¤ªå¯èƒ½æ³¨æ„åˆ°å—ï¼Ÿäº‹å®è¯æ˜ï¼Œè®¡ç®—æœºä¹Ÿå¯ä»¥ä½¿ç”¨è¯¥æŠ€æœ¯æ¥å‡å°‘å¸¦å®½ä½¿ç”¨å¹¶èŠ‚çœç£ç›˜ç©ºé—´ã€‚ RGBå°±æ˜¯è®¡ç®—æœºä¸æ˜¾ç¤ºå™¨è¿›è¡Œå¯¹è¯çš„æ–¹å¼ï¼Œä½†æ˜¯æ²¡æœ‰è§„åˆ™è¯´è®¡ç®—æœºè§†é¢‘æ–‡ä»¶éœ€è¦ç¼–ç ä¸ºRGBã€‚æˆ‘ä»¬ä¹Ÿå¯ä»¥å°†å®ƒä»¬ç¼–ç ä¸ºYUVï¼Œè¿™å°±æ˜¯è‰²åº¦å­é‡‡æ ·è¿™ä¸€æœ¯è¯­å‡ºç°çš„åœ°æ–¹ã€‚</p><p> While we always want to sample all 704 visible â€œpixelsâ€ of luma information, we can often get away with capturing 50% or even as little as 25% of the chroma information for a given line of picture. The ratio of sampled chroma data to luma data is called the â€œchroma subsamplingâ€ ratio and is indicated by the notation   Y:a:b, where:</p><p> å°½ç®¡æˆ‘ä»¬ä¸€ç›´æƒ³å¯¹äº®åº¦ä¿¡æ¯çš„æ‰€æœ‰704ä¸ªå¯è§â€œåƒç´ â€è¿›è¡Œé‡‡æ ·ï¼Œä½†æ˜¯å¯¹äºç»™å®šçš„å›¾åƒè¡Œï¼Œæˆ‘ä»¬é€šå¸¸å¯ä»¥æ•è·50ï¼…ç”šè‡³å°‘è‡³25ï¼…çš„è‰²åº¦ä¿¡æ¯ã€‚é‡‡æ ·çš„è‰²åº¦æ•°æ®ä¸äº®åº¦æ•°æ®çš„æ¯”ç‡ç§°ä¸ºâ€œè‰²åº¦äºŒæ¬¡é‡‡æ ·â€æ¯”ç‡ï¼Œå¹¶ç”¨ç¬¦å·Yï¼šaï¼šbè¡¨ç¤ºï¼Œå…¶ä¸­ï¼š</p><p> Y: the number of luma samples per line in the conceptual two-line block used by   a and   b to reference. This is almost always 4.</p><p> Yï¼šæ¦‚å¿µæ€§ä¸¤è¡Œå—ä¸­æ¯è¡Œçš„äº®åº¦é‡‡æ ·æ•°ï¼Œaå’Œbç”¨ä½œå‚è€ƒã€‚è¿™å‡ ä¹æ€»æ˜¯4ã€‚</p><p> a: the number of chroma samples mapped over t</p><p> aï¼štä¸Šæ˜ å°„çš„è‰²åº¦æ ·æœ¬æ•°</p><p>......</p><p>......</p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://blitter.net/blog/2020/11/24/digitizing-old-8mm-tapes/">https://blitter.net/blog/2020/11/24/digitizing-old-8mm-tapes/</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/mm/">#mm</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/è®¾è®¡/">#è®¾è®¡</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/åˆ›æ„/">#åˆ›æ„</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/æ‘„å½±/">#æ‘„å½±</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/å›¾ç‰‡/">#å›¾ç‰‡</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/æ¸¸æˆ/">#æ¸¸æˆ</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/è½¯ä»¶/">#è½¯ä»¶</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/è§†é¢‘/">#è§†é¢‘</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/æ‰‹æœº/">#æ‰‹æœº</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/å¹¿å‘Š/">#å¹¿å‘Š</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/ç½‘ç«™/">#ç½‘ç«™</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/å…è´¹/">#å…è´¹</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/ä¸‹è½½/">#ä¸‹è½½</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/å¾®è½¯/">#å¾®è½¯</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/è‹¹æœ/">#è‹¹æœ</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/éŸ³ä¹/">#éŸ³ä¹</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/åšå®¢/">#åšå®¢</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/æ¶æ/">#æ¶æ</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/è‰ºæœ¯/">#è‰ºæœ¯</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/å·¥å…·/">#å·¥å…·</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/åˆ†äº«/">#åˆ†äº«</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy; 2020 diglog.com </div></div></body></html>