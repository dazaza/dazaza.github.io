<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>ä¸ºä»€ä¹ˆå…³äºå›½é™…è±¡æ£‹çš„YouTubeèŠå¤©è¢«æ ‡è®°ä¸ºä»‡æ¨è¨€è®º Why a YouTube Chat About Chess Got Flagged for Hate Speech</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">Why a YouTube Chat About Chess Got Flagged for Hate Speech<br/>ä¸ºä»€ä¹ˆå…³äºå›½é™…è±¡æ£‹çš„YouTubeèŠå¤©è¢«æ ‡è®°ä¸ºä»‡æ¨è¨€è®º </h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2021-03-02 01:00:34</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2021/3/ed0cecb193d2fb7c58ea04fd00f33b8d.jpg"><img src="http://img2.diglog.com/img/2021/3/ed0cecb193d2fb7c58ea04fd00f33b8d.jpg" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>Last June, Antonio RadiÄ‡, the host of a  YouTube chess channel with more than a million subscribers, was live-streaming an interview with the grandmaster  Hikaru Nakamura when the broadcast suddenly cut out.</p><p>å»å¹´å…­æœˆï¼ŒYouTubeæ£‹ç‰Œé¢‘é“çš„ä¸»æŒäººå®‰ä¸œå°¼å¥¥Â·é›·è¿ªå¥‡ï¼ˆAntonioRadiÄ‡ï¼‰æ‹¥æœ‰è¶…è¿‡ä¸€ç™¾ä¸‡çš„è®¢é˜…è€…ï¼Œç›´æ’­çªç„¶ä¸­æ–­æ—¶ï¼Œç›´æ’­äº†å¯¹å¤§å¸ˆçº§ä¸­æ‘å…‰ï¼ˆHikaru Nakamuraï¼‰çš„é‡‡è®¿ã€‚</p><p> Instead of a lively discussion about chess openings, famous games, and iconic players, viewers were told  RadiÄ‡â€™s video had been removed for â€œharmful and dangerousâ€ content. RadiÄ‡ saw a message stating that the video, which included nothing more scandalous than a discussion of the  Kingâ€™s Indian Defense, had violated YouTubeâ€™s community guidelines. It remained offline for 24 hours.</p><p> è§‚ä¼—æ²¡æœ‰å¬åˆ°å…³äºå›½é™…è±¡æ£‹å¼€æ”¾ï¼Œè‘—åæ¸¸æˆå’Œæ ‡å¿—æ€§çƒå‘˜çš„çƒ­çƒˆè®¨è®ºï¼Œè€Œæ˜¯å‘Šè¯‰ä»–ä»¬RadiÄ‡çš„è§†é¢‘å·²åˆ é™¤ï¼Œå› ä¸ºå…¶ä¸­åŒ…å«â€œæœ‰å®³å’Œå±é™©â€çš„å†…å®¹ã€‚ RadiÄ‡çœ‹åˆ°ä¸€åˆ™æ¶ˆæ¯ï¼ŒæŒ‡å‡ºè¯¥è§†é¢‘è¿åäº†YouTubeçš„ç¤¾åŒºå‡†åˆ™ï¼Œå…¶ä¸­ä»…åŒ…å«è®¨è®ºå›½ç‹çš„å°åº¦å›½é˜²çš„ä¸‘é—»ã€‚å®ƒä¿æŒç¦»çº¿çŠ¶æ€24å°æ—¶ã€‚</p><p> Exactly what happened still isnâ€™t clear. YouTube declined to comment beyond saying that removing RadiÄ‡â€™s video was a mistake. But a new study suggests it reflects shortcomings in  artificial intelligence programs designed to automatically detect hate speech, abuse, and misinformation online.</p><p> åˆ°åº•å‘ç”Ÿäº†ä»€ä¹ˆè¿˜ä¸æ¸…æ¥šã€‚ YouTubeæ‹’ç»å‘è¡¨è¯„è®ºï¼Œåªæ˜¯è¯´åˆ é™¤RadiÄ‡çš„è§†é¢‘æ˜¯ä¸€ä¸ªé”™è¯¯ã€‚ä½†æ˜¯ä¸€é¡¹æ–°çš„ç ”ç©¶è¡¨æ˜ï¼Œå®ƒåæ˜ äº†æ—¨åœ¨è‡ªåŠ¨åœ¨çº¿æ£€æµ‹ä»‡æ¨è¨€è®ºï¼Œè™å¾…å’Œé”™è¯¯ä¿¡æ¯çš„äººå·¥æ™ºèƒ½ç¨‹åºçš„ç¼ºé™·ã€‚</p><p>  Ashique KhudaBukhsh, a project scientist who specializes in AI at Carnegie Mellon University and a serious chess player himself, wondered if YouTubeâ€™s algorithm may have been confused by discussions involving black and white pieces, attacks, and defenses.</p><p>  å¡å†…åŸºÂ·æ¢…éš†å¤§å­¦ï¼ˆCarnegie Mellon Universityï¼‰ä¸“æ”»AIçš„é¡¹ç›®ç§‘å­¦å®¶Ashique KhudaBukhshæœ¬èº«å°±æ˜¯ä¸€åä¸¥è‚ƒçš„å›½é™…è±¡æ£‹æ£‹æ‰‹ï¼Œä»–æƒ³çŸ¥é“YouTubeçš„ç®—æ³•æ˜¯å¦å¯èƒ½è¢«æ¶‰åŠé»‘ç™½æ£‹å­ï¼Œæ”»å‡»å’Œé˜²å¾¡çš„è®¨è®ºæ‰€æ··æ·†ã€‚</p><p> So he and  Rupak Sarkar, an engineer at CMU, designed an experiment. They trained two versions of a language model called  BERT, one using messages from the racist far-right website  Stormfront and the other using data from Twitter. They then tested the algorithms on the text and comments from 8,818 chess videos and found them to be far from perfect. The algorithms flagged around 1 percent of transcripts or comments as hate speech. But more than 80 percent of those flagged were false positivesâ€”read in context, the language was not racist. â€œWithout a human in the loop,â€ the pair say in their paper, â€œrelying on off-the-shelf classifiersâ€™ predictions on chess discussions can be misleading.â€</p><p> å› æ­¤ï¼Œä»–å’ŒCMUå·¥ç¨‹å¸ˆRupak Sarkarè®¾è®¡äº†ä¸€ä¸ªå®éªŒã€‚ä»–ä»¬åŸ¹è®­äº†ä¸¤ç§ç‰ˆæœ¬çš„BERTè¯­è¨€æ¨¡å‹ï¼Œä¸€ç§ä½¿ç”¨ç§æ—ä¸»ä¹‰çš„æå³ç¿¼ç½‘ç«™Stormfrontçš„æ¶ˆæ¯ï¼Œå¦ä¸€ç§ä½¿ç”¨Twitterçš„æ•°æ®ã€‚ç„¶åï¼Œä»–ä»¬æµ‹è¯•äº†8,818ä¸ªå›½é™…è±¡æ£‹è§†é¢‘ä¸­çš„æ–‡å­—å’Œè¯„è®ºä¸­çš„ç®—æ³•ï¼Œå‘ç°å®ƒä»¬è¿œéå®Œç¾ã€‚è¯¥ç®—æ³•å°†å¤§çº¦1ï¼…çš„æˆç»©å•æˆ–è¯„è®ºæ ‡è®°ä¸ºä»‡æ¨è¨€è®ºã€‚ä½†æ˜¯ï¼Œåœ¨è¢«ä¸¾æŠ¥çš„é‚£äº›äººä¸­ï¼Œæœ‰80ï¼…ä»¥ä¸Šæ˜¯å‡é˜³æ€§-åœ¨ä¸Šä¸‹æ–‡ä¸­é˜…è¯»ï¼Œè¯¥è¯­è¨€ä¸æ˜¯ç§æ—ä¸»ä¹‰è€…ã€‚ä»–ä»¬åœ¨è®ºæ–‡ä¸­è¯´ï¼šâ€œæ²¡æœ‰äººåœ¨åœˆå†…ï¼Œä¾é ç°æˆçš„åˆ†ç±»è€…å¯¹å›½é™…è±¡æ£‹è®¨è®ºçš„é¢„æµ‹å¯èƒ½ä¼šäº§ç”Ÿè¯¯å¯¼ã€‚â€</p><p>  The experiment exposed a core problem for AI language programs. Detecting hate speech or abuse is about more than just catching foul  words and phrases. The same words can have vastly different meaning in different contexts, so an algorithm must infer meaning from a string of words.</p><p>  è¯¥å®éªŒæš´éœ²äº†AIè¯­è¨€ç¨‹åºçš„ä¸€ä¸ªæ ¸å¿ƒé—®é¢˜ã€‚æ£€æµ‹ä»‡æ¨è¨€è®ºæˆ–è™å¾…ä¸ä»…ä»…æ˜¯ä¾¦å¬æ±¡ç§½çš„å•è¯å’ŒçŸ­è¯­ã€‚ç›¸åŒçš„å•è¯åœ¨ä¸åŒçš„ä¸Šä¸‹æ–‡ä¸­å¯èƒ½å…·æœ‰æˆªç„¶ä¸åŒçš„å«ä¹‰ï¼Œå› æ­¤ç®—æ³•å¿…é¡»ä»å­—ç¬¦ä¸²ä¸­æ¨æ–­å‡ºå«ä¹‰ã€‚</p><p>  â€œFundamentally, language is still a very subtle thing,â€ says  Tom Mitchell, a CMU professor who has previously worked with KhudaBukhsh. â€œThese kinds of trained classifiers are not soon going to be 100 percent accurate.â€</p><p>  â€œä»æ ¹æœ¬ä¸Šè®²ï¼Œè¯­è¨€ä»ç„¶æ˜¯éå¸¸å¾®å¦™çš„äº‹æƒ…ï¼Œâ€ä»¥å‰æ›¾åœ¨KhudaBukhshå·¥ä½œè¿‡çš„CMUæ•™æˆTom Mitchellè¯´ã€‚ â€œè¿™ç±»è®­ç»ƒæœ‰ç´ çš„åˆ†ç±»å™¨å¾ˆå¿«å°†ä¸ä¼š100ï¼…å‡†ç¡®ã€‚â€ </p><p>  Yejin Choi, an associate professor at the University of Washington who specializes in AI and language, says she is â€œnot at allâ€ surprised by the YouTube takedown, given the limits of language understanding today. Choi says additional progress in detecting hate speech will require big investments and new approaches. She says that algorithms work better when they analyze more than just a piece of text in isolation, incorporating, for example, a userâ€™s history of comments or the nature of the channel in which the comments are being posted.</p><p>åç››é¡¿å¤§å­¦ä¸“é—¨ç ”ç©¶AIå’Œè¯­è¨€çš„å‰¯æ•™æˆYeye Choiè¡¨ç¤ºï¼Œé‰´äºå½“ä»Šçš„è¯­è¨€ç†è§£èƒ½åŠ›æœ‰é™ï¼Œå¥¹å¯¹YouTubeçš„å–æ¶ˆæ„Ÿåˆ°â€œä¸€ç‚¹ä¹Ÿä¸æƒŠè®¶â€ã€‚ Choiè¯´ï¼Œåœ¨æ£€æµ‹ä»‡æ¨è¨€è®ºæ–¹é¢çš„å…¶ä»–è¿›å±•å°†éœ€è¦å¤§é‡æŠ•èµ„å’Œæ–°æ–¹æ³•ã€‚å¥¹è¯´ï¼Œç®—æ³•åœ¨å­¤ç«‹åœ°åˆ†æå¤šä¸ªæ–‡æœ¬æ—¶ï¼Œä¾‹å¦‚ç»“åˆç”¨æˆ·çš„è¯„è®ºå†å²è®°å½•æˆ–å‘å¸ƒè¯„è®ºçš„æ¸ é“çš„æ€§è´¨ï¼Œæ•ˆæœæ›´å¥½ã€‚</p><p> But Choiâ€™s research also shows how hate-speech detection can perpetuate biases. In a  2019 study, she and others found that human annotators were more likely to label Twitter posts by users who self-identify as African American as abusive and that algorithms trained to identify abuse using those annotations will repeat those biases.</p><p> ä½†æ˜¯Choiçš„ç ”ç©¶è¿˜è¡¨æ˜ï¼Œä»‡æ¨è¯­éŸ³æ£€æµ‹å¦‚ä½•ä½¿åè§æ°¸ä¹…åŒ–ã€‚åœ¨2019å¹´çš„ä¸€é¡¹ç ”ç©¶ä¸­ï¼Œå¥¹å’Œå…¶ä»–äººå‘ç°ï¼Œäººç±»æ³¨é‡Šè€…æ›´æœ‰å¯èƒ½é€šè¿‡è‡ªæˆ‘è¯†åˆ«ä¸ºéè£”ç¾å›½äººçš„ç”¨æˆ·ä¸ºTwitterå¸–å­è´´æ ‡ç­¾ï¼Œå¹¶ä¸”è®­ç»ƒæœ‰ç´ çš„ç®—æ³•ä½¿ç”¨è¿™äº›æ³¨é‡Šæ¥è¯†åˆ«æ»¥ç”¨è¡Œä¸ºå°†é‡å¤è¿™äº›åè§ã€‚</p><p>  Companies have spent many millions collecting and annotating training data for self-driving cars, but Choi says the same effort has not been put into annotating language. So far, no one has collected and annotated a high-quality data set of hate speech or abuse that includes lots of â€œedge casesâ€ with ambiguous language. â€œIf we made that level of investment on data collectionâ€”or even a small fraction of itâ€”Iâ€™m sure AI can do much better,â€ she says.</p><p>  å…¬å¸å·²ç»èŠ±è´¹äº†æ•°ç™¾ä¸‡ç¾å…ƒæ¥æ”¶é›†å’Œæ³¨é‡Šè‡ªåŠ¨é©¾é©¶æ±½è½¦çš„åŸ¹è®­æ•°æ®ï¼Œä½†æ˜¯Choiè¯´ï¼Œæ³¨é‡Šè¯­è¨€è¿˜æ²¡æœ‰ä»˜å‡ºåŒæ ·çš„åŠªåŠ›ã€‚åˆ°ç›®å‰ä¸ºæ­¢ï¼Œè¿˜æ²¡æœ‰äººæ”¶é›†å’Œæ³¨é‡ŠåŒ…æ‹¬ä»‡æ¨è¨€è®ºæˆ–è™å¾…çš„é«˜è´¨é‡æ•°æ®é›†ï¼Œå…¶ä¸­åŒ…æ‹¬è®¸å¤šå«ç³Šä¸æ¸…çš„è¯­è¨€çš„â€œè¾¹ç¼˜æ¡ˆä¾‹â€ã€‚å¥¹è¯´ï¼šâ€œå¦‚æœæˆ‘ä»¬åœ¨æ•°æ®æ”¶é›†ä¸Šè¿›è¡Œè¿™æ ·çš„æŠ•èµ„ï¼Œç”šè‡³åªæ˜¯å…¶ä¸­çš„ä¸€å°éƒ¨åˆ†ï¼Œæˆ‘ç›¸ä¿¡AIä¼šåšå¾—æ›´å¥½ã€‚â€</p><p> Mitchell, the CMU professor, says YouTube and other platforms likely have more sophisticated AI algorithms than the one KhudaBukhsh built; but even those are still limited.</p><p> CMUæ•™æˆç±³åˆ‡å°”ï¼ˆMitchellï¼‰è¯´ï¼ŒYouTubeå’Œå…¶ä»–å¹³å°å¯èƒ½æ‹¥æœ‰æ¯”KhudaBukhshæ‰€æ„å»ºçš„AIç®—æ³•æ›´å¤æ‚çš„AIç®—æ³•ã€‚ä½†å³ä½¿æ˜¯é‚£äº›ä»ç„¶æœ‰é™ã€‚</p><p>  Big tech companies are counting on AI to address hate speech online. In 2018, Mark Zuckerberg  told Congress that AI would help stamp out hate speech. Earlier this month,  Facebook said its AI algorithms detected 97 percent of the hate speech the company removed in the last three months of 2020, up from 24 percent in 2017. But it  does not disclose the volume of hate speech the algorithms miss, or how often AI gets it wrong.</p><p>  å¤§å‹ç§‘æŠ€å…¬å¸æŒ‡æœ›AIåœ¨ç½‘ä¸Šè§£å†³ä»‡æ¨è¨€è®ºã€‚åœ¨2018å¹´ï¼Œé©¬å…‹Â·æ‰å…‹ä¼¯æ ¼ï¼ˆMark Zuckerbergï¼‰å‘å›½ä¼šè¡¨ç¤ºï¼Œäººå·¥æ™ºèƒ½å°†æœ‰åŠ©äºæ¶ˆé™¤ä»‡æ¨è¨€è®ºã€‚æœ¬æœˆæ—©äº›æ—¶å€™ï¼ŒFacebookè¡¨ç¤ºï¼Œå…¶AIç®—æ³•æ£€æµ‹åˆ°è¯¥å…¬å¸åœ¨2020å¹´çš„æœ€åä¸‰ä¸ªæœˆä¸­åˆ é™¤äº†97ï¼…çš„ä»‡æ¨è¨€è®ºï¼Œé«˜äº2017å¹´çš„24ï¼…ã€‚ä½†å®ƒæ²¡æœ‰é€éœ²è¯¥ç®—æ³•é—æ¼çš„ä»‡æ¨è¨€è®ºçš„æ•°é‡ï¼Œä¹Ÿæ²¡æœ‰é€éœ²å¦‚ä½•äººå·¥æ™ºèƒ½å¸¸å¸¸ä¼šæŠŠå®ƒå¼„é”™ã€‚</p><p> WIRED fed some of the comments gathered by the CMU researchers into two hate-speech classifiersâ€” one from Jigsaw, an Alphabet subsidiary focused on tackling misinformation and toxic content, and  another from Facebook. Some statements, such as â€œAt 1:43, if white king simply moves to G1, it&#39;s the end of black&#39;s attack and white is only down a knight, right?â€ were judged 90 percent likely not hate speech. But the statement â€œWhiteâ€™s attack on black is brutal. White is stomping all over blackâ€™s defenses. The black king is gonna fall â€¦ â€ was judged more than 60 percent likely to be hate speech.</p><p> æœ‰çº¿å°†CMUç ”ç©¶äººå‘˜æ”¶é›†çš„ä¸€äº›è¯„è®ºåˆ†ä¸ºä¸¤ä¸ªè®¨åŒçš„è¯­éŸ³åˆ†ç±»å™¨-ä¸€ä¸ªæ¥è‡ªJigsawï¼ŒAlphabetå­å…¬å¸ä¸“æ³¨äºå¤„ç†é”™è¯¯ä¿¡æ¯å’Œæœ‰æ¯’å†…å®¹ï¼Œå¦ä¸€ä¸ªæ¥è‡ªFacebookã€‚ä¸€äº›é™ˆè¿°ï¼Œä¾‹å¦‚â€œåœ¨1:43ï¼Œå¦‚æœç™½äººå›½ç‹ç®€å•åœ°ç§»åŠ¨åˆ°G1ï¼Œé‚£æ˜¯é»‘äººè¿›æ”»çš„ç»ˆç‚¹ï¼Œè€Œç™½äººåªæ˜¯å‡»å€’äº†éª‘å£«ï¼Œå¯¹å—ï¼Ÿâ€è¢«åˆ¤å®šæœ‰90ï¼…çš„äººå¯èƒ½ä¸å–œæ¬¢è®²è¯ã€‚ä½†æ˜¯â€œç™½äººæ”»å‡»é»‘äººâ€çš„è¯´æ³•æ˜¯æ®‹é…·çš„ã€‚ç™½è‰²é˜»ç¢äº†é»‘äººçš„é˜²å¾¡ã€‚é»‘äººå›½ç‹å°†è¦å •è½â€¦â€¦è¢«åˆ¤å®šæœ‰60ï¼…ä»¥ä¸Šæ˜¯ä»‡æ¨è¨€è®ºã€‚</p><p> It remains unclear how often content may be mistakenly flagged as hate speech on YouTube and other platforms. â€œWe donâ€™t know how often it happens,â€ KhudaBukhsh says. â€œIf a YouTuber isnâ€™t that famous, we will not see it.â€</p><p> å°šä¸æ¸…æ¥šåœ¨YouTubeå’Œå…¶ä»–å¹³å°ä¸Šæœ‰å¤šå°‘æ¬¡å†…å®¹ä¼šè¢«é”™è¯¯åœ°æ ‡è®°ä¸ºä»‡æ¨è¨€è®ºã€‚ â€œæˆ‘ä»¬ä¸çŸ¥é“å®ƒå‘ç”Ÿçš„é¢‘ç‡ï¼Œâ€ KhudaBukhshè¯´ã€‚ â€œå¦‚æœYouTuberä¸é‚£ä¹ˆå‡ºåï¼Œæˆ‘ä»¬å°†ä¸ä¼šçœ‹åˆ°å®ƒã€‚â€ </p><p>   ğŸ“± Torn between the latest phones? Never fearâ€”check out our  iPhone buying guide and  favorite Android phones</p><p>ğŸ“±åœ¨æœ€æ–°æ‰‹æœºä¹‹é—´è¢«æ’•è£‚ï¼Ÿ ä¸ç”¨æ‹…å¿ƒ-æŸ¥çœ‹æˆ‘ä»¬çš„iPhoneè´­ä¹°æŒ‡å—å’Œå–œçˆ±çš„Androidæ‰‹æœº </p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://www.wired.com/story/why-youtube-chat-chess-flagged-hate-speech/">https://www.wired.com/story/why-youtube-chat-chess-flagged-hate-speech/</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/youtube/">#youtube</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/chat/">#chat</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/è¯­è¨€/">#è¯­è¨€</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/è®¾è®¡/">#è®¾è®¡</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/åˆ›æ„/">#åˆ›æ„</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/æ‘„å½±/">#æ‘„å½±</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/å›¾ç‰‡/">#å›¾ç‰‡</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/æ¸¸æˆ/">#æ¸¸æˆ</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/è½¯ä»¶/">#è½¯ä»¶</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/è§†é¢‘/">#è§†é¢‘</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/æ‰‹æœº/">#æ‰‹æœº</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/å¹¿å‘Š/">#å¹¿å‘Š</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/ç½‘ç«™/">#ç½‘ç«™</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/å…è´¹/">#å…è´¹</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/ä¸‹è½½/">#ä¸‹è½½</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/å¾®è½¯/">#å¾®è½¯</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/éŸ³ä¹/">#éŸ³ä¹</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/è‹¹æœ/">#è‹¹æœ</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/åšå®¢/">#åšå®¢</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/æ¶æ/">#æ¶æ</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/è‰ºæœ¯/">#è‰ºæœ¯</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/å·¥å…·/">#å·¥å…·</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/åˆ†äº«/">#åˆ†äº«</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy; 2020 diglog.com </div></div></body></html>