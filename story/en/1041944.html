<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>DeepMindçš„é¦–å¸­ç ”ç©¶ç§‘å­¦å®¶David Silveråœ¨AlphaGoï¼ŒAlphaZeroå’ŒMuZeroä¸Šçš„ç ”ç©¶å°†å¼ºåŒ–å­¦ä¹ åº”ç”¨äºç°å®ä¸–ç•Œä¸­çš„é—®é¢˜ç­‰ David Silver, a principal research scientist at DeepMind, on AlphaGo, AlphaZero, and MuZero, applying reinforcement learning to real world problems, and more</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">David Silver, a principal research scientist at DeepMind, on AlphaGo, AlphaZero, and MuZero, applying reinforcement learning to real world problems, and more<br/>DeepMindçš„é¦–å¸­ç ”ç©¶ç§‘å­¦å®¶David Silveråœ¨AlphaGoï¼ŒAlphaZeroå’ŒMuZeroä¸Šçš„ç ”ç©¶å°†å¼ºåŒ–å­¦ä¹ åº”ç”¨äºç°å®ä¸–ç•Œä¸­çš„é—®é¢˜ç­‰ </h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2020-12-27 07:34:03</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2020/12/7e5dd78c45a450a379b511dac96a35eb.jpg"><img src="http://img2.diglog.com/img/2020/12/7e5dd78c45a450a379b511dac96a35eb.jpg" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>David Silver is responsible for several eye-catching demonstrations of  artificial intelligence in recent years, working on advances that helped revive interest in the field after the last great  AI Winter.</p><p>æˆ´ç»´Â·è¥¿å°”å¼—ï¼ˆDavid Silverï¼‰è´Ÿè´£è¿‘å¹´æ¥çš„å‡ æ¬¡å¼•äººæ³¨ç›®çš„äººå·¥æ™ºèƒ½æ¼”ç¤ºï¼Œå¹¶è‡´åŠ›äºåœ¨ä¸Šä¸ªä¼Ÿå¤§çš„AI Winterå¤§ä¼šä¹‹åé‡æ–°å”¤èµ·äººä»¬å¯¹è¯¥é¢†åŸŸçš„å…´è¶£ã€‚</p><p> At  DeepMind, a subsidiary of Alphabet, Silver has led the development of techniques that let computers learn for themselves how to solve problems that once seemed intractable.</p><p> åœ¨Alphabetçš„å­å…¬å¸DeepMindï¼ŒSilveré¢†å¯¼äº†æŠ€æœ¯çš„å¼€å‘ï¼Œè¿™äº›æŠ€æœ¯å¯ä»¥ä½¿è®¡ç®—æœºè‡ªå·±å­¦ä¹ å¦‚ä½•è§£å†³æ›¾ç»æ£˜æ‰‹çš„é—®é¢˜ã€‚</p><p> Most famously, this includes  AlphaGo, a program revealed in 2017 that taught itself to play the ancient board game Go to a grandmaster level. Go is too subtle and instinctive to be tamed using conventional programming, but AlphaGo learned to play through practice and positive rewardâ€”an AI technique known as â€œreinforcement learning.â€</p><p> æœ€è‘—åçš„æ˜¯AlphaGoï¼Œè¯¥ç¨‹åºäº2017å¹´å‘å¸ƒï¼Œè¯¥ç¨‹åºè‡ªå­¦äº†ç©å¤ä»£æ£‹ç›˜æ¸¸æˆGoåˆ°å¤§å¸ˆçº§åˆ«ã€‚ Goå¤ªå¾®å¦™å’Œæœ¬èƒ½ï¼Œæ— æ³•ä½¿ç”¨å¸¸è§„ç¼–ç¨‹æ¥é©¯æœï¼Œä½†æ˜¯AlphaGoå­¦ä¼šäº†é€šè¿‡å®è·µå’Œç§¯æå¥–åŠ±æ¥ç©æ¸¸æˆ-ä¸€ç§ç§°ä¸ºâ€œå¼ºåŒ–å­¦ä¹ â€çš„AIæŠ€æœ¯ã€‚</p><p>  In 2018, Silver and colleagues developed  a more general version of the program, called AlphaZero, capable of learning to play expert chess and shogi as well as Go. Then, in November 2019, DeepMind released details of MuZero, a version that learns to play these and other gamesâ€”but crucially without needing to know the rules beforehand.</p><p>  åœ¨2018å¹´ï¼ŒSilverå’ŒåŒäº‹å¼€å‘äº†è¯¥ç¨‹åºçš„æ›´é€šç”¨ç‰ˆæœ¬ï¼Œç§°ä¸ºAlphaZeroï¼Œèƒ½å¤Ÿå­¦ä¹ ä¸‹æ£‹å’Œå°†æ£‹ä»¥åŠå›´æ£‹çš„ä¸“å®¶ã€‚ç„¶åï¼Œåœ¨2019å¹´11æœˆï¼ŒDeepMindå‘å¸ƒäº†MuZeroçš„è¯¦ç»†ä¿¡æ¯ï¼Œè¯¥ç‰ˆæœ¬å¯å­¦ä¹ ç©è¿™äº›æ¸¸æˆå’Œå…¶ä»–æ¸¸æˆ-ä½†è‡³å…³é‡è¦çš„æ˜¯ï¼Œæ— éœ€äº‹å…ˆäº†è§£è§„åˆ™ã€‚</p><p> Silver met with senior writer Will Knight over Zoom from London to discuss MuZero, reinforcement learning, and the secret to making further progress in AI. This transcript has been edited for length and clarity.</p><p> Silverä¸ä¼¦æ•¦çš„Zoomèµ„æ·±ä½œå®¶Will Knightä¼šé¢ï¼Œè®¨è®ºäº†MuZeroï¼Œå¼ºåŒ–å­¦ä¹ ä»¥åŠåœ¨AIæ–¹é¢å–å¾—è¿›ä¸€æ­¥è¿›æ­¥çš„ç§˜å¯†ã€‚æ­¤ç¬”å½•å·²è¿‡ç¼–è¾‘ï¼Œä»¥ç¡®ä¿ç¯‡å¹…å’Œæ¸…æ™°åº¦ã€‚</p><p>  WIRED: Your MuZero work is published in the journal   Nature  today. For the uninitiated, tell us why it is important.</p><p>  è¿çº¿ï¼šæ‚¨çš„MuZeroä½œå“å‘è¡¨åœ¨ã€Šè‡ªç„¶ã€‹æ‚å¿—ä¸Šã€‚å¯¹äºæ²¡æœ‰ç»éªŒçš„äººï¼Œå‘Šè¯‰æˆ‘ä»¬ä¸ºä»€ä¹ˆå®ƒå¾ˆé‡è¦ã€‚</p><p> David Silver: The big step forward with MuZero is we don&#39;t tell it the dynamics of the environment; it has to figure that out for itself in a way that still lets it plan ahead and figure out what&#39;s going to be the most effective strategy. We want to have algorithms that work in the real world, and the real world is complicated and messy and unknown. So you can&#39;t just look ahead, like in a game of chess. You, you have to learn how the world works.</p><p> æˆ´ç»´Â·è¥¿å°”å¼—ï¼ˆDavid Silverï¼‰ï¼šä¸MuZeroç›¸æ¯”ï¼Œå‘å‰è¿ˆå‡ºçš„ä¸€å¤§æ­¥æ˜¯æˆ‘ä»¬ä¸å‘Šè¯‰ç¯å¢ƒåŠ¨æ€ã€‚å®ƒå¿…é¡»ä»¥ä¸€ç§ä»ç„¶å¯ä»¥è®©è‡ªå·±æå‰è®¡åˆ’å¹¶å¼„æ¸…æ¥šä»€ä¹ˆå°†æ˜¯æœ€æœ‰æ•ˆçš„ç­–ç•¥çš„æ–¹å¼è‡ªå·±å¼„æ¸…æ¥šè¿™ä¸€ç‚¹ã€‚æˆ‘ä»¬å¸Œæœ›æœ‰åœ¨ç°å®ä¸–ç•Œä¸­å¯ä»¥å·¥ä½œçš„ç®—æ³•ï¼Œè€Œç°å®ä¸–ç•Œå´æ˜¯å¤æ‚ï¼Œæ··ä¹±ä¸”æœªçŸ¥çš„ã€‚å› æ­¤ï¼Œæ‚¨ä¸èƒ½åƒå›½é™…è±¡æ£‹ä¸€æ ·å‘å‰çœ‹ã€‚æ‚¨ï¼Œæ‚¨å¿…é¡»å­¦ä¹ ä¸–ç•Œå¦‚ä½•è¿è½¬ã€‚ </p><p>  Some observers point out that MuZero, AlphaGo, and AlphaZero donâ€™t really start from scratch. They use algorithms crafted by clever humans to learn how to perform a particular task. Does this miss the point?</p><p>ä¸€äº›è§‚å¯Ÿè€…æŒ‡å‡ºï¼ŒMuZeroï¼ŒAlphaGoå’ŒAlphaZeroå¹¶éçœŸæ­£ä»å¤´å¼€å§‹ã€‚ä»–ä»¬ä½¿ç”¨èªæ˜äººåˆ¶ä½œçš„ç®—æ³•æ¥å­¦ä¹ å¦‚ä½•æ‰§è¡Œç‰¹å®šä»»åŠ¡ã€‚è¿™ä¼šé”™è¿‡é‡ç‚¹å—ï¼Ÿ</p><p> I think it does, actually. You never truly have a blank slate. There&#39;s even a theorem in  machine learningâ€”the no-free-lunch theoremâ€”that says you have to start with something or you don&#39;t get anywhere. But in this case, the slate is as blank as it gets. We&#39;re providing it with a  neural network, and the neural network has to figure out for itself, just from the feedback of the wins and losses in games or the score, how to understand the world.</p><p> æˆ‘è®¤ä¸ºç¡®å®å¦‚æ­¤ã€‚æ‚¨æ°¸è¿œä¸ä¼šçœŸæ­£æ‹¥æœ‰ä¸€ç‰‡ç©ºç™½ã€‚æœºå™¨å­¦ä¹ ä¸­ç”šè‡³æœ‰ä¸€ä¸ªå®šç†â€”éè‡ªç”±åˆé¤å®šç†â€”è¯´æ‚¨å¿…é¡»ä»æŸä»¶äº‹å¼€å§‹ï¼Œå¦åˆ™å°±æ— æ‰€é€‚ä»ã€‚ä½†æ˜¯åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ¿å²©æ˜¯ç©ºç™½çš„ã€‚æˆ‘ä»¬æ­£åœ¨ä¸ºå®ƒæä¾›ä¸€ä¸ªç¥ç»ç½‘ç»œï¼Œè€Œç¥ç»ç½‘ç»œå¿…é¡»è‡ªå·±ä»æ¸¸æˆæˆ–å¾—åˆ†çš„å¾—å¤±åé¦ˆä¸­äº†è§£å¦‚ä½•ç†è§£ä¸–ç•Œã€‚</p><p> One thing people picked up on is that we tell MuZero the legal moves in each situation. But if you take reinforcement learning, which is all about trying to solve problems in situations where the world is unknown, it&#39;s normally assumed that you&#39;re told what you can do. You have to tell the agent what choices it has available, and then it takes one of them.</p><p> äººä»¬æ¥å—çš„ä¸€ä»¶äº‹æ˜¯ï¼Œæˆ‘ä»¬å‘Šè¯‰MuZeroåœ¨æ¯ç§æƒ…å†µä¸‹çš„åˆæ³•ä¸¾åŠ¨ã€‚ä½†æ˜¯ï¼Œå¦‚æœæ‚¨è¿›è¡Œå¼ºåŒ–å­¦ä¹ ï¼Œè€Œè¿™ä»…ä»…æ˜¯åœ¨ä¸–ç•ŒæœªçŸ¥çš„æƒ…å†µä¸‹è¯•å›¾è§£å†³é—®é¢˜çš„æ–¹æ³•ï¼Œé€šå¸¸ä¼šå‡è®¾æ‚¨è¢«å‘ŠçŸ¥å¯ä»¥åšä»€ä¹ˆã€‚æ‚¨å¿…é¡»å‘Šè¯‰ä»£ç†å®ƒæœ‰å“ªäº›é€‰æ‹©ï¼Œç„¶åå†é€‰æ‹©å…¶ä¸­ä¹‹ä¸€ã€‚</p><p> You might critique what we&#39;ve done with it so far. The real world is massively complex, and we haven&#39;t built something which is like a human brain that can adapt to all these things. So that&#39;s a fair critique. But I think MuZero really is discovering for itself how to build a model and understand it just from first principles.</p><p> æ‚¨å¯èƒ½ä¼šæ‰¹è¯„æˆ‘ä»¬åˆ°ç›®å‰ä¸ºæ­¢æ‰€åšçš„äº‹æƒ…ã€‚ç°å®ä¸–ç•Œéå¸¸å¤æ‚ï¼Œæˆ‘ä»¬è¿˜æ²¡æœ‰å»ºç«‹åƒäººç±»å¤§è„‘é‚£æ ·å¯ä»¥é€‚åº”æ‰€æœ‰è¿™äº›ä¸œè¥¿çš„ä¸œè¥¿ã€‚å› æ­¤ï¼Œè¿™æ˜¯ä¸€ä¸ªå…¬å¹³çš„æ‰¹è¯„ã€‚ä½†æ˜¯æˆ‘è®¤ä¸ºMuZeroç¡®å®æ˜¯åœ¨ä¸ºè‡ªå·±å¯»æ‰¾å¦‚ä½•å»ºç«‹æ¨¡å‹å¹¶ä»…ä»æœ€åˆçš„åŸç†å¯¹å…¶è¿›è¡Œç†è§£çš„æ–¹æ³•ã€‚</p><p> DeepMind recently announced that it had used the technology behind AlphaZero to solve an important practical problemâ€”  predicting the shape that a protein will fold into . Where do you think MuZero will have its first big impact?</p><p> DeepMindæœ€è¿‘å®£å¸ƒï¼Œå·²åˆ©ç”¨AlphaZeroèƒŒåçš„æŠ€æœ¯è§£å†³äº†ä¸€ä¸ªé‡è¦çš„å®é™…é—®é¢˜-é¢„æµ‹è›‹ç™½è´¨å°†æŠ˜å æˆçš„å½¢çŠ¶ã€‚æ‚¨è®¤ä¸ºMuZeroå°†åœ¨å“ªé‡Œäº§ç”Ÿç¬¬ä¸€ä¸ªé‡å¤§å½±å“ï¼Ÿ</p><p>  We are, of course, looking at ways to apply MuZero to real world problems, and there are some encouraging initial results. To give a concrete example, traffic on the internet is dominated by video, and a big open problem is how to compress those videos as efficiently as possible. You can think of this as a reinforcement learning problem because there are these very complicated programs that compress the video, but what you see next is unknown. But when you plug something like MuZero into it, our initial results look very promising in terms of saving significant amounts of data, maybe something like 5 percent of the bits that are used in compressing a video.</p><p>  å½“ç„¶ï¼Œæˆ‘ä»¬æ­£åœ¨å¯»æ‰¾å°†MuZeroåº”ç”¨åˆ°ç°å®ä¸–ç•Œä¸­çš„æ–¹æ³•ï¼Œå¹¶ä¸”æœ‰ä¸€äº›ä»¤äººé¼“èˆçš„åˆæ­¥ç»“æœã€‚ä¸¾ä¸€ä¸ªå…·ä½“çš„ä¾‹å­ï¼Œäº’è”ç½‘ä¸Šçš„æµé‡ä¸»è¦æ˜¯è§†é¢‘ï¼Œè€Œä¸€ä¸ªå¼€æ”¾çš„å¤§é—®é¢˜æ˜¯å¦‚ä½•å°½å¯èƒ½æœ‰æ•ˆåœ°å‹ç¼©è¿™äº›è§†é¢‘ã€‚æ‚¨å¯ä»¥è®¤ä¸ºè¿™æ˜¯ä¸€ä¸ªå¼ºåŒ–å­¦ä¹ é—®é¢˜ï¼Œå› ä¸ºæœ‰è®¸å¤šéå¸¸å¤æ‚çš„ç¨‹åºå¯ä»¥å‹ç¼©è§†é¢‘ï¼Œä½†æ˜¯æ¥ä¸‹æ¥çœ‹åˆ°çš„æ˜¯æœªçŸ¥çš„ã€‚ä½†æ˜¯ï¼Œå½“æ‚¨å°†è¯¸å¦‚MuZeroä¹‹ç±»çš„ä¸œè¥¿æ’å…¥å…¶ä¸­æ—¶ï¼Œå°±èŠ‚çœå¤§é‡æ•°æ®è€Œè¨€ï¼Œæˆ‘ä»¬çš„åˆæ­¥ç»“æœçœ‹èµ·æ¥å¾ˆæœ‰å¸Œæœ›ï¼Œä¹Ÿè®¸å¤§çº¦å å‹ç¼©è§†é¢‘æ‰€ç”¨ä½çš„5ï¼…ã€‚</p><p> â€œThere may be this one very clear and simple way to think about all of intelligence, which is that it&#39;s a goal-optimizing system.â€</p><p> â€œå¯èƒ½æœ‰ä¸€ç§éå¸¸æ¸…æ™°å’Œç®€å•çš„æ–¹å¼æ¥è€ƒè™‘æ‰€æœ‰æ™ºèƒ½ï¼Œè¿™å°±æ˜¯å®ƒæ˜¯ä¸€ä¸ªç›®æ ‡ä¼˜åŒ–ç³»ç»Ÿã€‚â€ </p><p>   I think of a system that can help you as a user achieve your goals as effectively as possible. A really powerful system that sees all the things that you see, that has all the same senses that you have, which is able to help you achieve your goals in your life. I think that is a really important one. Another transformative one, looking long term, is something which could provide a personalized health care solution. There are privacy and ethical issues that have to be addressed, but it will have huge transformative value; it will change the face of medicine and people&#39;s quality of life.</p><p>æˆ‘è®¤ä¸ºæœ‰ä¸€ä¸ªç³»ç»Ÿå¯ä»¥å¸®åŠ©æ‚¨ä½œä¸ºç”¨æˆ·å°½å¯èƒ½æœ‰æ•ˆåœ°å®ç°æ‚¨çš„ç›®æ ‡ã€‚ä¸€ä¸ªçœŸæ­£å¼ºå¤§çš„ç³»ç»Ÿï¼Œå¯ä»¥çœ‹åˆ°æ‚¨æ‰€çœ‹åˆ°çš„æ‰€æœ‰äº‹ç‰©ï¼Œå…·æœ‰ä¸æ‚¨ç›¸åŒçš„æ„Ÿè§‰ï¼Œèƒ½å¤Ÿå¸®åŠ©æ‚¨å®ç°äººç”Ÿç›®æ ‡ã€‚æˆ‘è®¤ä¸ºé‚£æ˜¯éå¸¸é‡è¦çš„ã€‚ä»é•¿è¿œæ¥çœ‹ï¼Œå¦ä¸€ä¸ªå˜é©æ€§çš„ä¸œè¥¿å¯ä»¥æä¾›ä¸ªæ€§åŒ–çš„åŒ»ç–—ä¿å¥è§£å†³æ–¹æ¡ˆã€‚æœ‰ä¸€äº›éšç§å’Œé“å¾·é—®é¢˜éœ€è¦è§£å†³ï¼Œä½†æ˜¯å®ƒå°†å…·æœ‰å·¨å¤§çš„å˜é©ä»·å€¼ï¼›å®ƒå°†æ”¹å˜åŒ»å­¦çš„é¢è²Œå’Œäººä»¬çš„ç”Ÿæ´»è´¨é‡ã€‚</p><p>  I don&#39;t want to put a timescale on it, but I would say that everything that a human can achieve, I ultimately think that a machine can. The brain is a computational process, I don&#39;t think there&#39;s any magic going on there.</p><p>  æˆ‘ä¸æƒ³åœ¨ä¸Šé¢åŠ ä¸Šæ—¶é—´è¡¨ï¼Œä½†æ˜¯æˆ‘æƒ³è¯´äººç±»å¯ä»¥å®ç°çš„ä¸€åˆ‡ï¼Œæˆ‘æœ€ç»ˆè®¤ä¸ºæœºå™¨å¯ä»¥å®ç°ã€‚å¤§è„‘æ˜¯ä¸€ä¸ªè®¡ç®—è¿‡ç¨‹ï¼Œæˆ‘è®¤ä¸ºé‚£é‡Œæ²¡æœ‰ä»»ä½•é­”æœ¯ã€‚</p><p> Can we reach the point where we can understand and implement algorithms as effective and powerful as the human brain? Well, I don&#39;t know what the timescale is. But I think that the journey is exciting. And we should be aiming to achieve that. The first step in taking that journey is to try to understand what it even means to achieve intelligence? What problem are we trying to solve in solving intelligence?</p><p> æˆ‘ä»¬èƒ½å¦è¾¾åˆ°å¯ä»¥ç†è§£å’Œå®ç°åƒäººè„‘ä¸€æ ·æœ‰æ•ˆå’Œå¼ºå¤§çš„ç®—æ³•çš„åœ°æ­¥ï¼Ÿå¥½å§ï¼Œæˆ‘ä¸çŸ¥é“æ—¶é—´è¡¨æ˜¯å¤šå°‘ã€‚ä½†æ˜¯æˆ‘è®¤ä¸ºæ—…é€”æ˜¯ä»¤äººå…´å¥‹çš„ã€‚æˆ‘ä»¬åº”è¯¥ä»¥å®ç°è¿™ä¸€ç›®æ ‡ä¸ºç›®æ ‡ã€‚è¸ä¸Šè¿™ä¸€æ—…ç¨‹çš„ç¬¬ä¸€æ­¥æ˜¯å°è¯•äº†è§£è·å¾—æ™ºæ…§ç”šè‡³æ„å‘³ç€ä»€ä¹ˆï¼Ÿæˆ‘ä»¬åœ¨è§£å†³æ™ºåŠ›æ–¹é¢è¯•å›¾è§£å†³ä»€ä¹ˆé—®é¢˜ï¼Ÿ</p><p> Beyond practical uses, are you confident that you can go from mastering games like chess and Atari to real intelligence? What makes you think that reinforcement learning will lead to   machines with common sense understanding ?</p><p> é™¤äº†å®é™…ç”¨é€”ä¹‹å¤–ï¼Œæ‚¨æ˜¯å¦æœ‰ä¿¡å¿ƒå¯ä»¥ä»è±¡æ£‹å’ŒAtariç­‰ç²¾é€šæ¸¸æˆåˆ°çœŸæ­£çš„æ™ºåŠ›ï¼Ÿæ˜¯ä»€ä¹ˆè®©æ‚¨è®¤ä¸ºå¼ºåŒ–å­¦ä¹ å°†å¯¼è‡´å¯¹æœºå™¨å…·æœ‰å¸¸è¯†çš„ç†è§£ï¼Ÿ</p><p> There&#39;s a hypothesis, we call it the reward-is-enough hypothesis, which says that the essential process of intelligence could be as simple as a system seeking to maximize its reward, and that process of trying to achieve a goal and trying to maximize reward is enough to give rise to all the attributes of intelligence that we see in natural intelligence. It&#39;s a hypothesis, we don&#39;t know whether it is true, but it kind of gives a direction to research.</p><p> æœ‰ä¸€ä¸ªå‡è®¾ï¼Œæˆ‘ä»¬ç§°å…¶ä¸ºâ€œæŠ¥é…¬è¶³å¤Ÿâ€å‡è®¾ï¼Œè¯¥å‡è®¾è¯´ï¼Œæ™ºåŠ›çš„åŸºæœ¬è¿‡ç¨‹å¯èƒ½ä¸å¯»æ±‚æœ€å¤§åŒ–å…¶æŠ¥é…¬çš„ç³»ç»Ÿä¸€æ ·ç®€å•ï¼Œè€Œè¯•å›¾å®ç°ç›®æ ‡å¹¶å°è¯•æœ€å¤§åŒ–æŠ¥é…¬è¶³ä»¥äº§ç”Ÿæˆ‘ä»¬åœ¨è‡ªç„¶æ™ºèƒ½ä¸­çœ‹åˆ°çš„æ‰€æœ‰æ™ºèƒ½å±æ€§ã€‚è¿™æ˜¯ä¸€ä¸ªå‡è®¾ï¼Œæˆ‘ä»¬ä¸çŸ¥é“å®ƒæ˜¯å¦æ­£ç¡®ï¼Œä½†è¿™ä¸ºç ”ç©¶æä¾›äº†æ–¹å‘ã€‚</p><p> If we take common sense specifically, the reward-is-enough hypothesis says well, if common sense is useful to a system, that means it should actually help it to better achieve its goals.</p><p> å¦‚æœæˆ‘ä»¬å…·ä½“åœ°ç†è§£å¸¸è¯†ï¼Œé‚£ä¹ˆâ€œæŠ¥é…¬è¶³å¤Ÿâ€å‡è®¾å°±å¾ˆå¥½åœ°è¯´æ˜äº†è¿™ä¸€ç‚¹ï¼Œå¦‚æœå¸¸è¯†å¯¹ç³»ç»Ÿæœ‰ç”¨ï¼Œåˆ™æ„å‘³ç€å®ƒå®é™…ä¸Šåº”è¯¥å¸®åŠ©å®ƒæ›´å¥½åœ°å®ç°å…¶ç›®æ ‡ã€‚</p><p> It sounds like you think that your area of expertiseâ€”reinforcement learningâ€”is in some sense fundamental to understanding, or â€œsolving,â€ intelligence. Is that right?</p><p> å¬èµ·æ¥æ‚¨è®¤ä¸ºæ‚¨çš„ä¸“é•¿é¢†åŸŸ-å¼ºåŒ–å­¦ä¹ -åœ¨æŸç§æ„ä¹‰ä¸Šæ˜¯ç†è§£æˆ–â€œè§£å†³â€æ™ºåŠ›çš„åŸºç¡€ã€‚æ˜¯å¯¹çš„å—ï¼Ÿ </p><p>  I really see it as very essential. I think the big question is, is it true? Because it certainly flies in the face of how a lot of people view AI, which is that there&#39;s this incredibly complex collection of mechanisms involved in intelligence, and each one of them has its own kind of problem that itâ€™s solving or its own special way of working, or maybe there&#39;s not even any clear problem definition at all for something like common sense. This theory says, no, actually there may be this one very clear and simple way to think about all of intelligence, which is that it&#39;s a goal-optimizing system, and that if we find the way to optimize goals really, really well, then all of these other things will will will emerge from that process.</p><p>æˆ‘çœŸçš„è®¤ä¸ºè¿™æ˜¯éå¸¸å¿…è¦çš„ã€‚æˆ‘è®¤ä¸ºæœ€å¤§çš„é—®é¢˜æ˜¯ï¼Œè¿™æ˜¯çœŸçš„å—ï¼Ÿå› ä¸ºå®ƒè‚¯å®šä¼šé¢å¯¹å¾ˆå¤šäººå¦‚ä½•çœ‹å¾…AIï¼Œè¿™å°±æ˜¯æƒ…æŠ¥ä¸­æ¶‰åŠåˆ°çš„è¿™ç§æå…¶å¤æ‚çš„æœºåˆ¶é›†åˆï¼Œå¹¶ä¸”æ¯ä¸ªæœºåˆ¶éƒ½æœ‰å…¶è‡ªå·±è¦è§£å†³æˆ–è§£å†³çš„ç§ç§é—®é¢˜ã€‚è‡ªå·±çš„ç‰¹æ®Šå·¥ä½œæ–¹å¼ï¼Œæˆ–è€…ç”šè‡³æ ¹æœ¬æ²¡æœ‰é’ˆå¯¹å¸¸è¯†ä¹‹ç±»çš„æ˜ç¡®é—®é¢˜å®šä¹‰ã€‚è¿™ä¸ªç†è®ºè¯´ï¼Œä¸ï¼Œå®é™…ä¸Šå¯èƒ½å­˜åœ¨ç€ä¸€ç§éå¸¸æ¸…æ™°ï¼Œç®€å•çš„æ–¹å¼æ¥è€ƒè™‘æ‰€æœ‰æ™ºèƒ½ï¼Œè¿™å°±æ˜¯å®ƒæ˜¯ä¸€ä¸ªç›®æ ‡ä¼˜åŒ–ç³»ç»Ÿï¼Œå¹¶ä¸”å¦‚æœæˆ‘ä»¬çœŸçš„æ‰¾åˆ°äº†ä¸€ç§ä¼˜åŒ–ç›®æ ‡çš„æ–¹æ³•ï¼Œå¥½å§ï¼Œé‚£ä¹ˆæ‰€æœ‰å…¶ä»–è¿™äº›äº‹æƒ…å°†åœ¨è¯¥è¿‡ç¨‹ä¸­æ˜¾ç°å‡ºæ¥ã€‚</p><p>  Reinforcement learning has been around for decades, but for a while it seemed like a dead end. One of your old advisers in fact told me that she tried to dissuade you from working on it. Why did you ignore her and keep going?</p><p>  å¼ºåŒ–å­¦ä¹ å·²ç»å­˜åœ¨äº†æ•°åå¹´ï¼Œä½†æœ‰ä¸€æ®µæ—¶é—´ä¼¼ä¹æ˜¯æ­»èƒ¡åŒã€‚å®é™…ä¸Šï¼Œæ‚¨çš„ä¸€ä½è€é¡¾é—®å‘Šè¯‰æˆ‘ï¼Œå¥¹è¯•å›¾åŠé˜»æ‚¨ä¸è¦è¿™æ ·åšã€‚ä½ ä¸ºä»€ä¹ˆä¸ç†herå¥¹å¹¶ç»§ç»­å‰è¿›ï¼Ÿ</p><p> Many people view reinforcement learning as one of many hammers that you could apply to solve the many problems that we need to solve in AI. I don&#39;t view it that way. I view reinforcement learning as the whole thing. If we want to try and describe intelligence as best as possible, I think reinforcement learning essentially characterizes what we really mean by intelligence. And once you start to see it that way, it&#39;s like, how can I not work on this? If this really is the thing that is closest to what we mean by intelligenceâ€”if we solve it, we will crack that.</p><p> è®¸å¤šäººå°†å¼ºåŒ–å­¦ä¹ è§†ä¸ºæ‚¨å¯ä»¥ç”¨æ¥è§£å†³æˆ‘ä»¬åœ¨AIä¸­éœ€è¦è§£å†³çš„è®¸å¤šé—®é¢˜çš„ä¼—å¤šé”¤å­ä¹‹ä¸€ã€‚æˆ‘ä¸è¿™æ ·çœ‹ã€‚æˆ‘å°†å¼ºåŒ–å­¦ä¹ è§†ä¸ºæ•´ä½“ã€‚å¦‚æœæˆ‘ä»¬æƒ³å°è¯•å¹¶å°½å¯èƒ½åœ°æè¿°æ™ºåŠ›ï¼Œæˆ‘è®¤ä¸ºå¼ºåŒ–å­¦ä¹ ä»æœ¬è´¨ä¸Šæè¿°äº†æˆ‘ä»¬å¯¹æ™ºåŠ›çš„çœŸæ­£ç†è§£ã€‚å½“æ‚¨å¼€å§‹ä»¥è¿™ç§æ–¹å¼çœ‹åˆ°å®ƒæ—¶ï¼Œæˆ‘è¯¥å¦‚ä½•å¤„ç†å‘¢ï¼Ÿå¦‚æœè¿™ç¡®å®æ˜¯æœ€æ¥è¿‘æˆ‘ä»¬çš„æ™ºèƒ½å«ä¹‰çš„äº‹ç‰©ï¼Œé‚£ä¹ˆï¼Œå¦‚æœæˆ‘ä»¬è§£å†³å®ƒï¼Œæˆ‘ä»¬å°†äºˆä»¥ç ´è§£ã€‚</p><p>  If you look at the work I&#39;ve done, Iâ€™ve consistently tried to focus on that problem. When tackling things like Go, in solving it, we learn about what intelligence means in the process. You can think of reinforcement learning as the ability that enables an agent to acquire all other abilitiesâ€”all the other pieces of intelligence that it needs . You see a little bit of that in something like AlphaGo, where all we asked it to do was to win games, and yet it learned all these thingsâ€”endgames and openingsâ€”that people used to have specialized subsystems for.</p><p>  å¦‚æœæ‚¨çœ‹ä¸€ä¸‹æˆ‘æ‰€åšçš„å·¥ä½œï¼Œé‚£ä¹ˆæˆ‘ä¸€ç›´éƒ½åœ¨åŠªåŠ›è§£å†³è¿™ä¸ªé—®é¢˜ã€‚è§£å†³è¯¸å¦‚Goä¹‹ç±»çš„é—®é¢˜æ—¶ï¼Œåœ¨è§£å†³å®ƒæ—¶ï¼Œæˆ‘ä»¬äº†è§£äº†æ™ºèƒ½åœ¨æ­¤è¿‡ç¨‹ä¸­æ„å‘³ç€ä»€ä¹ˆã€‚æ‚¨å¯ä»¥å°†å¼ºåŒ–å­¦ä¹ è§†ä¸ºä½¿ä»£ç†èƒ½å¤Ÿè·å¾—æ‰€æœ‰å…¶ä»–èƒ½åŠ›ï¼ˆå®ƒéœ€è¦çš„æ‰€æœ‰å…¶ä»–æ™ºèƒ½ï¼‰çš„èƒ½åŠ›ã€‚æ‚¨ä¼šåœ¨AlphaGoä¹‹ç±»çš„äº§å“ä¸­çœ‹åˆ°ä¸€ç‚¹ç‚¹ï¼Œæˆ‘ä»¬è¦æ±‚å®ƒåšçš„å°±æ˜¯èµ¢å¾—æ¯”èµ›ï¼Œä½†å®ƒäº†è§£äº†äººä»¬è¿‡å»æ›¾ç»æ‹¥æœ‰ä¸“é—¨å­ç³»ç»Ÿçš„æ‰€æœ‰è¿™äº›ä¸œè¥¿-æ¯”èµ›ç»“æŸå’Œå¼€å±€ã€‚</p><p> Is there pressure at DeepMind to do another big demonstration, something like AlphaGo? Do you feel that at all?</p><p> DeepMindæ˜¯å¦æœ‰å‹åŠ›è¿›è¡Œå¦ä¸€ä¸ªå¤§å‹å±•ç¤ºï¼Œä¾‹å¦‚AlphaGoï¼Ÿä½ æœ‰æ„Ÿè§‰å—ï¼Ÿ</p><p> That&#39;s a great question. I feel that we&#39;re in a really privileged position in the sense that we are secure in our positions, in our funding, all of these things are very, very secure.</p><p> è¿™æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„é—®é¢˜ã€‚æˆ‘è§‰å¾—æˆ‘ä»¬å¤„äºéå¸¸ç‰¹æƒçš„ä½ç½®ï¼Œå› ä¸ºæˆ‘ä»¬åœ¨ä½ç½®ä¸Šï¼Œèµ„é‡‘ä¸Šéƒ½æ˜¯å®‰å…¨çš„ï¼Œæ‰€æœ‰è¿™äº›äº‹æƒ…éƒ½æ˜¯éå¸¸éå¸¸å®‰å…¨çš„ã€‚</p><p> The only pressure for trying to build a new, big demonstration is the drive to make progress towards general intelligence. Itâ€™s a real privilege that you don&#39;t have when you&#39;re either in a startup and trying to secure your funding, or in academia, where you&#39;re trying to secure your grants and so forth.</p><p> è¯•å›¾å»ºç«‹ä¸€ä¸ªæ–°çš„å¤§å‹ç¤ºèŒƒçš„å”¯ä¸€å‹åŠ›æ˜¯æœç€é€šç”¨æƒ…æŠ¥è¿ˆè¿›çš„åŠ¨åŠ›ã€‚å½“æ‚¨åœ¨åˆåˆ›ä¼ä¸šä¸­å°è¯•è·å¾—èµ„é‡‘æ—¶ï¼Œæˆ–è€…åœ¨å­¦æœ¯ç•Œä¸­å°è¯•è·å¾—è¡¥åŠ©é‡‘ç­‰æ—¶ï¼Œè¿™æ˜¯æ‚¨æ²¡æœ‰çš„çœŸæ­£ç‰¹æƒã€‚ </p><p> Powerful AI systems now require enormous amounts of computer power to work. Are you worried that this will hold progress back?</p><p>å¼ºå¤§çš„AIç³»ç»Ÿç°åœ¨éœ€è¦å¤§é‡çš„è®¡ç®—æœºåŠŸèƒ½æ‰èƒ½å·¥ä½œã€‚æ‚¨æ˜¯å¦æ‹…å¿ƒè¿™ä¼šé˜»ç¢è¿›åº¦ï¼Ÿ</p><p>  To bring this back to MuZero, it is an example of an algorithm that scales very well and gracefully with computation. We ran an experiment in Atari, where we showed that even using a very modest amount of computeâ€”roughly equivalent to one GPU for a couple of weeksâ€”it works really, really well, and you get performance that far exceeds a human.</p><p>  ä¸ºäº†å°†å…¶å¸¦å›MuZeroï¼Œå®ƒæ˜¯ç®—æ³•çš„ä¸€ä¸ªç¤ºä¾‹ï¼Œå¯ä»¥å¾ˆå¥½åœ°æ‰©å±•è®¡ç®—ã€‚æˆ‘ä»¬åœ¨Atariè¿›è¡Œäº†ä¸€é¡¹å®éªŒï¼Œç»“æœè¡¨æ˜å³ä½¿ä½¿ç”¨éå¸¸å°‘é‡çš„è®¡ç®—ï¼ˆå¤§çº¦ç›¸å½“äºä¸€ä¸ªGPUæ•°å‘¨çš„æ—¶é—´ï¼‰ï¼Œå®ƒçš„æ•ˆæœä¹Ÿéå¸¸å¥½ï¼Œè€Œä¸”æ‚¨è·å¾—çš„æ€§èƒ½è¿œè¿œè¶…è¿‡äº†äººç±»ã€‚</p><p> There are some figures that suggest if you add up all the compute power that you can leverage right now we&#39;re reaching something comparable to the human brain. So it&#39;s probably more us needing to come up with smarter algorithms.</p><p> æœ‰ä¸€äº›æ•°å­—è¡¨æ˜ï¼Œå¦‚æœæ‚¨å°†ç°åœ¨å¯ä»¥åˆ©ç”¨çš„æ‰€æœ‰è®¡ç®—èƒ½åŠ›åŠ åœ¨ä¸€èµ·ï¼Œæˆ‘ä»¬å°†è¾¾åˆ°ä¸äººè„‘å¯æ¯”çš„æ°´å¹³ã€‚å› æ­¤ï¼Œå¯èƒ½æ›´å¤šçš„æ˜¯æˆ‘ä»¬éœ€è¦æå‡ºæ›´æ™ºèƒ½çš„ç®—æ³•ã€‚</p><p> But the beauty of MuZero is that because it&#39;s building its own model, it&#39;s starting to understand how the world worksâ€”to imagine things. And that imagination is a way that you can actually leverage computation to start to look ahead, imagine what might happen next.</p><p> ä½†æ˜¯MuZeroçš„ä¼˜ç‚¹åœ¨äºï¼Œå› ä¸ºå®ƒæ­£åœ¨å»ºç«‹è‡ªå·±çš„æ¨¡å‹ï¼Œæ‰€ä»¥å®ƒå¼€å§‹äº†è§£ä¸–ç•Œæ˜¯å¦‚ä½•è¿è½¬çš„-æƒ³è±¡äº‹ç‰©ã€‚è¿™ç§æƒ³è±¡åŠ›æ˜¯æ‚¨å®é™…ä¸Šå¯ä»¥åˆ©ç”¨è®¡ç®—å¼€å§‹å±•æœ›æœªæ¥ï¼Œæƒ³è±¡æ¥ä¸‹æ¥ä¼šå‘ç”Ÿä»€ä¹ˆçš„ä¸€ç§æ–¹å¼ã€‚</p><p> Some military contractors are using reinforcement learning to   build better weapons systems . How do you feel about that? Do you ever think that some of your work should not be published openly?</p><p> ä¸€äº›å†›äº‹æ‰¿åŒ…å•†æ­£åœ¨åˆ©ç”¨å¼ºåŒ–å­¦ä¹ æ¥å»ºç«‹æ›´å¥½çš„æ­¦å™¨ç³»ç»Ÿã€‚ä½ å¯¹è¿™ä»¶äº‹æœ‰ä»€ä¹ˆæ„Ÿæƒ³ï¼Ÿæ‚¨æ˜¯å¦æ›¾ç»è®¤ä¸ºæ‚¨çš„æŸäº›ä½œå“ä¸åº”è¯¥å…¬å¼€å‘è¡¨ï¼Ÿ</p><p> I oppose the use of AI in any deadly weapon, and I wish we had made more progress toward a  ban on lethal autonomous weapons. DeepMind and its co-founders are signatories of the  Lethal Autonomous Weapons Pledge, which outlines the companyâ€™s belief in the principle that offensive technology should always remain under appropriate human control.</p><p> æˆ‘åå¯¹åœ¨ä»»ä½•è‡´å‘½æ­¦å™¨ä¸­ä½¿ç”¨AIï¼Œå¹¶å¸Œæœ›æˆ‘ä»¬åœ¨ç¦æ­¢è‡´å‘½è‡ªåŠ¨æ­¦å™¨æ–¹é¢å–å¾—æ›´å¤§è¿›å±•ã€‚ DeepMindåŠå…¶è”åˆåˆ›å§‹äººæ˜¯ã€Šè‡´å‘½è‡ªåŠ¨æ­¦å™¨æ‰¿è¯ºã€‹çš„ç­¾ç½²æ–¹ï¼Œè¯¥æ‰¿è¯ºæ¦‚è¿°äº†å…¬å¸å¯¹è¿›æ”»æ€§æŠ€æœ¯åº”å§‹ç»ˆåœ¨é€‚å½“çš„äººä¸ºæ§åˆ¶ä¸‹çš„ä¿¡å¿µã€‚</p><p> However, we continue to believe that the appropriate publication of our methods is a cornerstone of science and that the development of general-purpose AI algorithms will lead to greater overall societal benefit across a raft of positive applications.</p><p> ä½†æ˜¯ï¼Œæˆ‘ä»¬ä»ç„¶è®¤ä¸ºï¼Œé€‚å½“åœ°å‘å¸ƒæˆ‘ä»¬çš„æ–¹æ³•æ˜¯ç§‘å­¦çš„åŸºçŸ³ï¼Œé€šç”¨AIç®—æ³•çš„å¼€å‘å°†åœ¨ä¼—å¤šç§¯æåº”ç”¨ä¸­å¸¦æ¥æ›´å¤§çš„æ€»ä½“ç¤¾ä¼šæ•ˆç›Šã€‚ </p><p>   ğŸ§ Things not sounding right? Check out our favorite  wireless headphones,  soundbars, and  Bluetooth speakers</p><p>ğŸ§å¬èµ·æ¥ä¸å¯¹å—ï¼Ÿ æŸ¥çœ‹æˆ‘ä»¬æœ€å–œæ¬¢çš„æ— çº¿è€³æœºï¼Œæ¡å½¢éŸ³ç®±å’Œè“ç‰™æ‰¬å£°å™¨ </p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://www.wired.com/story/what-alphago-teach-how-people-learn">https://www.wired.com/story/what-alphago-teach-how-people-learn</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/ç§‘å­¦å®¶/">#ç§‘å­¦å®¶</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/ç ”ç©¶/">#ç ”ç©¶</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/silver/">#silver</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/muzero/">#muzero</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/è®¾è®¡/">#è®¾è®¡</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/åˆ›æ„/">#åˆ›æ„</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/æ‘„å½±/">#æ‘„å½±</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/æ¸¸æˆ/">#æ¸¸æˆ</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/å›¾ç‰‡/">#å›¾ç‰‡</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/è½¯ä»¶/">#è½¯ä»¶</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/è§†é¢‘/">#è§†é¢‘</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/æ‰‹æœº/">#æ‰‹æœº</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/å¹¿å‘Š/">#å¹¿å‘Š</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/ç½‘ç«™/">#ç½‘ç«™</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/å…è´¹/">#å…è´¹</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/ä¸‹è½½/">#ä¸‹è½½</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/è‹¹æœ/">#è‹¹æœ</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/å¾®è½¯/">#å¾®è½¯</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/éŸ³ä¹/">#éŸ³ä¹</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/åšå®¢/">#åšå®¢</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/æ¶æ/">#æ¶æ</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/è‰ºæœ¯/">#è‰ºæœ¯</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/å·¥å…·/">#å·¥å…·</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/åˆ†äº«/">#åˆ†äº«</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy; 2020 diglog.com </div></div></body></html>