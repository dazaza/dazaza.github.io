<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>ä¸ºä»€ä¹ˆè§†é¢‘æ¸¸æˆå›¾å½¢ä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ï¼Ÿ Why are video games graphics (still) a challenge?</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">Why are video games graphics (still) a challenge?<br/>ä¸ºä»€ä¹ˆè§†é¢‘æ¸¸æˆå›¾å½¢ä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ï¼Ÿ </h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2020-12-29 04:45:08</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2020/12/0306f97c9c65c94779062edd566317cd.png"><img src="http://img2.diglog.com/img/2020/12/0306f97c9c65c94779062edd566317cd.png" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>This post will cover challenges and aspects of production to consider when creating new rendering / graphics techniques and algorithms â€“ especially in the context of  applied research for real time rendering. I will base this on my personal experiences, working on  Witcher 2, Assassinâ€™s Creed 4: Black Flag, Far Cry 4, and God of War.</p><p>è¿™ç¯‡æ–‡ç« å°†æ¶µç›–åˆ›å»ºæ–°çš„æ¸²æŸ“/å›¾å½¢æŠ€æœ¯å’Œç®—æ³•æ—¶è¦è€ƒè™‘çš„æŒ‘æˆ˜å’Œç”Ÿäº§æ–¹é¢ï¼Œå°¤å…¶æ˜¯åœ¨å®æ—¶æ¸²æŸ“çš„åº”ç”¨ç ”ç©¶ä¸­ã€‚æˆ‘å°†åŸºäºæˆ‘çš„ä¸ªäººç»éªŒï¼Œåœ¨ã€Šå·«å¸ˆ2ã€‹ï¼Œã€Šåˆºå®¢ä¿¡æ¡4ï¼šé»‘æ——ã€‹ï¼Œã€Šå­¤å²›æƒŠé­‚4ã€‹å’Œã€Šæˆ˜ç¥ã€‹ä¸­å·¥ä½œã€‚</p><p> Many of those challenges are easily ignored â€“ they are  real problems in production, but not necessarily there only if you only read about those techniques, or if you work on pure research, writing papers, or create tech demos.</p><p> è¿™äº›æŒ‘æˆ˜ä¸­æœ‰è®¸å¤šå¾ˆå®¹æ˜“è¢«å¿½ç•¥-å®ƒä»¬æ˜¯ç”Ÿäº§ä¸­çš„å®é™…é—®é¢˜ï¼Œä½†åªæœ‰å½“æ‚¨ä»…äº†è§£è¿™äº›æŠ€æœ¯ï¼Œæˆ–è€…æ‚¨ä»äº‹çº¯ç ”ç©¶ï¼Œæ’°å†™è®ºæ–‡æˆ–åˆ›å»ºæŠ€æœ¯æ¼”ç¤ºæ—¶ï¼Œå¹¶ä¸ä¸€å®šå­˜åœ¨ã€‚</p><p> I have seen statements like â€œwhy is this brilliant research technique X not used in production?â€ both from gamers, but also from my colleagues with academic background. And there are always some good reasons!</p><p> æˆ‘çœ‹åˆ°è¿‡è¿™æ ·çš„é™ˆè¿°ï¼šâ€œä¸ºä»€ä¹ˆè¿™ç§å‡ºè‰²çš„ç ”ç©¶æŠ€æœ¯Xä¸åœ¨ç”Ÿäº§ä¸­ä½¿ç”¨ï¼Ÿâ€æ—¢æ¥è‡ªæ¸¸æˆç©å®¶ï¼Œä¹Ÿæ¥è‡ªå…·æœ‰å­¦æœ¯èƒŒæ™¯çš„åŒäº‹ã€‚æ€»æ˜¯æœ‰ä¸€äº›å¾ˆå¥½çš„ç†ç”±ï¼</p><p> The post is also inspired by  my joke tweet from a while ago about appearing smart and mature as a graphics programmer by â€œdismissingâ€ most of the rendering techniques â€“ that they are not going to work on foliage. ğŸ™‚Â And yes, I will come back to vegetation rendering a few times in this post.</p><p> è¿™ç¯‡æ–‡ç« è¿˜å—åˆ°æˆ‘å‰æ®µæ—¶é—´åœ¨æˆ‘çš„ç©ç¬‘æ¨æ–‡ä¸­çš„å¯å‘ï¼Œè¯¥æ¨æ–‡æ˜¯é€šè¿‡â€œå–æ¶ˆâ€å¤§å¤šæ•°æ¸²æŸ“æŠ€æœ¯æ¥ä½¿ä»–ä»¬æˆä¸ºå›¾å½¢ç¨‹åºå‘˜è€Œå˜å¾—èªæ˜æˆç†Ÿçš„ï¼Œå› ä¸ºè¿™äº›æ¸²æŸ“æŠ€æœ¯ä¸ä¼šåœ¨å¶å­ä¸Šèµ·ä½œç”¨ã€‚ yesæ˜¯çš„ï¼Œåœ¨è¿™ç¯‡æ–‡ç« ä¸­æˆ‘å°†å†æ¬¡å›åˆ°æ¤è¢«æ¸²æŸ“ã€‚</p><p> I tend to think of this topic as well when I hear discussions about how â€œphotogrammetry, raytracing, neural rendering, [insert any other new how topic] will be a universal answer to rendering and replace everything!â€. Spoiler alert: not gonna happen (soon).</p><p> å½“æˆ‘å¬åˆ°æœ‰å…³â€œæ‘„å½±æµ‹é‡ï¼Œå…‰çº¿è¿½è¸ªï¼Œç¥ç»æ¸²æŸ“ï¼Œ[æ’å…¥ä»»ä½•å…¶ä»–æ–°ä¸»é¢˜â€å°†å¦‚ä½•æˆä¸ºæ¸²æŸ“å’Œæ›¿æ¢æ‰€æœ‰å†…å®¹çš„é€šç”¨ç­”æ¡ˆâ€çš„è®¨è®ºæ—¶ï¼Œæˆ‘ä¹Ÿä¼šæƒ³åˆ°è¿™ä¸ªä¸»é¢˜ã€‚å‰§é€è­¦æŠ¥ï¼šä¸ä¼šï¼ˆå¾ˆå¿«ï¼‰å‘ç”Ÿã€‚</p><p>   Rendering engineers, especially ones earlier in their career â€“ who havenâ€™t built their intuition yet,</p><p>   æ¸²æŸ“å·¥ç¨‹å¸ˆï¼Œå°¤å…¶æ˜¯åœ¨èŒä¸šç”Ÿæ¶¯æ—©æœŸçš„å·¥ç¨‹å¸ˆï¼Œä»–ä»¬è¿˜æ²¡æœ‰å»ºç«‹ç›´è§‰ï¼Œ</p><p>   People who are excited and care about game graphics (or real time graphics in general) and would like to understand a bit â€œhow sausages are madeâ€. Some concepts might be too technical, but then feel free to skip those.</p><p>   é‚£äº›å¯¹æ¸¸æˆå›¾å½¢ï¼ˆæˆ–ä¸€èˆ¬æ¥è¯´æ˜¯å®æ—¶å›¾å½¢ï¼‰æ„Ÿåˆ°å…´å¥‹å’Œå…³å¿ƒçš„äººï¼Œå¹¶ä¸”æƒ³äº†è§£ä¸€ç‚¹â€œé¦™è‚ çš„åˆ¶ä½œæ–¹æ³•â€ã€‚æœ‰äº›æ¦‚å¿µå¯èƒ½å¤ªæŠ€æœ¯æ€§ï¼Œä½†æ˜¯å¯ä»¥éšæ—¶è·³è¿‡è¿™äº›æ¦‚å¿µã€‚ </p><p> Note that I didnâ€™t place â€œpureâ€ academic researchers in the above list â€“ as I donâ€™t think that pure research should be considering too many obstacles. Role of the fundamental research is inspiration and creating theory that can be later productionized by people who are experts in productionization.</p><p>è¯·æ³¨æ„ï¼Œæˆ‘æ²¡æœ‰å°†â€œçº¯ç²¹çš„â€å­¦æœ¯ç ”ç©¶äººå‘˜æ”¾åœ¨ä¸Šé¢çš„åˆ—è¡¨ä¸­-å› ä¸ºæˆ‘ä¸è®¤ä¸ºçº¯ç²¹çš„ç ”ç©¶åº”è¯¥è€ƒè™‘å¤ªå¤šçš„éšœç¢ã€‚åŸºç¡€ç ”ç©¶çš„ä½œç”¨æ˜¯å¯å‘å’Œåˆ›é€ ç†è®ºï¼Œè¿™äº›ç†è®ºä»¥åå¯ä»¥ç”±ç”Ÿäº§ä¸“å®¶æ¥ç”Ÿäº§ã€‚</p><p> But if you are a pure researcher and somehow got here, Iâ€™ll be happy if youâ€™re interested in what kinds of problems might be on the long way from idea or paper to a product (and  why most new genuinely good research will never find its place in products).</p><p> ä½†æ˜¯ï¼Œå¦‚æœæ‚¨æ˜¯ä¸€ä¸ªçº¯ç²¹çš„ç ”ç©¶äººå‘˜å¹¶ä¸”ä»¥æŸç§æ–¹å¼æ¥åˆ°äº†è¿™é‡Œï¼Œå¦‚æœæ‚¨å¯¹ä»æ„æ€æˆ–è®ºæ–‡åˆ°äº§å“çš„æ¼«é•¿è¿‡ç¨‹ä¸­å¯èƒ½ä¼šé‡åˆ°å“ªäº›é—®é¢˜æ„Ÿå…´è¶£ï¼Œä»¥åŠä¸ºä»€ä¹ˆå¤§å¤šæ•°æ–°çš„çœŸæ­£ä¼˜ç§€çš„ç ”ç©¶æ°¸è¿œä¸ä¼šæ‰¾åˆ°å®ƒåœ¨äº§å“ä¸­çš„ä½ç½®ï¼‰ã€‚</p><p>  Very important note â€“  none of the â€œobstaclesâ€ I am going to describe  are deal breakers.</p><p>  éå¸¸é‡è¦çš„è¯´æ˜â€“æˆ‘è¦æè¿°çš„â€œéšœç¢â€éƒ½ä¸æ˜¯ç ´åäº¤æ˜“çš„å› ç´ ã€‚</p><p> Far from it â€“ most successful tech that became state of the art violates many of those constraints! It simply means that those are challenges that will need to be overcome in some way â€“ manual workarounds, feature exclusivity, ignoring the problems, or applying them only in specific cases.</p><p> è¿œéå¦‚æ­¤-æˆä¸ºæœ€å…ˆè¿›æŠ€æœ¯çš„æœ€æˆåŠŸçš„æŠ€æœ¯è¿åäº†è®¸å¤šé™åˆ¶ï¼è¿™ä»…æ„å‘³ç€è¿™äº›æŒ‘æˆ˜å°†éœ€è¦ä»¥æŸç§æ–¹å¼åŠ ä»¥å…‹æœ-æ‰‹åŠ¨è§£å†³æ–¹æ³•ï¼ŒåŠŸèƒ½ç‹¬å ï¼Œå¿½ç•¥é—®é¢˜æˆ–ä»…åœ¨ç‰¹å®šæƒ…å†µä¸‹åº”ç”¨ã€‚</p><p> I am going to describe first the  use-cases â€“ potential uses of the technology and how those impact potential requirements and constraints.</p><p> æˆ‘å°†é¦–å…ˆæè¿°ç”¨ä¾‹-æŠ€æœ¯çš„æ½œåœ¨ç”¨é€”ä»¥åŠå®ƒä»¬å¦‚ä½•å½±å“æ½œåœ¨çš„éœ€æ±‚å’Œçº¦æŸã€‚</p><p>  The categories of â€œuse casesâ€ deserve some explanation and description of â€œseverityâ€ of their constraints.</p><p>  â€œç”¨ä¾‹â€ç±»åˆ«åº”å¯¹å…¶çº¦æŸçš„â€œä¸¥é‡æ€§â€è¿›è¡Œä¸€äº›è§£é‡Šå’Œæè¿°ã€‚</p><p>  Tech demo is the easiest category. If your whole product is a  demonstration of a given technique (whether for benchmarking, showing off some new research, artistic demoscene), most of the considerations go away.</p><p>  æŠ€æœ¯æ¼”ç¤ºæ˜¯æœ€ç®€å•çš„ç±»åˆ«ã€‚å¦‚æœæ‚¨çš„æ•´ä¸ªäº§å“éƒ½æ˜¯ç»™å®šæŠ€æœ¯çš„æ¼”ç¤ºï¼ˆæ— è®ºæ˜¯ç”¨äºåŸºå‡†æµ‹è¯•ï¼Œå±•ç¤ºä¸€äº›æ–°ç ”ç©¶ï¼Œè‰ºæœ¯æ¼”ç¤ºï¼‰ï¼Œåˆ™å¤§å¤šæ•°è€ƒè™‘éƒ½å°†æ¶ˆå¤±ã€‚ </p><p> You can actually retrofit everything: from the demo concept, art itself, camera trajectory to show off the technology the best and avoid any problems.</p><p>å®é™…ä¸Šï¼Œæ‚¨å¯ä»¥è¿›è¡Œæ‰€æœ‰æ”¹è£…ï¼šä»æ¼”ç¤ºæ¦‚å¿µï¼Œè‰ºæœ¯å“æœ¬èº«ï¼Œç…§ç›¸æœºè½¨è¿¹åˆ°æœ€ä½³å±•ç¤ºæŠ€æœ¯ï¼Œé¿å…å‡ºç°ä»»ä½•é—®é¢˜ã€‚</p><p> The main considerations will be around performance (a choppy tech demo can be seen as a tech failure) and working very closely with artists able to show it off.</p><p> ä¸»è¦è€ƒè™‘å› ç´ å°†å›´ç»•æ€§èƒ½ï¼ˆä¸ç¨³å®šçš„æŠ€æœ¯æ¼”ç¤ºå¯è¢«è§†ä¸ºæŠ€æœ¯å¤±è´¥ï¼‰ï¼Œå¹¶ä¸èƒ½å¤Ÿè¿›è¡Œå±•ç¤ºçš„è‰ºæœ¯å®¶ç´§å¯†åˆä½œã€‚</p><p> The rest? Hack away, write one-off code â€“ just donâ€™t have expectations that turning a tech demo into a production ready feature is simple or easy (itâ€™s more like the 99% of work remaining).</p><p> å…¶ä½™çš„éƒ¨åˆ†ï¼Ÿè½»æ¾å®Œæˆï¼Œç¼–å†™ä¸€æ¬¡æ€§ä»£ç â€“åªæ˜¯ä¸æœŸæœ›å°†æŠ€æœ¯æ¼”ç¤ºè½¬æ¢ä¸ºå¯ç”¨äºç”Ÿäº§çš„åŠŸèƒ½æ—¢ç®€å•åˆå®¹æ˜“ï¼ˆæ›´åƒæ˜¯å‰©ä½™çš„99ï¼…çš„å·¥ä½œï¼‰ã€‚</p><p>  The next level â€œupâ€ in the difficulty is creating some  special features that are one-off. It can be some visual special effect happening in a single scene, game intro, or a single level that is different from the other ones. In this case, a feature doesnâ€™t need to be very â€œrobustâ€, and often replaces many others.</p><p>  éš¾åº¦çš„ä¸‹ä¸€ä¸ªâ€œæå‡â€æ˜¯åˆ›å»ºä¸€äº›ä¸€æ¬¡æ€§çš„ç‰¹æ®ŠåŠŸèƒ½ã€‚å¯èƒ½æ˜¯æŸäº›è§†è§‰ç‰¹æ®Šæ•ˆæœå‘ç”Ÿåœ¨å•ä¸ªåœºæ™¯ï¼Œæ¸¸æˆä»‹ç»æˆ–ä¸å…¶ä»–åœºæ™¯ä¸åŒçš„å•ä¸ªå…³å¡ä¸­ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼ŒåŠŸèƒ½ä¸å¿…å¤ªâ€œå¥å£®â€ï¼Œè€Œé€šå¸¸å¯ä»¥æ›¿ä»£è®¸å¤šå…¶ä»–åŠŸèƒ½ã€‚</p><p> An example could be lighting in the jungle levels in Assassinâ€™s Creed 4: Black Flag that I worked on.</p><p> ä¾‹å¦‚ï¼Œæˆ‘åœ¨ã€Šåˆºå®¢ä¿¡æ¡4ï¼šé»‘æ——ã€‹ä¸­ä¸›æ—ä¸­çš„ç…§æ˜ã€‚</p><p>  Jungles were â€œcut offâ€ from the rest of the open world by special streaming corridors and we completely replaced the whole lighting in them! Instead of relying on tree shadow maps and global lighting, we created  fake â€œcausticsâ€ that looked much softer and played very nicely with our volumetric lighting / atmospherics system. They not only looked better, but also were much faster â€“ obviously worked only because of those special conditions.</p><p>  ä¸›æ—é€šè¿‡ç‰¹æ®Šçš„æ°´æµèµ°å»Šä¸å…¶ä»–å¼€æ”¾ä¸–ç•Œâ€œéš”ç¦»â€ï¼Œæˆ‘ä»¬å®Œå…¨æ›¿æ¢äº†å…¶ä¸­çš„æ•´ä¸ªç…§æ˜ï¼æˆ‘ä»¬æ²¡æœ‰ä¾èµ–æ ‘å½±åœ°å›¾å’Œå…¨å±€ç…§æ˜ï¼Œè€Œæ˜¯åˆ›å»ºäº†ä¼ªé€ çš„â€œç„¦æ•£â€ï¼Œçœ‹èµ·æ¥æ›´æŸ”å’Œï¼Œå¹¶ä¸”åœ¨æˆ‘ä»¬çš„ä½“ç§¯ç…§æ˜/å¤§æ°”ç³»ç»Ÿä¸­è¡¨ç°å¾—éå¸¸å¥½ã€‚å®ƒä»¬ä¸ä»…çœ‹èµ·æ¥æ›´å¥½ï¼Œè€Œä¸”é€Ÿåº¦æ›´å¿«-æ˜¾ç„¶ä»…ç”±äºè¿™äº›ç‰¹æ®Šæ¡ä»¶è€Œèµ·ä½œç”¨ã€‚</p><p>  A slightly more demanding type of feature is cinematic-only one. Cinematics are a bit different as they can be very strictly controlled by cinematic artists and  most of their aspects like lighting, character placement, or animations are faked â€“ just like in regular cinema! Cinematics often feature fast camera cuts (useful to hide any transitions/popping) and have more computational budget due to more predictable nature (and even in 60fps console games rendered in 30fps).</p><p>  ç¨å¾®æœ‰ç‚¹è‹›åˆ»çš„åŠŸèƒ½æ˜¯ä»…ç”µå½±åŠŸèƒ½ã€‚ç”µå½±æŠ€æœ¯æœ‰ç‚¹ä¸åŒï¼Œå› ä¸ºå®ƒä»¬å¯ä»¥ç”±ç”µå½±è‰ºæœ¯å®¶ä¸¥æ ¼æ§åˆ¶ï¼Œå¹¶ä¸”å®ƒä»¬åœ¨ç…§æ˜ï¼Œè§’è‰²æ”¾ç½®æˆ–åŠ¨ç”»ç­‰å¤§å¤šæ•°æ–¹é¢éƒ½æ˜¯ä¼ªé€ çš„ï¼Œå°±åƒåœ¨å¸¸è§„ç”µå½±é™¢ä¸€æ ·ï¼ç”µå½±é€šå¸¸å…·æœ‰å¿«é€Ÿçš„æ‘„åƒæœºå‰ªåˆ‡åŠŸèƒ½ï¼ˆå¯ç”¨äºéšè—ä»»ä½•è¿‡æ¸¡/å¼¹å‡ºçª—å£ï¼‰ï¼Œå¹¶ä¸”ç”±äºå…·æœ‰æ›´å¯é¢„æµ‹çš„æ€§è´¨è€Œå…·æœ‰æ›´å¤šçš„è®¡ç®—é¢„ç®—ï¼ˆç”šè‡³åœ¨ä»¥30fpsæ¸²æŸ“çš„60fpsæ§åˆ¶å°æ¸¸æˆä¸­ï¼‰ã€‚ </p><p>   â€œRegularâ€ features â€“ lighting, particles, geometry rendering â€“ are the  hardest category. They need to be either very easy to implement (most of the obstacles / problems solved easily), provide huge benefits surpassing state of the art by far to facilitate the adoption pain, or have some very excited team pushing for it (never underestimate the drive of engineers or artists that really want to see something happen!).</p><p>â€œå¸¸è§„â€åŠŸèƒ½-ç…§æ˜ï¼Œç²’å­ï¼Œå‡ ä½•ä½“æ¸²æŸ“-æ˜¯æœ€éš¾çš„ç±»åˆ«ã€‚ä»–ä»¬éœ€è¦è¦ä¹ˆéå¸¸æ˜“äºå®æ–½ï¼ˆå¤§å¤šæ•°éšœç¢/é—®é¢˜å°±å¾ˆå®¹æ˜“è§£å†³ï¼‰ï¼Œè¦ä¹ˆæä¾›è¿œè¿œè¶…è¿‡ç°æœ‰æŠ€æœ¯çš„å·¨å¤§æ”¶ç›Šï¼ˆä»¥è§£å†³é‡‡ç”¨éš¾é¢˜ï¼‰ï¼Œè¦ä¹ˆè®©ä¸€äº›éå¸¸æ¿€åŠ¨çš„å›¢é˜Ÿä¸ºä¹‹å¥‹æ–—ï¼ˆæ°¸è¿œä¸è¦ä½ä¼°æ¨åŠ¨åŠ›ï¼‰çœŸæ­£æƒ³çœ‹åˆ°æŸäº›äº‹æƒ…å‘ç”Ÿçš„å·¥ç¨‹å¸ˆæˆ–è‰ºæœ¯å®¶ï¼ï¼‰ã€‚</p><p>   Paradoxically, if something is a key or differentiating feature, this can alleviate many of the difficulties. Letâ€™s take VR â€“ there stereo, performance (low latency), and perfect AA with no smudging (so rather forget about TAA), are  THE features and absolutely core to the experience. This means that you can completely ignore for example rendering foliage or some animations that would look uncannily â€“ as being immersed and the VR experience of being there are much more important!</p><p>   çŸ›ç›¾çš„æ˜¯ï¼Œå¦‚æœæŸé¡¹æ˜¯å…³é”®æˆ–ä¸ä¼—ä¸åŒçš„åŠŸèƒ½ï¼Œåˆ™å¯ä»¥å‡è½»è®¸å¤šå›°éš¾ã€‚è®©æˆ‘ä»¬ä»¥è™šæ‹Ÿç°å®ä¸ºä¾‹â€“ç«‹ä½“å£°ï¼Œæ€§èƒ½ï¼ˆä½å»¶è¿Ÿï¼‰å’Œå®Œç¾çš„AAè€Œä¸ä¼šå¼„è„ï¼ˆå®å¯ä¸ç”¨TAAï¼‰ï¼Œå®ƒä»¬æ˜¯åŠŸèƒ½ï¼Œç»å¯¹æ˜¯ä½“éªŒâ€‹â€‹çš„æ ¸å¿ƒã€‚è¿™æ„å‘³ç€æ‚¨å¯ä»¥å®Œå…¨å¿½ç•¥ä¾‹å¦‚æ¸²æŸ“æ ‘å¶æˆ–æŸäº›çœ‹èµ·æ¥ä»¤äººè®¨åŒçš„åŠ¨ç”»â€“å› ä¸ºæ²‰æµ¸å’Œåœ¨é‚£é‡Œçš„VRä½“éªŒæ›´ä¸ºé‡è¦ï¼</p><p>  Letâ€™s have a look at compatibility of a newly developed feature with some other common â€œfeaturesâ€ (the distinction between â€œfeaturesâ€, and the next large section â€œpipelineâ€ is fuzzy).</p><p>  è®©æˆ‘ä»¬çœ‹ä¸€ä¸‹æ–°å¼€å‘çš„åŠŸèƒ½ä¸å…¶ä»–ä¸€äº›å¸¸è§â€œåŠŸèƒ½â€çš„å…¼å®¹æ€§ï¼ˆâ€œåŠŸèƒ½â€ä¹‹é—´çš„åŒºåˆ«ï¼Œä»¥åŠä¸‹ä¸€ä¸ªè¾ƒå¤§çš„â€œç®¡é“â€éƒ¨åˆ†æ˜¯æ¨¡ç³Šçš„ï¼‰ã€‚</p><p> Features are not the most important of challenges â€“ arguably the category Iâ€™m going to cover at the end (the â€œprocessâ€) is. But those are fun and easy to look at!</p><p> åŠŸèƒ½å¹¶ä¸æ˜¯æŒ‘æˆ˜ä¸­æœ€é‡è¦çš„-å¯ä»¥è¯´æˆ‘æœ€åè¦è®¨è®ºçš„ç±»åˆ«ï¼ˆâ€œè¿‡ç¨‹â€ï¼‰æ˜¯ã€‚ä½†æ˜¯è¿™äº›å¾ˆæœ‰è¶£ï¼Œè€Œä¸”å¾ˆå®¹æ˜“çœ‹ï¼</p><p>  Dense geometry like  foliage â€“ a â€œfeatureâ€ that inspired this post â€“ is an enemy of most rendering algorithms.</p><p>  å¯†é›†çš„å‡ ä½•å½¢çŠ¶ï¼ˆä¾‹å¦‚æ ‘å¶ï¼‰æ˜¯æ¿€å‘è¿™ç¯‡æ–‡ç« çš„â€œç‰¹å¾â€ï¼Œæ˜¯å¤§å¤šæ•°æ¸²æŸ“ç®—æ³•çš„æ•Œäººã€‚</p><p> The main problem is that with very dense geometry (lots of overlapping and small triangles), many â€œoptimizationsâ€ and assumptions become impossible.</p><p> ä¸»è¦é—®é¢˜æ˜¯ï¼Œç”±äºå‡ ä½•å½¢çŠ¶éå¸¸å¯†é›†ï¼ˆå¤§é‡é‡å å’Œå°ä¸‰è§’å½¢ï¼‰ï¼Œè®¸å¤šâ€œä¼˜åŒ–â€å’Œå‡è®¾å˜å¾—ä¸å¯èƒ½ã€‚</p><p>      Dense geometry through which you can see (like grass blades) is incompatible with many techniques, for example lightmapping (storing a precomputed lighting per every grass blade texel would be very costly).</p><p>      å¯ä»¥çœ‹åˆ°çš„å¯†é›†å‡ ä½•ä½“ï¼ˆä¾‹å¦‚è‰å¶ï¼‰ä¸è®¸å¤šæŠ€æœ¯ä¸å…¼å®¹ï¼Œä¾‹å¦‚ï¼Œå…‰ç…§è´´å›¾ï¼ˆæ¯ä¸ªè‰å¶texelå­˜å‚¨ä¸€ä¸ªé¢„å…ˆè®¡ç®—çš„ç…§æ˜ä¼šéå¸¸æ˜‚è´µï¼‰ã€‚ </p><p> If a game has a tree here and there or is placed in a city, this might not be a problem. But for any â€œnaturalâ€ environment, a big chunk of the productionization of any feature is going to be combining it to coexist well with foliage.</p><p>å¦‚æœæ¸¸æˆåœ¨è¿™é‡Œåˆ°å¤„éƒ½æœ‰æ ‘ï¼Œæˆ–è€…æ”¾åœ¨åŸå¸‚ä¸­ï¼Œé‚£ä¹ˆè¿™å¯èƒ½ä¸æ˜¯é—®é¢˜ã€‚ä½†æ˜¯å¯¹äºä»»ä½•â€œè‡ªç„¶â€ç¯å¢ƒï¼Œä»»ä½•åŠŸèƒ½çš„å¤§é‡ç”Ÿäº§éƒ½å°†ç»“åˆèµ·æ¥ä½¿å…¶ä¸æ ‘å¶å¾ˆå¥½åœ°å…±å­˜ã€‚</p><p>  Alpha testing is an extension of the above, as it disables even more hardware features / optimizations.</p><p>  Alphaæµ‹è¯•æ˜¯ä¸Šè¿°åŠŸèƒ½çš„æ‰©å±•ï¼Œå› ä¸ºå®ƒç¦ç”¨äº†æ›´å¤šç¡¬ä»¶åŠŸèƒ½/ä¼˜åŒ–ã€‚</p><p> Alpha testing is a technique, when a pixel evaluates â€œalphaâ€ value from a texture or pixel shader computations, and  based on some fixed threshold, doesnâ€™t render/write it.</p><p> é˜¿å°”æ³•æµ‹è¯•æ˜¯ä¸€ç§æŠ€æœ¯ï¼Œå½“åƒç´ ä»çº¹ç†æˆ–åƒç´ ç€è‰²å™¨è®¡ç®—ä¸­è¯„ä¼°â€œé˜¿å°”æ³•â€å€¼ï¼Œå¹¶ä¸”åŸºäºæŸä¸ªå›ºå®šé˜ˆå€¼æ—¶ï¼Œä¸ä¼šæ¸²æŸ“/å†™å…¥è¯¥å€¼ã€‚</p><p> It is much faster than alpha blending, but for example disables early z writes (early z tests are ok), and requires raytracing hit shaders and reading a texture to decide if a texel was opaque or not.</p><p> å®ƒæ¯”alphaæ··åˆå¿«å¾—å¤šï¼Œä½†æ˜¯ä¾‹å¦‚ç¦ç”¨äº†æ—©æœŸçš„zå†™æ“ä½œï¼ˆæ—©æœŸçš„zæµ‹è¯•æ˜¯å¯ä»¥çš„ï¼‰ï¼Œå¹¶ä¸”éœ€è¦å…‰çº¿è·Ÿè¸ªå‘½ä¸­ç€è‰²å™¨å¹¶è¯»å–çº¹ç†æ¥ç¡®å®šçº¹ç†åƒç´ æ˜¯å¦ä¸é€æ˜ã€‚</p><p> It also makes antialiasing very challenging (forget about regular MSAA, you have to emulate alpha to coverageâ€¦).</p><p> è¿™ä¹Ÿä½¿æŠ—é”¯é½¿å˜å¾—éå¸¸å…·æœ‰æŒ‘æˆ˜æ€§ï¼ˆå¿˜äº†å¸¸è§„çš„MSAAï¼Œæ‚¨å¿…é¡»æ¨¡æ‹Ÿalphaè¦†ç›–ï¼‰ã€‚</p><p> For a description and great visual explanation of some problems, see this blog post of  Ben Golus.</p><p> æœ‰å…³æŸäº›é—®é¢˜çš„æè¿°å’Œç›´è§‚çš„è§†è§‰è§£é‡Šï¼Œè¯·å‚é˜…Ben Golusçš„æ­¤åšå®¢æ–‡ç« ã€‚</p><p>  Most animators work with â€œskeletal animationsâ€.  Creating rigs, skinning meshes, animating skeletons. When you create a new technique for rendering meshes that relies on some heavy precomputations, would animators be able to â€œdeformâ€ it? Would they be able to plug it into a complicated animation blending system? How does it fit in their workflow?</p><p>  å¤§å¤šæ•°åŠ¨ç”»å¸ˆéƒ½ä½¿ç”¨â€œéª¨éª¼åŠ¨ç”»â€ã€‚åˆ›å»ºè£…å¤‡ï¼Œè’™çš®ç½‘æ ¼ï¼Œä¸ºéª¨éª¼è®¾ç½®åŠ¨ç”»ã€‚å½“æ‚¨åˆ›å»ºä¸€ç§æ–°çš„æ¸²æŸ“ç½‘æ ¼çš„æŠ€æœ¯æ—¶ï¼Œå®ƒä¾èµ–äºä¸€äº›ç¹ççš„é¢„è®¡ç®—ï¼ŒåŠ¨ç”»å¸ˆæ˜¯å¦èƒ½å¤Ÿå¯¹å…¶â€œå˜å½¢â€ï¼Ÿä»–ä»¬èƒ½å¤Ÿå°†å…¶æ’å…¥å¤æ‚çš„åŠ¨ç”»æ··åˆç³»ç»Ÿä¸­å—ï¼Ÿå®ƒå¦‚ä½•é€‚åˆä»–ä»¬çš„å·¥ä½œæµç¨‹ï¼Ÿ </p><p> Note that it can also mean rigid deformations, like a rotating wheel â€“ itâ€™s much cheaper to render complicated objects as a skinned whole, than splitting them.</p><p>è¯·æ³¨æ„ï¼Œå®ƒä¹Ÿå¯èƒ½æ„å‘³ç€åˆšæ€§å˜å½¢ï¼Œä¾‹å¦‚æ—‹è½¬çš„è½®å­â€“å°†å¤æ‚çš„å¯¹è±¡ä½œä¸ºè’™çš®çš„æ•´ä½“è¿›è¡Œæ¸²æŸ“è¦æ¯”æ‹†åˆ†å®ƒä»¬ä¾¿å®œå¾—å¤šã€‚</p><p>    The next category of animations are â€œproceduralâ€ and non-rigid. Procedural animations are useful for any animation that is â€œendlessâ€, relatively simple, and shouldnâ€™t loop too visibly. The most common example is  leaf shimmer and branch movement.</p><p>    ä¸‹ä¸€ç±»åŠ¨ç”»æ˜¯â€œè¿‡ç¨‹æ€§çš„â€å’Œéåˆšæ€§çš„ã€‚ç¨‹åºåŠ¨ç”»å¯¹äºâ€œæ— ä¼‘æ­¢â€ï¼Œç›¸å¯¹ç®€å•ä¸”ä¸åº”å¤ªæ˜æ˜¾åœ°å¾ªç¯çš„åŠ¨ç”»å¾ˆæœ‰ç”¨ã€‚æœ€å¸¸è§çš„ä¾‹å­æ˜¯å¶ç‰‡å¾®å…‰å’Œæ ‘æè¿åŠ¨ã€‚</p><p> See  this video of middleware Speedtree movement â€“ all movement there is described by some mathematical formulas, not animated â€œby handâ€ and looks fantastic and plausible.</p><p> è§‚çœ‹æœ‰å…³ä¸­é—´ä»¶Speedtreeè¿åŠ¨çš„è§†é¢‘-é‚£é‡Œçš„æ‰€æœ‰è¿åŠ¨éƒ½æ˜¯ç”±ä¸€äº›æ•°å­¦å…¬å¼æè¿°çš„ï¼Œè€Œä¸æ˜¯â€œæ‰‹å·¥åˆ¶ä½œâ€çš„åŠ¨ç”»ï¼Œçœ‹ä¸Šå»å¥‡å¦™è€Œåˆç†ã€‚</p><p> A good rendering technique that is applicable on elements like foliage (again!) needs to support the option of displacing it in any arbitrary fashion from simple shimmer to large bends â€“ otherwise the world will look â€œdeadâ€.</p><p> ä¸€ç§é€‚ç”¨äºæ ‘å¶ï¼ˆå†æ¬¡ï¼ï¼‰ç­‰å…ƒç´ çš„è‰¯å¥½æ¸²æŸ“æŠ€æœ¯éœ€è¦æ”¯æŒä»¥ä»»æ„æ–¹å¼ï¼ˆä»ç®€å•çš„å¾®å…‰åˆ°å¤§å¼¯è§’ï¼‰è¿›è¡Œæ›¿æ¢çš„é€‰é¡¹â€“å¦åˆ™ä¸–ç•Œå°†çœ‹èµ·æ¥â€œæ­»â€ã€‚</p><p> Non-rigid animation, modifying vertex positions, or even streaming whole vertex buffers causes headaches for the raytracing â€“ as it requires readjusting the spatial acceleration structures (essential for RT) every single frame, which is impractical.</p><p> éåˆšæ€§åŠ¨ç”»ï¼Œä¿®æ”¹é¡¶ç‚¹ä½ç½®ï¼Œç”šè‡³æµå¼ä¼ è¾“æ•´ä¸ªé¡¶ç‚¹ç¼“å†²åŒºéƒ½ä¼šå¯¼è‡´å…‰çº¿è·Ÿè¸ªçš„éº»çƒ¦-å› ä¸ºå®ƒéœ€è¦æ¯å¸§é‡æ–°è°ƒæ•´ç©ºé—´åŠ é€Ÿåº¦ç»“æ„ï¼ˆå¯¹äºRTè‡³å…³é‡è¦ï¼‰ï¼Œè¿™æ˜¯ä¸åˆ‡å®é™…çš„ã€‚</p><p>  Yet another type of animation is animating textures on surfaces of objects. This is not just for emulating  neons or TVs, but also for example raindrops and rain ripples. Technical and FX artists have lots of amazing tricks there, from just sliding and scaling UVs, having flowmaps, to directly animating â€œflipbookâ€ textures.</p><p>  åŠ¨ç”»çš„å¦ä¸€ç§ç±»å‹æ˜¯åœ¨å¯¹è±¡è¡¨é¢ä¸Šè®¾ç½®çº¹ç†åŠ¨ç”»ã€‚è¿™ä¸ä»…ç”¨äºæ¨¡æ‹Ÿéœ“è™¹ç¯æˆ–ç”µè§†ï¼Œè¿˜ç”¨äºä¾‹å¦‚é›¨æ»´å’Œé›¨æ°´æ³¢çº¹ã€‚æŠ€æœ¯äººå‘˜å’ŒFXè‰ºæœ¯å®¶é‚£é‡Œæœ‰è®¸å¤šæƒŠäººçš„æŠ€å·§ï¼Œä»æ»‘åŠ¨å’Œç¼©æ”¾UVï¼Œå…·æœ‰æµç¨‹å›¾åˆ°ç›´æ¥ä¸ºâ€œåŠ¨ç”»ä¹¦â€çº¹ç†è®¾ç½®åŠ¨ç”»ã€‚</p><p>   Many techniques work well assuming a relatively fixed camera viewpoint. From artists tricks and hacks, to techniques like impostor rendering.</p><p>   å‡è®¾æ‘„åƒæœºçš„è§†ç‚¹ç›¸å¯¹å›ºå®šï¼Œè®¸å¤šæŠ€æœ¯éƒ½å¯ä»¥å¾ˆå¥½åœ°å·¥ä½œã€‚ä»è‰ºæœ¯å®¶çš„æŠ€å·§å’Œéª‡å®¢ï¼Œåˆ°å†’åé¡¶æ›¿è€…æ¸²æŸ“ä¹‹ç±»çš„æŠ€æœ¯ã€‚ </p><p> Some rendering acceleration techniques optimize for a semi-constrained view (like  Project Seurat that my colleagues worked on). Degrees of camera freedom are something to be considered when adapting any technique. A billboard-based tree can look ok from a distance, but if you get closer, or can see the scene from a higher viewpoint, it will break completely.</p><p>ä¸€äº›æ¸²æŸ“åŠ é€ŸæŠ€æœ¯é’ˆå¯¹åŠçº¦æŸè§†å›¾è¿›è¡Œäº†ä¼˜åŒ–ï¼ˆä¾‹å¦‚æˆ‘çš„åŒäº‹ä»äº‹çš„Project Seuraté¡¹ç›®ï¼‰ã€‚é€‚åº”ä»»ä½•æŠ€æœ¯æ—¶éƒ½åº”è€ƒè™‘ç›¸æœºè‡ªç”±åº¦ã€‚åŸºäºå¹¿å‘Šç‰Œçš„æ ‘ä»è¿œå¤„çœ‹å¯èƒ½ä¸é”™ï¼Œä½†æ˜¯å¦‚æœæ‚¨ç¦»å¾—å¾ˆè¿‘ï¼Œæˆ–è€…å¯ä»¥ä»æ›´é«˜çš„è§’åº¦çœ‹åˆ°åœºæ™¯ï¼Œåˆ™æ ‘ä¼šå®Œå…¨æ–­è£‚ã€‚</p><p> Also â€“ think of early photogrammetry that was capturing the specular reflections as textures, which look absolutely wrong when you change the viewpoint even slightly.</p><p> å¦å¤–â€“æƒ³åƒä¸€ä¸‹æ—©æœŸçš„æ‘„å½±æµ‹é‡æ³•ï¼Œå°†é•œé¢åå°„æ•è·ä¸ºçº¹ç†ï¼Œå½“æ‚¨ç¨å¾®æ”¹å˜è§†ç‚¹æ—¶ï¼Œçœ‹èµ·æ¥ç»å¯¹æ˜¯é”™è¯¯çš„ã€‚</p><p>  How dynamic is the lighting? Is there a dynamic time of day? Weather system? Can the user turn on/off lights? Do special effects cast lights? Are there dynamic shadow casting objects?</p><p>  ç…§æ˜çš„åŠ¨æ€ç¨‹åº¦å¦‚ä½•ï¼Ÿæœ‰ä¸€å¤©çš„åŠ¨æ€æ—¶é—´å—ï¼Ÿå¤©æ°”ç³»ç»Ÿï¼Ÿç”¨æˆ·å¯ä»¥æ‰“å¼€/å…³é—­ç¯å—ï¼Ÿç‰¹æ®Šæ•ˆæœä¼šæŠ•å°„ç¯å…‰å—ï¼Ÿæ˜¯å¦æœ‰åŠ¨æ€é˜´å½±æŠ•å°„å¯¹è±¡ï¼Ÿ</p><p> The answer is going to be â€œyesâ€ to many of those questions for most of the contemporary real-time rendering products like games; especially with a tendency of creating larger, living worlds.</p><p> å¯¹äºå¤§å¤šæ•°å½“ä»£å®æ—¶æ¸²æŸ“äº§å“ï¼ˆå¦‚æ¸¸æˆï¼‰ï¼Œç­”æ¡ˆå°†æ˜¯â€œå¾ˆå¤šâ€ã€‚ç‰¹åˆ«æ˜¯å€¾å‘äºåˆ›é€ æ›´å¤§çš„ç”Ÿæ´»ä¸–ç•Œã€‚</p><p> This doesnâ€™t necessarily preclude precomputed/baked solutions (like  our precomputed GI solution for AC4 that supported dynamic time of day!) but needs extra considerations.</p><p> è¿™å¹¶ä¸ä¸€å®šæ’é™¤é¢„å…ˆè®¡ç®—/çƒ˜ç„™çš„è§£å†³æ–¹æ¡ˆï¼ˆä¾‹å¦‚æˆ‘ä»¬æ”¯æŒAC4çš„åŠ¨æ€è®¡ç®—çš„GIé¢„å…ˆè®¡ç®—çš„GIè§£å†³æ–¹æ¡ˆï¼ï¼‰ï¼Œä½†éœ€è¦é¢å¤–è€ƒè™‘ã€‚</p><p> There are still many new publications coming out that describe new approaches and solutions to those problems (combining precomputations of the light transport, and the dynamic lighting).</p><p> ä»ç„¶æœ‰è®¸å¤šæ–°å‡ºç‰ˆç‰©å‘è¡¨ï¼Œæè¿°äº†è§£å†³è¿™äº›é—®é¢˜çš„æ–°æ–¹æ³•å’Œè§£å†³æ–¹æ¡ˆï¼ˆç»“åˆäº†å…‰ä¼ è¾“å’ŒåŠ¨æ€ç…§æ˜çš„é¢„è®¡ç®—ï¼‰ã€‚</p><p>  Shadows, another never ending topic and an unsolved problem. Most games still use a mixture of precomputed shadows and shadow maps, some start to experiment with raytraced shadows.</p><p>  é˜´å½±ï¼Œå¦ä¸€ä¸ªæ°¸æ— æ­¢å¢ƒçš„è¯é¢˜å’Œæœªè§£å†³çš„é—®é¢˜ã€‚å¤§å¤šæ•°æ¸¸æˆä»ç„¶ä½¿ç”¨é¢„å…ˆè®¡ç®—çš„é˜´å½±å’Œé˜´å½±è´´å›¾çš„æ··åˆç‰©ï¼Œæœ‰äº›æ¸¸æˆå¼€å§‹å°è¯•ä½¿ç”¨å…‰çº¿è·Ÿè¸ªé˜´å½±ã€‚ </p><p> Anytime you want to insert a new type of object to be rendered, you need to consider: is it going to be able to receive shadows from other objects? Is it going to cast shadows on other objects?</p><p>æ¯å½“æ‚¨è¦æ’å…¥è¦æ¸²æŸ“çš„æ–°å‹å¯¹è±¡æ—¶ï¼Œéƒ½éœ€è¦è€ƒè™‘ï¼šå®ƒæ˜¯å¦èƒ½å¤Ÿæ¥æ”¶æ¥è‡ªå…¶ä»–å¯¹è±¡çš„é˜´å½±ï¼Ÿå®ƒä¼šåœ¨å…¶ä»–ç‰©ä½“ä¸ŠæŠ•å°„é˜´å½±å—ï¼Ÿ</p><p> For particles or volumetrics, the answer might not be easy (as partial transmittance is not supported by shadow maps), but also â€œsimpleâ€ techniques like mesh tessellation or parallax occlusion mapping are going to create a mismatch between shadow caster and the receiver, potentially causing shadowing artifacts!</p><p> å¯¹äºç²’å­æˆ–ä½“ç§¯ï¼Œç­”æ¡ˆå¯èƒ½å¹¶ä¸å®¹æ˜“ï¼ˆå› ä¸ºé˜´å½±è´´å›¾ä¸æ”¯æŒéƒ¨åˆ†é€å°„ç‡ï¼‰ï¼Œä½†æ˜¯åƒç½‘æ ¼ç»†åˆ†æˆ–è§†å·®é®æŒ¡è´´å›¾è¿™æ ·çš„â€œç®€å•â€æŠ€æœ¯ä¹Ÿä¼šåœ¨é˜´å½±æŠ•å°„å™¨å’Œæ¥æ”¶å™¨ä¹‹é—´é€ æˆä¸åŒ¹é…ã€‚é€ æˆé˜´å½±ä¼ªå½±ï¼</p><p>   Finally, if the environment can be dynamic (through game story mandated changes, destruction, or in the extreme case through user content creation), any techniques relying on offline precomputation become challenging.</p><p>   æœ€åï¼Œå¦‚æœç¯å¢ƒæ˜¯åŠ¨æ€çš„ï¼ˆé€šè¿‡å¼ºåˆ¶æ›´æ”¹ï¼Œé”€æ¯æ¸¸æˆæ•…äº‹ï¼Œæˆ–è€…åœ¨æç«¯æƒ…å†µä¸‹é€šè¿‡åˆ›å»ºç”¨æˆ·å†…å®¹ï¼‰ï¼Œåˆ™ä¾èµ–è„±æœºé¢„è®¡ç®—çš„ä»»ä½•æŠ€æœ¯éƒ½å°†é¢ä¸´æŒ‘æˆ˜ã€‚</p><p> On  God of War the Caldera Lake and the bridge, moving levels of water and bridge rotations were  one of the biggest concerns throughout the whole production from the perspective of lighting / global illumination systems that rely on precomputations. There was no â€œgeneralâ€ solution, it all relied on manual work and streaming / managing the loaded dataâ€¦</p><p> ä»ä¾é é¢„è®¡ç®—çš„ç…§æ˜/å…¨çƒç…§æ˜ç³»ç»Ÿçš„è§’åº¦æ¥çœ‹ï¼Œåœ¨æˆ˜ç¥ç ´ç«å±±å£æ¹–å’Œæ¡¥æ¢ä¸Šï¼Œæ°´ä½å’Œæ¡¥æ¢æ—‹è½¬çš„ç§»åŠ¨æ˜¯æ•´ä¸ªç”Ÿäº§è¿‡ç¨‹ä¸­æœ€å¤§çš„é—®é¢˜ä¹‹ä¸€ã€‚æ²¡æœ‰â€œé€šç”¨â€è§£å†³æ–¹æ¡ˆï¼Œå®ƒå…¨éƒ¨ä¾é æ‰‹åŠ¨å·¥ä½œä»¥åŠæµå¼ä¼ è¾“/ç®¡ç†åŠ è½½çš„æ•°æ®â€¦</p><p>   Finally, there are transparent objects and particles â€“ a very special and different category than anything else.</p><p>   æœ€åï¼Œè¿˜æœ‰é€æ˜çš„å¯¹è±¡å’Œç²’å­â€“ä¸€ä¸ªéå¸¸ç‰¹æ®Šä¸”ä¸ä¼—ä¸åŒçš„ç±»åˆ«ã€‚</p><p> They donâ€™t write depth or motion vectors (more on it later), require back-to-front sorting, need many evaluations of costly computations and texture samplers per final output piels, usually are lit in a simpler way, need special handling of shadowsâ€¦ They are also very expensive due to overdraw â€“ a single output pixel can be many evaluations of alpha blended particlesâ€™ pixel shaders.</p><p> ä»–ä»¬ä¸ç¼–å†™æ·±åº¦æˆ–è¿åŠ¨çŸ¢é‡ï¼ˆç¨åä¼šè¯¦ç»†ä»‹ç»ï¼‰ï¼Œéœ€è¦ä»å¤´åˆ°å°¾è¿›è¡Œæ’åºï¼Œéœ€è¦å¯¹æ¯ä¸ªæœ€ç»ˆè¾“å‡ºçš„æ‰¹å¤„ç†è¿›è¡Œè®¸å¤šè¯„ä¼°ï¼ŒåŒ…æ‹¬æ˜‚è´µçš„è®¡ç®—å’Œçº¹ç†é‡‡æ ·å™¨ï¼Œé€šå¸¸ä»¥æ›´ç®€å•çš„æ–¹å¼ç‚¹äº®ï¼Œéœ€è¦å¯¹é˜´å½±...ç”±äºè¿‡åº¦ç»˜åˆ¶ï¼Œå®ƒä»¬ä¹Ÿéå¸¸æ˜‚è´µ-ä¸€ä¸ªè¾“å‡ºåƒç´ å¯ä»¥å¯¹alphaæ··åˆç²’å­çš„åƒç´ ç€è‰²å™¨è¿›è¡Œè®¸å¤šè¯„ä¼°ã€‚</p><p> Person-years of work (on most projects I worked on there were N dedicated FX artists and at least one dedicated FX and particle rendering engineer) that cannot be just discarded or ignored by a newly introduced technique.</p><p> å†æ—¶æ•°å¹´çš„å·¥ä½œï¼ˆåœ¨æˆ‘ä»äº‹çš„å¤§å¤šæ•°é¡¹ç›®ä¸­ï¼Œæœ‰Nä½ä¸“ä¸šçš„FXè‰ºæœ¯å®¶ä»¥åŠè‡³å°‘ä¸€ä½ä¸“ä¸šçš„FXå’Œç²’å­æ¸²æŸ“å·¥ç¨‹å¸ˆï¼‰ä¸èƒ½è¢«æ–°å¼•å…¥çš„æŠ€æœ¯ä¸¢å¼ƒæˆ–å¿½ç•¥ã€‚ </p><p>  The above were some product features and requirements to consider. But what about some deeper, more low-level implications? Rendering of a single frame requires tens of discrete passes that are designed to work with each other, tens of intermediate outputs and buffers. Letâ€™s look at  parts of the rendering pipeline to consider.</p><p>ä»¥ä¸Šæ˜¯è¦è€ƒè™‘çš„ä¸€äº›äº§å“åŠŸèƒ½å’Œè¦æ±‚ã€‚ä½†æ˜¯ï¼Œä¸€äº›æ›´æ·±å±‚æ¬¡ï¼Œæ›´åº•å±‚çš„å«ä¹‰å‘¢ï¼Ÿæ¸²æŸ“å•ä¸ªå¸§éœ€è¦æ•°åä¸ªç¦»æ•£é€šé“ï¼Œè¿™äº›é€šé“è¢«è®¾è®¡ä¸ºå¯ä»¥ç›¸äº’é…åˆå·¥ä½œï¼Œéœ€è¦æ•°åä¸ªä¸­é—´è¾“å‡ºå’Œç¼“å†²åŒºã€‚è®©æˆ‘ä»¬çœ‹ä¸€ä¸‹è¦è€ƒè™‘çš„éƒ¨åˆ†æ¸²æŸ“ç®¡é“ã€‚</p><p>  I mentioned above some challenges with alpha testing, alpha blending, sorting, and particles. But it gets even more challenging when you realize that many features require  precise Z buffer values in the depth buffer for every object!</p><p>  æˆ‘åœ¨ä¸Šé¢æåˆ°äº†alphaæµ‹è¯•ï¼Œalphaæ··åˆï¼Œæ’åºå’Œç²’å­æ–¹é¢çš„ä¸€äº›æŒ‘æˆ˜ã€‚ä½†æ˜¯ï¼Œå½“æ‚¨æ„è¯†åˆ°è®¸å¤šåŠŸèƒ½éœ€è¦æ¯ä¸ªå¯¹è±¡çš„æ·±åº¦ç¼“å†²åŒºä¸­çš„ç²¾ç¡®Zç¼“å†²åŒºå€¼æ—¶ï¼ŒæŒ‘æˆ˜å°±å˜å¾—æ›´å¤§äº†ï¼</p><p> That creamy depth of field effect and many other camera effects? Most require a depth buffer. Old school depth fog? Required depth buffer!</p><p> é‚£ç§å¥¶æ²¹èˆ¬çš„æ™¯æ·±æ•ˆæœå’Œè®¸å¤šå…¶ä»–ç›¸æœºæ•ˆæœï¼Ÿå¤§å¤šæ•°éœ€è¦æ·±åº¦ç¼“å†²åŒºã€‚è€æ´¾æ·±åº¦è¿·é›¾ï¼Ÿéœ€è¦æ·±åº¦ç¼“å†²åŒºï¼</p><p>  Ok, this seems like a deal breaker, as we know that alpha blended objects donâ€™t write those and there cannot be a single depth value corresponding to themâ€¦ But games are a mastery of smoke and mirrors and faking. ğŸ™‚ If you really care you can create depth proxies by hand, sort and reorder some things manually, alpha blend depth (wrong but can look â€œokâ€), tweak depth of field until artifacts are not distractingâ€¦ Lots of manual work and puzzles â€œwhich compromise is less badâ€!</p><p>  å¥½çš„ï¼Œè¿™çœ‹èµ·æ¥åƒæ˜¯ä¸€ä¸ªäº¤æ˜“çªç ´ï¼Œå› ä¸ºæˆ‘ä»¬çŸ¥é“Alphaæ··åˆå¯¹è±¡ä¸ä¼šå†™è¿™äº›å¯¹è±¡ï¼Œå¹¶ä¸”ä¸èƒ½æœ‰å¯¹åº”äºå®ƒä»¬çš„å•ä¸ªæ·±åº¦å€¼â€¦â€¦ä½†æ˜¯æ¸¸æˆç²¾é€šçƒŸé›¾ï¼Œé•œå­å’Œä¼ªé€ ã€‚ ğŸ™‚å¦‚æœæ‚¨çœŸçš„å¾ˆåœ¨æ„ï¼Œå¯ä»¥æ‰‹åŠ¨åˆ›å»ºæ·±åº¦ä»£ç†ï¼Œæ‰‹åŠ¨å¯¹ä¸€äº›ä¸œè¥¿è¿›è¡Œæ’åºå’Œé‡æ–°æ’åºï¼Œalphaæ··åˆæ·±åº¦ï¼ˆé”™è¯¯ï¼Œä½†çœ‹èµ·æ¥å¯ä»¥ï¼‰ï¼Œè°ƒæ•´æ™¯æ·±ï¼Œç›´åˆ°å·¥ä»¶ä¸ä¼šåˆ†æ•£æ³¨æ„åŠ›â€¦â€¦å¾ˆå¤šæ‰‹åŠ¨å·¥ä½œå’Œéš¾é¢˜â€å“ªç§å¦¥åè¿˜ä¸é”™â€ï¼</p><p>  A related pipeline component is writing of the motion vectors. While depth is essential for many mentioned depth based effects, proper occlusions, screen-sapce refractions, fog etc,  the motion vectors are used for â€œonlyâ€ two things: motion blur and temporal antialiasing (see below).</p><p>  ä¸€ä¸ªç›¸å…³çš„æµæ°´çº¿ç»„ä»¶æ˜¯è¿åŠ¨çŸ¢é‡çš„å†™å…¥ã€‚è™½ç„¶æ·±åº¦å¯¹äºè®¸å¤šä¸Šè¿°åŸºäºæ·±åº¦çš„æ•ˆæœï¼Œé€‚å½“çš„é®æŒ¡ï¼Œå±å¹•ç©ºé—´æŠ˜å°„ï¼Œé›¾ç­‰è‡³å…³é‡è¦ï¼Œä½†è¿åŠ¨çŸ¢é‡ä»…ç”¨äºâ€œä¸¤ä»¶äº‹æƒ…â€ï¼šè¿åŠ¨æ¨¡ç³Šå’Œæ—¶é—´æŠ—é”¯é½¿ï¼ˆè¯·å‚è§ä¸‹æ–‡ï¼‰ã€‚</p><p> Motion blur seems like â€œjust an effectâ€, but having small amounts of it is essential to reduce the â€œstrobingâ€ effect and generally cheap feel (see movie 24fps half shutter motion blur).</p><p> è¿åŠ¨æ¨¡ç³Šä¼¼ä¹åªæ˜¯â€œä¸€ç§æ•ˆæœâ€ï¼Œä½†æ˜¯å‡å°‘è¿åŠ¨æ¨¡ç³Šå’Œå‡å°‘é€šå¸¸çš„å»‰ä»·æ„Ÿè§‰è‡³å…³é‡è¦ï¼ˆè¯·å‚é˜…ç”µå½±24fpsåŠå¿«é—¨è¿åŠ¨æ¨¡ç³Šï¼‰ã€‚</p><p> (Some bragging / Christmas time nostalgia: thinking about motion blur made me feel nostalgic â€“ motion blur was the first feature I  got interviewed about by the press â€“ I still feel the pride the 23 year old me living in Eastern Europe and that didnâ€™t even finish the college felt!)</p><p> ï¼ˆæœ‰äº›å¹ç‰›/åœ£è¯èŠ‚çš„æ€€æ—§ä¹‹æƒ…ï¼šå¯¹è¿åŠ¨æ¨¡ç³Šçš„æ€è€ƒä½¿æˆ‘æ„Ÿåˆ°æ€€æ—§-è¿åŠ¨æ¨¡ç³Šæ˜¯æˆ‘è¢«åª’ä½“é‡‡è®¿çš„ç¬¬ä¸€ä¸ªåŠŸèƒ½-æˆ‘ä»ç„¶å¯¹23å²çš„æˆ‘ç”Ÿæ´»åœ¨ä¸œæ¬§æ„Ÿåˆ°è‡ªè±ªï¼Œä½†äº‹å®å¹¶éå¦‚æ­¤ã€‚ç”šè‡³å®Œæˆäº†å¤§å­¦çš„æ„Ÿè§‰ï¼ï¼‰ </p><p> Producing accurate motion vectors is not trivial â€“ for every pixel, you need to estimate where this part of the object was in the previous frame. This can mean re-computing some animation data again, storing it for the previous frame (extra used memory), or can be too difficult / impossible (dealing with occlusions, shadows, or texture animations).</p><p>äº§ç”Ÿå‡†ç¡®çš„è¿åŠ¨çŸ¢é‡å¹¶éæ˜“äº‹-å¯¹äºæ¯ä¸ªåƒç´ ï¼Œæ‚¨éƒ½éœ€è¦ä¼°è®¡å¯¹è±¡çš„è¿™ä¸€éƒ¨åˆ†åœ¨ä¸Šä¸€å¸§ä¸­çš„ä½ç½®ã€‚è¿™å¯èƒ½æ„å‘³ç€å†æ¬¡é‡æ–°è®¡ç®—ä¸€äº›åŠ¨ç”»æ•°æ®ï¼Œå°†å…¶å­˜å‚¨åˆ°å‰ä¸€å¸§ï¼ˆé¢å¤–ä½¿ç”¨çš„å†…å­˜ï¼‰ï¼Œæˆ–è€…å¯èƒ½å¤ªå›°éš¾/ä¸å¯èƒ½ï¼ˆå¤„ç†é®æŒ¡ï¼Œé˜´å½±æˆ–çº¹ç†åŠ¨ç”»ï¼‰ã€‚</p><p> On AC4 we have implemented it for almost everything â€“ with an exception of the ocean and ignored the TAA and motion blur problems on itâ€¦</p><p> åœ¨AC4ä¸Šï¼Œæˆ‘ä»¬å‡ ä¹å¯¹æ‰€æœ‰äº‹ç‰©éƒ½å®ç°äº†å®ƒ-é™¤äº†æµ·æ´‹ï¼Œå®ƒå¿½ç•¥äº†TAAå’Œä¸Šé¢çš„è¿åŠ¨æ¨¡ç³Šé—®é¢˜â€¦â€¦</p><p>  Temporal antialiasingâ€¦ one of the biggest achievements of the rendering engines in the last few years, but also one of the biggest sources of problems and artifacts. Not going to discuss here if there are alternatives to it or if itâ€™s a good idea or not, but itâ€™s here to stay for a while â€“ not just for the antialiasing, but also  temporal distribution of samples in Monte Carlo techniques, supersampling, stochastic rendering, and allowing for slow things to become possible or higher quality in real-time.</p><p>  ä¸´æ—¶æŠ—é”¯é½¿â€¦æ˜¯è¿‡å»å‡ å¹´æ¸²æŸ“å¼•æ“çš„æœ€å¤§æˆå°±ä¹‹ä¸€ï¼Œä½†ä¹Ÿæ˜¯é—®é¢˜å’Œå·¥ä»¶çš„æœ€å¤§æ¥æºä¹‹ä¸€ã€‚åœ¨è¿™é‡Œä¸è®¨è®ºæ˜¯å¦æœ‰æ›¿ä»£æ–¹æ³•ï¼Œæˆ–è€…å®ƒæ˜¯å¦æ˜¯ä¸€ä¸ªå¥½ä¸»æ„ï¼Œä½†è¿™å°†åœ¨è¿™é‡Œåœç•™ä¸€æ®µæ—¶é—´-ä¸ä»…ç”¨äºæŠ—é”¯é½¿ï¼Œè€Œä¸”è¿˜ç”¨äºè’™ç‰¹å¡æ´›æŠ€æœ¯ï¼Œè¶…çº§é‡‡æ ·ï¼Œéšæœºæ¸²æŸ“ä¸­çš„æ ·æœ¬æ—¶é—´åˆ†å¸ƒï¼Œå¹¶å…è®¸ç¼“æ…¢çš„äº‹æƒ…å˜ä¸ºå¯èƒ½æˆ–å®æ—¶è·å¾—æ›´é«˜çš„è´¨é‡ã€‚</p><p> It  can be a problem for many new rendering techniques â€“ not only because of the need for pretty good motion vectors, but also its nature can lead to some smearing artifacts, or even cancel out visual effects like sparkly snow (glints, sparkles, muzzle flash etc).</p><p> å¯¹äºè®¸å¤šæ–°çš„æ¸²æŸ“æŠ€æœ¯è€Œè¨€ï¼Œè¿™å¯èƒ½æ˜¯ä¸€ä¸ªé—®é¢˜â€“ä¸ä»…æ˜¯å› ä¸ºéœ€è¦éå¸¸å¥½çš„è¿åŠ¨çŸ¢é‡ï¼Œè€Œä¸”å®ƒçš„æ€§è´¨è¿˜å¯èƒ½å¯¼è‡´äº§ç”Ÿä¸€äº›æ‹–å°¾çš„ä¼ªå½±ï¼Œç”šè‡³æŠµæ¶ˆè¯¸å¦‚é—ªé—ªå‘å…‰çš„é›ªï¼ˆé—ªçƒï¼Œç«èŠ±ï¼Œæªå£é—ªå…‰ï¼‰çš„è§†è§‰æ•ˆæœç­‰ç­‰ï¼‰ã€‚</p><p>   Majority of the engines use  deferred shading (yes, there are many exceptions and they look and perform fantastic). It has many desirable properties and â€œliftsâ€ / decouples parts of the rendering, simplifies things like decals, can provide a sweet reduction of the overdrawâ€¦</p><p>   å¤§å¤šæ•°å¼•æ“ä½¿ç”¨å»¶è¿Ÿç€è‰²ï¼ˆæ˜¯çš„ï¼Œæœ‰å¾ˆå¤šä¾‹å¤–ï¼Œå®ƒä»¬çœ‹èµ·æ¥å’Œè¡¨ç°éƒ½å¾ˆæ£’ï¼‰ã€‚å®ƒå…·æœ‰è®¸å¤šç†æƒ³çš„å±æ€§ï¼Œå¹¶ä¸”å¯ä»¥â€œæå‡â€ /è§£è€¦æ¸²æŸ“çš„å„ä¸ªéƒ¨åˆ†ï¼Œç®€åŒ–äº†è´´èŠ±ä¹‹ç±»çš„äº‹æƒ…ï¼Œå¯ä»¥å¾ˆå¥½åœ°å‡å°‘é€æ”¯ã€‚</p><p>  But having a â€œbottleneckâ€ in form of the GBuffer and lighting not having access to any other data can be very limiting.</p><p>  ä½†æ˜¯ï¼Œä»¥GBufferå½¢å¼å‡ºç°â€œç“¶é¢ˆâ€ï¼Œå¹¶ä¸”ç…§æ˜æ— æ³•è®¿é—®ä»»ä½•å…¶ä»–æ•°æ®å¯èƒ½ä¼šéå¸¸å—é™åˆ¶ã€‚</p><p> New shading model? New look-up table? New data precomputed / prebaked and stored in vertices or textures?  Need to squeeze those into GBuffer!</p><p> æ–°çš„é˜´å½±æ¨¡å‹ï¼Ÿæ–°çš„æŸ¥è¯¢è¡¨ï¼Ÿé¢„è®¡ç®—/é¢„çƒ˜ç„™å¹¶å­˜å‚¨åœ¨é¡¶ç‚¹æˆ–çº¹ç†ä¸­çš„æ–°æ•°æ®ï¼Ÿéœ€è¦å°†å®ƒä»¬å‹ç¼©åˆ°GBufferä¸­ï¼ </p><p> Modern GPUs handle branching and divergence with ease (provided there is â€œsomeâ€ coherency), but it can complicate the pipeline and lead to â€œexclusiveâ€ features.</p><p>ç°ä»£GPUå¯ä»¥è½»æ¾å¤„ç†åˆ†æ”¯å’Œå‘æ•£ï¼ˆå‰ææ˜¯å­˜åœ¨â€œæŸç§â€ä¸€è‡´æ€§ï¼‰ï¼Œä½†å®ƒä¼šä½¿ç®¡é“å¤æ‚åŒ–å¹¶å¯¼è‡´â€œä¸“æœ‰â€åŠŸèƒ½ã€‚</p><p> For example on God of War you couldnâ€™t use subsurface scattering at the same time as the cloth/retroreflective specular model due to them (re)using same slots in the GBuffer. The GBuffer itself was very memory heavy anyway and there were many more mutually exclusive features â€“ I had many possible combinations written out in my notebook (IIRC there were 6 bits just for encoding the material type + its features) and â€œnegotiatingâ€ those compromises between different artists who all had different uses and needs.</p><p> ä¾‹å¦‚ï¼Œåœ¨ã€Šæˆ˜ç¥ã€‹ä¸­ï¼Œæ‚¨ä¸èƒ½ä¸å¸ƒæ–™/åå°„é•œé¢æ¨¡å‹åŒæ—¶ä½¿ç”¨æ¬¡è¡¨é¢æ•£å°„ï¼Œå› ä¸ºå®ƒä»¬ï¼ˆé‡æ–°ï¼‰ä½¿ç”¨äº†GBufferä¸­çš„ç›¸åŒæ’æ§½ã€‚æ— è®ºå¦‚ä½•ï¼ŒGBufferæœ¬èº«éƒ½å ç”¨å¤§é‡å†…å­˜ï¼Œå¹¶ä¸”è¿˜æœ‰æ›´å¤šäº’æ–¥çš„åŠŸèƒ½â€“æˆ‘åœ¨ç¬”è®°æœ¬ä¸­å†™äº†è®¸å¤šå¯èƒ½çš„ç»„åˆï¼ˆIIRCæœ‰6ä½ä»…ç”¨äºç¼–ç ææ–™ç±»å‹åŠå…¶åŠŸèƒ½ï¼‰ï¼Œå¹¶â€œåå•†â€æœ‰ä¸åŒç”¨é€”å’Œéœ€æ±‚çš„ä¸åŒè‰ºæœ¯å®¶ã€‚</p><p>   In most cinematics, there are  heavy camera cuts all the time to show different characters, different perspectives of the scene, or maybe action happening in parallel. This is a tool widely used in all kinds cinema (maybe except for  Dogme 95 or Birdman ğŸ˜‰ ), and if a cinematic artist wants to use it, it needs to be supported.</p><p>   åœ¨å¤§å¤šæ•°ç”µå½±ä¸­ï¼Œå§‹ç»ˆä¼šæœ‰å¤§é‡çš„æ‘„åƒæœºé•œå¤´å‰ªè¾‘ä»¥æ˜¾ç¤ºä¸åŒçš„è§’è‰²ï¼Œä¸åŒçš„åœºæ™¯è§†è§’ï¼Œæˆ–è€…å¯èƒ½åŒæ—¶å‘ç”ŸåŠ¨ä½œã€‚è¿™æ˜¯ä¸€ç§å¹¿æ³›ç”¨äºå„ç§ç”µå½±é™¢çš„å·¥å…·ï¼ˆä¹Ÿè®¸Dogme 95æˆ–Birdman excepté™¤å¤–ï¼‰ï¼Œå¦‚æœç”µå½±è‰ºæœ¯å®¶æƒ³è¦ä½¿ç”¨å®ƒï¼Œåˆ™éœ€è¦å¯¹å…¶è¿›è¡Œæ”¯æŒã€‚</p><p> But what happens when the camera cuts with all the per-pixel temporal accumulation history for TAA/temporal supersampling? How about all the texture streaming that suddenly sees a completely new view? View-dependent amortized rendering like shadowmap caching? All solvable, but also a lot of work, or might introduce unacceptable delay / popping / prohibitive cost of the new frame.Â A colleague of mine also noted that this is a problem for physics or animations â€“ often when the camera cuts and animators adjusted some positions, you see physical objects â€œsettling inâ€, for example a necklace move on a character. Another immersion breaker that requires another series of custom â€œhacksâ€.</p><p> ä½†æ˜¯ï¼Œå½“ç›¸æœºä½¿ç”¨TAA /æ—¶é—´è¶…é‡‡æ ·çš„æ‰€æœ‰æ¯ä¸ªåƒç´ çš„æ—¶é—´ç´¯ç§¯å†å²è®°å½•è¿›è¡Œå‰ªåˆ‡æ—¶ï¼Œä¼šå‘ç”Ÿä»€ä¹ˆï¼Ÿçªç„¶çœ‹åˆ°å…¨æ–°è§†å›¾çš„æ‰€æœ‰çº¹ç†æµå¦‚ä½•å¤„ç†ï¼Ÿä¸è§†å›¾ç›¸å…³çš„æ‘Šé”€æ¸²æŸ“ï¼Œä¾‹å¦‚é˜´å½±æ˜ å°„ç¼“å­˜ï¼Ÿæ‰€æœ‰è¿™äº›éƒ½å¯ä»¥è§£å†³ï¼Œä½†ä¹Ÿéœ€è¦å¤§é‡å·¥ä½œï¼Œå¦åˆ™å¯èƒ½ä¼šå¯¼è‡´æ–°æ¡†æ¶çš„å»¶è¿Ÿ/å¼¹å‡º/æˆæœ¬è¿‡é«˜ã€‚æˆ‘çš„ä¸€ä½åŒäº‹è¿˜æŒ‡å‡ºï¼Œè¿™æ˜¯ç‰©ç†æˆ–åŠ¨ç”»æ–¹é¢çš„é—®é¢˜â€“é€šå¸¸å½“ç›¸æœºåˆ‡å‰²å¹¶ä¸”åŠ¨ç”»å¸ˆè°ƒæ•´äº†æŸäº›ä½ç½®æ—¶ï¼Œæ‚¨ä¼šçœ‹åˆ°ç‰©ç†ç‰©ä½“â€œæ²‰å…¥å…¶ä¸­â€ï¼Œä¾‹å¦‚é¡¹é“¾åœ¨è§’è‰²ä¸Šç§»åŠ¨ã€‚å¦ä¸€ä¸ªæµ¸å…¥å¼æ–­è·¯å™¨éœ€è¦å¦ä¸€ç³»åˆ—çš„è‡ªå®šä¹‰â€œ hacksâ€ã€‚</p><p> Conversely,  lack of camera cuts (like in  God of War) is also difficult, especially for cinematics lighting, good animations, transitions etc. In any case â€“ both need to be solved/accounted for. Even worth adding a flag â€œcamera was cutâ€ in the renderer.</p><p> ç›¸åï¼Œç¼ºä¹é•œå¤´çš„è£å‰ªä¹Ÿå¾ˆå›°éš¾ï¼ˆä¾‹å¦‚åœ¨ã€Šæˆ˜ç¥ã€‹ä¸­ï¼‰ï¼Œå°¤å…¶æ˜¯å¯¹äºç”µå½±ç…§æ˜ï¼Œè‰¯å¥½çš„åŠ¨ç”»ï¼Œè½¬åœºç­‰ã€‚æ— è®ºå¦‚ä½•ï¼Œè¿™ä¸¤è€…éƒ½éœ€è¦è§£å†³/è§£å†³ã€‚ç”šè‡³å€¼å¾—åœ¨æ¸²æŸ“å™¨ä¸­æ·»åŠ æ ‡å¿—â€œç›¸æœºè¢«å‰ªåˆ‡â€ã€‚</p><p>  Games generally donâ€™t render what you donâ€™t see in the camera frustum â€“ which is obviously desirable, as why would you waste cycles on it?</p><p>  æ¸¸æˆé€šå¸¸ä¸ä¼šå‘ˆç°æ‚¨åœ¨æ‘„åƒæœºè§†é”¥ä¸­çœ‹ä¸åˆ°çš„å†…å®¹-è¿™æ˜¾ç„¶æ˜¯å¯å–çš„ï¼Œå› ä¸ºä¸ºä»€ä¹ˆæ‚¨ä¼šæµªè´¹æ—¶é—´å‘¢ï¼Ÿ</p><p>  Now, it gets more complicated! Why would you animate objects that are not visible? Not doing so can save a lot of CPU time.</p><p>  ç°åœ¨ï¼Œå®ƒå˜å¾—æ›´åŠ å¤æ‚ï¼ä¸ºä»€ä¹ˆè¦è®¾ç½®ä¸å¯è§å¯¹è±¡çš„åŠ¨ç”»ï¼Ÿä¸è¿™æ ·åšå¯ä»¥èŠ‚çœå¤§é‡CPUæ—¶é—´ã€‚ </p><p> However things being visible in the main view is only part of the story â€“ there are reflections, shadowsâ€¦ I cannot count in how many games I have seen the shadows of the off-screen characters in the â€œT-poseâ€ (default pose when a character is not animated). Raytracing that can â€œtouchâ€ any objects poses a new challenge here!</p><p>ä½†æ˜¯ï¼Œåœ¨ä¸»è§†å›¾ä¸­å¯è§çš„å†…å®¹åªæ˜¯æ•…äº‹çš„ä¸€éƒ¨åˆ†â€“åå°„ï¼Œé˜´å½±â€¦â€¦æˆ‘ä¸èƒ½æŒ‡æœ›åœ¨â€œ Tå§¿åŠ¿â€ï¼ˆé»˜è®¤å§¿åŠ¿ä¸ºè§’è‰²æ²¡æœ‰åŠ¨ç”»ï¼‰ã€‚å¯ä»¥â€œè§¦æ‘¸â€ä»»ä½•ç‰©ä½“çš„å…‰çº¿è¿½è¸ªåœ¨è¿™é‡Œæå‡ºäº†æ–°çš„æŒ‘æˆ˜ï¼</p><p>   Occlusion culling is the next step after frustum culling. You donâ€™t want to render things outside of the camera? Sure. But if in front of the camera there is a huge building, you also  donâ€™t want to render the whole city behind it!</p><p>   æˆªé”¥å‰”é™¤æ˜¯å¹³æˆªå¤´å‰”é™¤ä¹‹åçš„ä¸‹ä¸€æ­¥ã€‚æ‚¨ä¸æƒ³åœ¨ç›¸æœºå¤–éƒ¨æ¸²æŸ“ç‰©ä½“å—ï¼Ÿå½“ç„¶ã€‚ä½†æ˜¯ï¼Œå¦‚æœåœ¨é•œå¤´å‰æœ‰ä¸€ä¸ªå·¨å¤§çš„å»ºç­‘ç‰©ï¼Œé‚£ä¹ˆæ‚¨ä¹Ÿä¸æƒ³åœ¨å…¶åé¢æ¸²æŸ“æ•´ä¸ªåŸå¸‚ï¼</p><p>  Robust occlusion culling (together with the LOD, streaming etc. below) is in many ways an unsolved problem â€“ all existing solutions require compromises, precomputation, or extremely complex pipelines.</p><p>  å¥å£®çš„é®æŒ¡å‰”é™¤ï¼ˆè¿åŒä¸‹é¢çš„LODï¼Œæµç­‰ï¼‰åœ¨è®¸å¤šæ–¹é¢éƒ½æ˜¯æ— æ³•è§£å†³çš„é—®é¢˜-æ‰€æœ‰ç°æœ‰è§£å†³æ–¹æ¡ˆéƒ½éœ€è¦æŠ˜è¡·ï¼Œé¢„å…ˆè®¡ç®—æˆ–æå…¶å¤æ‚çš„ç®¡é“ã€‚</p><p> In a way an occlusion culling system is a new rendering feature that has to go through all the steps that I list in this post! ğŸ™‚ But given its complexity and general fragility of many solutions â€“ yet another aspect to consider, we donâ€™t want to make it even more difficult.</p><p> åœ¨æŸç§ç¨‹åº¦ä¸Šï¼Œé®æŒ¡å‰”é™¤ç³»ç»Ÿæ˜¯ä¸€é¡¹æ–°çš„æ¸²æŸ“åŠŸèƒ½ï¼Œå¿…é¡»ç»è¿‡æˆ‘åœ¨æœ¬æ–‡ä¸­åˆ—å‡ºçš„æ‰€æœ‰æ­¥éª¤ï¼ ğŸ™‚ä½†æ˜¯ï¼Œé‰´äºå…¶å¤æ‚æ€§å’Œè®¸å¤šè§£å†³æ–¹æ¡ˆçš„æ€»ä½“è„†å¼±æ€§-éœ€è¦è€ƒè™‘çš„å¦ä¸€ä¸ªæ–¹é¢ï¼Œæˆ‘ä»¬ä¸æƒ³ä½¿å…¶å˜å¾—æ›´åŠ å›°éš¾ã€‚</p><p>  Any technique that requires some computational budget to render and memory usage needs to â€œscaleâ€ properly with distance. When the rendered object is 100m away and occupies a few pixels, you donâ€™t want it to eat 100MB of memory or its rendering/</p><p>  ä»»ä½•éœ€è¦ä¸€äº›è®¡ç®—é¢„ç®—æ¥æ¸²æŸ“å’Œå ç”¨å†…å­˜çš„æŠ€æœ¯éƒ½éœ€è¦éšè·ç¦»é€‚å½“åœ°â€œç¼©æ”¾â€ã€‚å½“æ¸²æŸ“çš„å¯¹è±¡åœ¨100mä¹‹å¤–ä¸”å ç”¨å‡ ä¸ªåƒç´ æ—¶ï¼Œæ‚¨ä¸å¸Œæœ›å®ƒå ç”¨100MBçš„å†…å­˜æˆ–å®ƒçš„æ¸²æŸ“/</p><p>......</p><p>...... </p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://bartwronski.com/2020/12/27/why-are-video-games-graphics-still-a-challenge-productionizing-rendering-algorithms/">https://bartwronski.com/2020/12/27/why-are-video-games-graphics-still-a-challenge-productionizing-rendering-algorithms/</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/æ¸¸æˆ/">#æ¸¸æˆ</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/games/">#games</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/æ¸²æŸ“/">#æ¸²æŸ“</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/è®¾è®¡/">#è®¾è®¡</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/åˆ›æ„/">#åˆ›æ„</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/æ‘„å½±/">#æ‘„å½±</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/æ¸¸æˆ/">#æ¸¸æˆ</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/å›¾ç‰‡/">#å›¾ç‰‡</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/è½¯ä»¶/">#è½¯ä»¶</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/è§†é¢‘/">#è§†é¢‘</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/æ‰‹æœº/">#æ‰‹æœº</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/å¹¿å‘Š/">#å¹¿å‘Š</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/ç½‘ç«™/">#ç½‘ç«™</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/å…è´¹/">#å…è´¹</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/ä¸‹è½½/">#ä¸‹è½½</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/è‹¹æœ/">#è‹¹æœ</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/å¾®è½¯/">#å¾®è½¯</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/éŸ³ä¹/">#éŸ³ä¹</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/åšå®¢/">#åšå®¢</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/æ¶æ/">#æ¶æ</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/è‰ºæœ¯/">#è‰ºæœ¯</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/å·¥å…·/">#å·¥å…·</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/åˆ†äº«/">#åˆ†äº«</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy; 2020 diglog.com </div></div></body></html>