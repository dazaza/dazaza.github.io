<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Ditherpunkï¼šæˆ‘å¸Œæœ›æˆ‘æœ‰å…³äºå•è‰²å›¾åƒæŠ–åŠ¨çš„æ–‡ç«  Ditherpunk: The article I wish I had about monochrome image dithering</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">Ditherpunk: The article I wish I had about monochrome image dithering<br/>Ditherpunkï¼šæˆ‘å¸Œæœ›æˆ‘æœ‰å…³äºå•è‰²å›¾åƒæŠ–åŠ¨çš„æ–‡ç«  </h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2021-01-05 02:11:31</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2021/1/3cfb1c23dd89084f2a7884c9e8670b50.png"><img src="http://img2.diglog.com/img/2021/1/3cfb1c23dd89084f2a7884c9e8670b50.png" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>I always loved the visual aesthetic of dithering but never knew how itâ€™s done. So I did some research. This article may contain traces of nostaliga and none of Lena.</p><p>æˆ‘ä¸€ç›´å¾ˆå–œæ¬¢æŠ–åŠ¨çš„è§†è§‰ç¾æ„Ÿï¼Œä½†ä»æ¥ä¸çŸ¥é“å®ƒæ˜¯å¦‚ä½•å®Œæˆçš„ã€‚æ‰€ä»¥æˆ‘åšäº†ä¸€äº›ç ”ç©¶ã€‚æœ¬æ–‡å¯èƒ½åŒ…å«nostaligaçš„ç—•è¿¹ï¼Œè€Œæ²¡æœ‰Lenaçš„ç—•è¿¹ã€‚</p><p>     I am late to the party, but I finally played  â€œReturn of the Obra Dinnâ€, the most recent game by  Lucas Pope of  â€œPapers Pleaseâ€ fame. Obra Dinn is a story puzzler that I can only recommend, but what piqued my curiosity as a software engineer is that it is a 3D game (using the  Unity game engine) but rendered using only 2 colors with dithering. Apparently, this has been dubbed â€œDitherpunkâ€, and I love that.</p><p>     æˆ‘å‚åŠ èšä¼šçš„æ—¶é—´å¾ˆæ™šï¼Œä½†æœ€ç»ˆæˆ‘ç©äº†å¢å¡æ–¯Â·æ³¢æ™®ï¼ˆLucas Popeï¼‰æœ€è¿‘ä»¥â€œ Papers Pleaseâ€æˆåçš„æ¸¸æˆâ€œ Obra Dinnçš„å›å½’â€ã€‚ Obra Dinnæ˜¯ä¸€ä¸ªæˆ‘åªèƒ½æ¨èçš„æ•…äº‹è¿·é¢˜è€…ï¼Œä½†æ˜¯å¼•èµ·æˆ‘ä½œä¸ºè½¯ä»¶å·¥ç¨‹å¸ˆçš„å¥½å¥‡å¿ƒçš„æ˜¯ï¼Œå®ƒæ˜¯3Dæ¸¸æˆï¼ˆä½¿ç”¨Unityæ¸¸æˆå¼•æ“ï¼‰ï¼Œä½†æ˜¯ä»…ä½¿ç”¨2ç§é¢œè‰²è¿›è¡ŒæŠ–åŠ¨å¤„ç†ã€‚æ˜¾ç„¶ï¼Œå®ƒè¢«ç§°ä¸ºâ€œ Ditherpunkâ€ï¼Œæˆ‘å¾ˆå–œæ¬¢ã€‚</p><p>    Dithering, so my original understanding, was a technique to place pixels using only a  few colors from a palette in a clever way to trick your brain into seeing  many colors. Like in the picture, where you probably feel like there are multipl brightness levels when in fact thereâ€™s only two: Full brightness and black.</p><p>    é¢¤åŠ¨æ˜¯æˆ‘æœ€åˆçš„ç†è§£ï¼Œæ˜¯ä¸€ç§å·§å¦™åœ°ä½¿ç”¨è°ƒè‰²æ¿ä¸­å‡ ç§é¢œè‰²æ¥æ”¾ç½®åƒç´ çš„æŠ€æœ¯ï¼Œå¯ä»¥è¯±ä½¿æ‚¨çš„å¤§è„‘çœ‹åˆ°å¤šç§é¢œè‰²ã€‚å°±åƒåœ¨å›¾ç‰‡ä¸­ä¸€æ ·ï¼Œæ‚¨å¯èƒ½ä¼šè§‰å¾—å®é™…ä¸Šå­˜åœ¨å¤šé‡äº®åº¦ï¼Œè€Œå®é™…ä¸Šåªæœ‰ä¸¤ä¸ªï¼šå…¨äº®åº¦å’Œé»‘è‰²ã€‚</p><p>  The fact that I have never seen a 3D game with dithering like this probably stems from the fact that color palettes are mostly a thing of the past. You  may remember running Windows 95 with 16 colors and playing games like â€œMonkey Islandâ€ on it.</p><p>  æˆ‘ä»æœªè§è¿‡åƒè¿™æ ·çš„æŠ–åŠ¨çš„3Dæ¸¸æˆï¼Œè¿™å¯èƒ½æ˜¯ç”±äºè°ƒè‰²æ¿å·²æˆä¸ºè¿‡å»çš„äº‹å®ã€‚æ‚¨å¯èƒ½è¿˜è®°å¾—è¿è¡Œ16ç§é¢œè‰²çš„Windows 95å¹¶åœ¨ä¸Šé¢ç©è¿‡ç±»ä¼¼â€œçŒ´å­å²›â€çš„æ¸¸æˆã€‚</p><p>    For a long time now, however, we have had 8 bits per channel per pixel, allowing each pixel on your screen to assume one of 16 million colors. With HDR and wide gamut on the horizon, things are moving even further away to ever requiring any form of dithering. And yet Obra Dinn used it anyway and rekindled a long forgotten love for me. Knowing a tiny bit about dithering from my work on  Squoosh, I was especially impressed with Obra Dinnâ€™s ability to keep the dithering stable while I moved and rotated the camera through 3D space and I wanted to understand how it all worked.</p><p>    ä½†æ˜¯ï¼Œå¾ˆé•¿ä¸€æ®µæ—¶é—´ä»¥æ¥ï¼Œæˆ‘ä»¬æ¯ä¸ªåƒç´ æ¯ä¸ªé€šé“åªæœ‰8ä½ï¼Œå› æ­¤å±å¹•ä¸Šçš„æ¯ä¸ªåƒç´ éƒ½å¯ä»¥é‡‡ç”¨1600ä¸‡ç§é¢œè‰²ä¸­çš„ä¸€ç§ã€‚éšç€HDRå’Œå¹¿æ³›è‰²åŸŸçš„å‡ºç°ï¼Œäº‹æƒ…æ­£å˜å¾—è¶Šæ¥è¶Šè¿œï¼Œä»¥è‡³äºéœ€è¦ä»»ä½•å½¢å¼çš„æŠ–åŠ¨ã€‚ä½†æ˜¯Obra Dinnè¿˜æ˜¯ä½¿ç”¨äº†å®ƒï¼Œå¹¶é‡æ–°ç‡ƒèµ·äº†å¯¹æˆ‘æ—©å·²è¢«é—å¿˜çš„çˆ±ã€‚æˆ‘å¯¹Squooshçš„å·¥ä½œäº†è§£åˆ°ä¸€ç‚¹æŠ–åŠ¨çš„çŸ¥è¯†ï¼Œå½“æˆ‘åœ¨3Dç©ºé—´ä¸­ç§»åŠ¨å’Œæ—‹è½¬ç›¸æœºæ—¶ï¼ŒObra Dinnä¿æŒæŠ–åŠ¨ç¨³å®šçš„èƒ½åŠ›ç»™æˆ‘ç•™ä¸‹äº†ç‰¹åˆ«æ·±åˆ»çš„å°è±¡ï¼Œæˆ‘æƒ³äº†è§£è¿™ä¸€åˆ‡å¦‚ä½•å·¥ä½œã€‚</p><p>  As it turns out, Lucas Pope wrote a  forum post where he explains which dithering techniques he uses and how he applies them to 3D space. He put extensive work into making the dithering stable when camera movements occur. Reading that forum post kicked me down the rabbit hole, which this blog post tries to summarize.</p><p>  äº‹å®è¯æ˜ï¼Œå¢å¡æ–¯Â·æ³¢æ™®ï¼ˆLucas Popeï¼‰åœ¨è®ºå›ä¸Šå‘è¡¨äº†ä¸€ç¯‡æ–‡ç« ï¼Œä»–åœ¨å…¶ä¸­è§£é‡Šäº†ä»–ä½¿ç”¨çš„æŠ–åŠ¨æŠ€æœ¯ä»¥åŠå¦‚ä½•å°†å…¶åº”ç”¨äº3Dç©ºé—´ã€‚ä»–åœ¨æ‘„åƒæœºè¿åŠ¨å‘ç”Ÿæ—¶ä¸ºä½¿æŠ–åŠ¨ç¨³å®šè€Œè¿›è¡Œäº†å¤§é‡å·¥ä½œã€‚é˜…è¯»è¯¥è®ºå›å¸–å­ä¼šæŠŠæˆ‘è¸¢åˆ°å…”å­æ´ï¼Œè¿™ç¯‡åšå®¢æ–‡ç« è¯•å›¾å¯¹æ­¤è¿›è¡Œæ€»ç»“ã€‚</p><p>      According to Wikipedia, â€œDither is an intentionally applied form of noise used to randomize quantization errorâ€, and is a technique not only limited to images. It is actually a technique used to this day on audio recordings, but that is yet another rabbit hole to fall into another time. Letâ€™s dissect that definition in the context of images. First up: Quantization.</p><p>      æ ¹æ®Wikipediaæ‰€è¯´ï¼Œâ€œæŠ–åŠ¨æ˜¯ä¸€ç§æœ‰æ„åº”ç”¨çš„å™ªå£°å½¢å¼ï¼Œç”¨äºä½¿é‡åŒ–è¯¯å·®éšæœºåŒ–â€ï¼Œå¹¶ä¸”æ˜¯ä¸€ç§ä¸ä»…é™äºå›¾åƒçš„æŠ€æœ¯ã€‚è¿™å®é™…ä¸Šæ˜¯è¿„ä»Šä¸ºæ­¢ç”¨äºå½•éŸ³çš„ä¸€ç§æŠ€æœ¯ï¼Œä½†è¿™åˆæ˜¯å¦ä¸€ä¸ªéº»çƒ¦ã€‚è®©æˆ‘ä»¬åœ¨å›¾åƒçš„ä¸Šä¸‹æ–‡ä¸­å‰–æè¯¥å®šä¹‰ã€‚é¦–å…ˆï¼šé‡åŒ–ã€‚ </p><p>    Quantization is the process of mapping a large set of values to a smaller, usually finite, set of values. For the remainder of this article, I am going to use two images as examples:</p><p>é‡åŒ–æ˜¯å°†å¤§é‡å€¼æ˜ å°„åˆ°è¾ƒå°å€¼ï¼ˆé€šå¸¸æ˜¯æœ‰é™å€¼ï¼‰çš„è¿‡ç¨‹ã€‚å¯¹äºæœ¬æ–‡çš„å…¶ä½™éƒ¨åˆ†ï¼Œæˆ‘å°†ä½¿ç”¨ä¸¤ä¸ªå›¾åƒä½œä¸ºç¤ºä¾‹ï¼š</p><p>      Both black-and-white photos use 256 different shades of gray. If we wanted to use fewer colors â€” for example just black and white to achieve monochromaticity â€” we have to change every pixel to be either pure black or pure white. In this scenario, the colors black and white are called our â€œcolor paletteâ€ and the process of changing pixels that do not use a color from the palette is called â€œquantizationâ€. Because not all colors from the original images are in the color palette, this will inevitably introduce an error called the â€œquantization errorâ€. The naÃ¯ve solution is to quantizer each pixel to the color in the palette that is closest to the pixelâ€™s original color.</p><p>      é»‘ç™½ç…§ç‰‡éƒ½ä½¿ç”¨256ç§ä¸åŒçš„ç°è‰²é˜´å½±ã€‚å¦‚æœæˆ‘ä»¬æƒ³ä½¿ç”¨æ›´å°‘çš„é¢œè‰²ï¼ˆä¾‹å¦‚ï¼Œä»…ä½¿ç”¨é»‘è‰²å’Œç™½è‰²ä»¥å®ç°å•è‰²ï¼‰ï¼Œåˆ™å¿…é¡»å°†æ¯ä¸ªåƒç´ æ›´æ”¹ä¸ºçº¯é»‘è‰²æˆ–çº¯ç™½è‰²ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œé»‘è‰²å’Œç™½è‰²ç§°ä¸ºæˆ‘ä»¬çš„â€œè°ƒè‰²æ¿â€ï¼Œè€Œæ›´æ”¹ä¸ä½¿ç”¨è°ƒè‰²æ¿ä¸­é¢œè‰²çš„åƒç´ çš„è¿‡ç¨‹ç§°ä¸ºâ€œé‡åŒ–â€ã€‚ç”±äºå¹¶éåŸå§‹å›¾åƒä¸­çš„æ‰€æœ‰é¢œè‰²éƒ½åœ¨è°ƒè‰²æ¿ä¸­ï¼Œå› æ­¤ä¸å¯é¿å…åœ°ä¼šå¼•å…¥ç§°ä¸ºâ€œé‡åŒ–é”™è¯¯â€çš„é”™è¯¯ã€‚å¤©çœŸçš„è§£å†³æ–¹æ¡ˆæ˜¯å°†æ¯ä¸ªåƒç´ é‡åŒ–ä¸ºæœ€æ¥è¿‘è°ƒè‰²æ¿åŸå§‹é¢œè‰²çš„è°ƒè‰²æ¿ä¸­çš„é¢œè‰²ã€‚</p><p>  Note: Defining which colors are â€œclose to each otherâ€ is open to interpretation and depends on how you measure the distance between two colors. I suppose ideally weâ€™d measure distance in a psycho-visual way, but most of the articles I found simply used the euclidian distance in the RGB cube, i.e.         Î”  red 2 + Î”  green 2 + Î”  blue 2 \sqrt{\Delta\text{red}^2 + \Delta\text{green}^2 + \Delta\text{blue}^2}           Î”   red        2  +  Î”   green        2  +  Î”   blue        2      â€‹   .</p><p>  æ³¨æ„ï¼šå®šä¹‰å“ªäº›é¢œè‰²â€œå½¼æ­¤æ¥è¿‘â€å°šå¾…è§£é‡Šï¼Œå¹¶ä¸”å–å†³äºæ‚¨å¦‚ä½•æµ‹é‡ä¸¤ç§é¢œè‰²ä¹‹é—´çš„è·ç¦»ã€‚æˆ‘æƒ³ç†æƒ³çš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬åº”è¯¥ä»¥ä¸€ç§å¿ƒç†è§†è§‰çš„æ–¹å¼æ¥æµ‹é‡è·ç¦»ï¼Œä½†æ˜¯æˆ‘å‘ç°çš„å¤§å¤šæ•°æ–‡ç« éƒ½åªæ˜¯åœ¨RGBç«‹æ–¹ä½“ä¸­ä½¿ç”¨äº†æ¬§å‡ é‡Œå¾—è·ç¦»ï¼Œå³Î”çº¢è‰²2 +Î”ç»¿è‰²2 +Î”è“è‰²2 \ sqrt {\ Delta \ text {red} ^ 2 + \ Delta \ text {green} ^ 2 + \ Delta \ text {blue} ^ 2}Î”red 2 +Î”green 2 +Î”blue 2ã€‚</p><p>  With our palette only consisting of black and white, we can use the brightness of a pixel to decide which color to quantize to. A brightness of 0 means black, a brightness of 1 means white, everything else is in-between, ideally correlating with human perception such that a brightness of 0.5 is a nice mid-gray. To quantize a given color, we only need to check if the colorâ€™s brightness is greater or less than 0.5 and quantize to white and black respectively. Applying this quantization to the image above yields an... unsatisfying result.</p><p>  ä½¿ç”¨ä»…ç”±é»‘ç™½ç»„æˆçš„è°ƒè‰²æ¿ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨åƒç´ çš„äº®åº¦æ¥ç¡®å®šè¦é‡åŒ–çš„é¢œè‰²ã€‚äº®åº¦0è¡¨ç¤ºé»‘è‰²ï¼Œäº®åº¦1è¡¨ç¤ºç™½è‰²ï¼Œå…¶ä»–æ‰€æœ‰ä¸œè¥¿éƒ½ä»‹äºä¸¤è€…ä¹‹é—´ï¼Œç†æƒ³æƒ…å†µä¸‹ä¸äººç±»çš„æ„ŸçŸ¥ç›¸å…³ï¼Œå› æ­¤äº®åº¦0.5ä»£è¡¨ä¸­ç­‰ç°è‰²ã€‚è¦é‡åŒ–ç»™å®šçš„é¢œè‰²ï¼Œæˆ‘ä»¬åªéœ€è¦æ£€æŸ¥é¢œè‰²çš„äº®åº¦æ˜¯å¤§äºè¿˜æ˜¯å°äº0.5ï¼Œç„¶ååˆ†åˆ«é‡åŒ–ä¸ºç™½è‰²å’Œé»‘è‰²ã€‚å°†æ­¤é‡åŒ–åº”ç”¨äºä¸Šé¢çš„å›¾åƒä¼šäº§ç”Ÿä»¤äººä¸æ»¡æ„çš„ç»“æœã€‚</p><p>    Note: The code samples in this article are real but built on top of a helper class  GrayImageF32N0F8 I wrote for the  demo of this article. Itâ€™s similar to the webâ€™s   ImageData, but uses  Float32Array, only has one color channel, represents values between 0.0 and 1.0 and has a whole bunch of helper functions. The source code is available in  the lab.</p><p>    æ³¨æ„ï¼šæœ¬æ–‡ä¸­çš„ä»£ç ç¤ºä¾‹æ˜¯çœŸå®çš„ï¼Œä½†æ˜¯åŸºäºæˆ‘ä¸ºæœ¬æ–‡çš„æ¼”ç¤ºç¼–å†™çš„è¾…åŠ©ç±»GrayImageF32N0F8æ„å»ºã€‚å®ƒç±»ä¼¼äºç½‘ç»œä¸Šçš„ImageDataï¼Œä½†ä½¿ç”¨Float32Arrayï¼Œä»…å…·æœ‰ä¸€ä¸ªé¢œè‰²é€šé“ï¼Œè¡¨ç¤º0.0åˆ°1.0ä¹‹é—´çš„å€¼ï¼Œå¹¶å…·æœ‰å¤§é‡å¸®åŠ©å‡½æ•°ã€‚æºä»£ç åœ¨å®éªŒå®¤ä¸­å¯ç”¨ã€‚</p><p>      I had finished writing this article and just wanted to â€œquicklyâ€ look what a black-to-white gradient looks like with the different dithering algorithms. The results showed me that I failed to consider  the thing that always becomes a problem when working with images: color spaces. I had written the sentence â€œideally correlating with human perceptionâ€ without actually following it myself.</p><p>      æˆ‘å·²ç»å†™å®Œäº†è¿™ç¯‡æ–‡ç« ï¼Œåªæ˜¯æƒ³â€œå¿«é€Ÿåœ°â€äº†è§£ä½¿ç”¨ä¸åŒçš„æŠ–åŠ¨ç®—æ³•æ—¶é»‘ç™½æ¸å˜çš„å¤–è§‚ã€‚ç»“æœè¡¨æ˜ï¼Œæˆ‘æ²¡æœ‰è€ƒè™‘ä½¿ç”¨å›¾åƒæ—¶æ€»æ˜¯æˆä¸ºé—®é¢˜çš„ä¸œè¥¿ï¼šè‰²å½©ç©ºé—´ã€‚æˆ‘å†™çš„å¥å­â€œä¸äººç±»çš„è§‚å¿µæœ‰ç†æƒ³çš„è”ç³»â€ï¼Œä½†æˆ‘æœ¬äººå¹¶æ²¡æœ‰çœŸæ­£è·Ÿéšå®ƒã€‚</p><p>  My  demo is implemented using web technologies, most notably  &lt;canvas&gt; and  ImageData, which are â€” at the time of writing â€” specified to use  sRGB. Itâ€™s an old color space specification (from 1996) whose value-to-color mapping was modeled to mirror the behavior of CRT monitors. While barely anyone uses CRTs these days, itâ€™s still considered the â€œsafeâ€ color space that gets correctly displayed on every display. As such, it is the default on the web platform. However, sRGB is not linear, meaning that       ( 0.5 , 0.5 , 0.5 ) (0.5, 0.5, 0.5)    ( 0 . 5 ,  0 . 5 ,  0 . 5 ) in sRGB is  not the color a human sees when you mix 50% of       ( 0 , 0 , 0 ) (0, 0, 0)    ( 0 ,  0 ,  0 ) and       ( 1 , 1 , 1 ) (1, 1, 1)    ( 1 ,  1 ,  1 ). Instead, itâ€™s the color you get when you pump half the power of full white through your Cathod-Ray Tube (CRT).</p><p>  æˆ‘çš„æ¼”ç¤ºæ˜¯ä½¿ç”¨WebæŠ€æœ¯ï¼ˆæœ€è‘—åçš„æ˜¯ï¼†quot; canvasï¼†gt;å’ŒImageDataï¼Œåœ¨æ’°å†™æœ¬æ–‡æ—¶å·²æŒ‡å®šä½¿ç”¨sRGBã€‚è¿™æ˜¯ä¸€ä¸ªå¤è€çš„è‰²å½©ç©ºé—´è§„èŒƒï¼ˆå§‹äº1996å¹´ï¼‰ï¼Œå…¶å€¼å¯¹é¢œè‰²çš„æ˜ å°„è¢«å»ºæ¨¡ä¸ºåæ˜ CRTæ˜¾ç¤ºå™¨çš„è¡Œä¸ºã€‚å°½ç®¡å¦‚ä»Šå‡ ä¹æ²¡æœ‰äººä½¿ç”¨CRTï¼Œä½†ä»è¢«è®¤ä¸ºæ˜¯å¯ä»¥åœ¨æ¯ä¸ªæ˜¾ç¤ºå™¨ä¸Šæ­£ç¡®æ˜¾ç¤ºçš„â€œå®‰å…¨â€è‰²å½©ç©ºé—´ã€‚å› æ­¤ï¼Œå®ƒæ˜¯Webå¹³å°ä¸Šçš„é»˜è®¤è®¾ç½®ã€‚ä½†æ˜¯ï¼ŒsRGBä¸æ˜¯çº¿æ€§çš„ï¼Œè¿™æ„å‘³ç€å½“æ‚¨æ··åˆ50ï¼…æ—¶ï¼ŒsRGBä¸­çš„ï¼ˆ0.5ï¼Œ0.5ï¼Œ0.5ï¼‰ï¼ˆ0.5ï¼Œ0.5ï¼Œ0.5ï¼‰ï¼ˆ0.5,0.5,0.5ï¼‰ä¸æ˜¯äººç±»çœ‹åˆ°çš„é¢œè‰²ï¼ˆ0ï¼Œ0ï¼Œ0ï¼‰ï¼ˆ0ï¼Œ0ï¼Œ0ï¼‰ï¼ˆ0ï¼Œ0ï¼Œ0ï¼‰å’Œï¼ˆ1ï¼Œ1ï¼Œ1ï¼‰ï¼ˆ1ï¼Œ1ï¼Œ1ï¼‰ï¼ˆ1ï¼Œ1ï¼Œ1ï¼‰ä¸­çš„ã€‚ç›¸åï¼Œå®ƒæ˜¯é€šè¿‡é˜´æå°„çº¿ç®¡ï¼ˆCRTï¼‰æ³µæµ¦å…¨ç™½å…‰ä¸€åŠåŠŸç‡æ—¶å¾—åˆ°çš„é¢œè‰²ã€‚ </p><p>    As this image shows, the dithered gradient gets bright way too quickly. If we want 0.5 be the color in the middle of pure black and white (as perceived by a human), we need to convert from sRGB to linear RGB space, which can be done with a process called â€œgamma correctionâ€. Wikipedia lists the following formulas to convert between sRGB and linear RGB.</p><p>å¦‚è¯¥å›¾æ‰€ç¤ºï¼ŒæŠ–åŠ¨æ¸å˜å¤ªäº®äº†ã€‚å¦‚æœæˆ‘ä»¬æƒ³è®©0.5æˆä¸ºçº¯é»‘è‰²å’Œç™½è‰²ï¼ˆå¦‚äººç±»æ‰€æ„ŸçŸ¥ï¼‰ä¸­é—´çš„é¢œè‰²ï¼Œåˆ™éœ€è¦å°†sRGBè½¬æ¢ä¸ºçº¿æ€§RGBç©ºé—´ï¼Œè¿™å¯ä»¥é€šè¿‡ç§°ä¸ºâ€œä¼½ç›æ ¡æ­£â€çš„è¿‡ç¨‹æ¥å®Œæˆã€‚ç»´åŸºç™¾ç§‘åˆ—å‡ºäº†ä»¥ä¸‹å…¬å¼ï¼Œå¯åœ¨sRGBå’Œçº¿æ€§RGBä¹‹é—´è½¬æ¢ã€‚</p><p>  srgbToLinear ( b )   =    {      b 12.92    b â‰¤ 0.04045      (   b + 0.055 1.055 ) Î³   otherwise     linearToSrgb ( b )   =    {      12.92 â‹… b    b â‰¤ 0.0031308     1.055 â‹…  b  1 Î³ âˆ’ 0.055   otherwise     ( Î³ = 2.4 )  \begin{array}{rcl} \text{srgbToLinear}(b) &amp; = &amp; \left\{\begin{array}{ll} \frac{b}{12.92} &amp; b \le 0.04045 \\ \left( \frac{b + 0.055}{1.055}\right)^{\gamma} &amp; \text{otherwise} \end{array}\right.\\ \text{linearToSrgb}(b) &amp; = &amp; \left\{\begin{array}{ll} 12.92\cdot b &amp; b \le 0.0031308 \\ 1.055 \cdot b^\frac{1}{\gamma} - 0.055 &amp; \text{otherwise} \end{array}\right.\\ (\gamma = 2.4) \end{array}\\                srgbToLinear ( b )     linearToSrgb ( b )    ( Î³  =  2 . 4 ) â€‹             =    = â€‹               {                     1 2 . 9 2        b â€‹           (           1 . 0 5 5        b + 0 . 0 5 5 â€‹      )         Î³ â€‹             b  â‰¤  0 . 0 4 0 4 5     otherwise â€‹           {           1 2 . 9 2  â‹…  b    1 . 0 5 5  â‹…   b                  Î³        1 â€‹      âˆ’  0 . 0 5 5 â€‹             b  â‰¤  0 . 0 0 3 1 3 0 8     otherwise â€‹      â€‹</p><p>  srgbToLinearï¼ˆbï¼‰= {b 12.92 bâ‰¤0.04045ï¼ˆb + 0.055 1.055ï¼‰Î³å¦åˆ™linearToSrgbï¼ˆbï¼‰= {12.92â‹…bbâ‰¤0.0031308 1.055â‹…b 1Î³-0.055å¦åˆ™ï¼ˆÎ³= 2.4ï¼‰\ begin {array} {rcl } \ text {srgbToLinear}ï¼ˆbï¼‰ï¼†amp; =ï¼†amp; \ left \ {\ begin {array} {ll} \ frac {b} {12.92}ï¼†amp; b \ le 0.04045 \\ \ leftï¼ˆ\ frac {b + 0.055} {1.055} \ rightï¼‰^ {\ gamma}ï¼†amp; \ text {å¦åˆ™} \ end {array} \æ­£ç¡®ã€‚\\ \ text {linearToSrgb}ï¼ˆbï¼‰ï¼†amp; =ï¼†amp; \ left \ {\ begin {array} {ll} 12.92 \ cdot bï¼†amp; b \ le 0.0031308 \\ 1.055 \ cdot b ^ \ frac {1} {\ gamma}-0.055ï¼†amp; \ text {otherwise} \ end {array} \ rightã€‚\\ï¼ˆ\ gamma = 2.4ï¼‰\ end {array} \\ srgbToLinearï¼ˆbï¼‰linearToSrgbï¼ˆbï¼‰ï¼ˆÎ³= 2ã€‚4ï¼‰= = {1 2 ã€‚ 9 2 bï¼ˆ1ã€‚0 5 5 b + 0ã€‚0 5 5ï¼‰Î³bâ‰¤0ã€‚ 0 4 0 4 5å¦åˆ™{1 2ã€‚ 9 2â‹…b 1ã€‚ 0 5 5â‹…bÎ³1 âˆ’ 0ã€‚ 0 5 5 bâ‰¤0ã€‚ 0 0 3 1 3 0 8å¦åˆ™</p><p>        Back to Wikipediaâ€™s definition of dithering: â€œIntentionally applied form of noise used to randomize quantization errorâ€. We got the quantization down, and now it says to add noise.  Intentionally.</p><p>        å›åˆ°Wikipediaå¯¹æŠ–åŠ¨çš„å®šä¹‰ï¼šâ€œæœ‰æ„åº”ç”¨çš„å™ªå£°å½¢å¼ï¼Œç”¨äºä½¿é‡åŒ–è¯¯å·®éšæœºåŒ–â€ã€‚æˆ‘ä»¬é™ä½äº†é‡åŒ–ï¼Œç°åœ¨è¯´å¢åŠ äº†å™ªå£°ã€‚æ•…æ„åœ°ã€‚</p><p>  Instead of quantizing each pixel directly, we add noise with a value between -0.5 and 0.5 to each pixel. The idea is that some pixels will now be quantized to the â€œwrongâ€ color, but how often that happens depends on the pixelâ€™s original brightness. Black will  always remain black, white will  always remain white, a mid-gray will be dithered to black roughly 50% of the time. Statistically, the overall quantization error is reduced and our brains are eager to do the rest and help you see the, uh, big picture.</p><p>  ä»£æ›¿ç›´æ¥é‡åŒ–æ¯ä¸ªåƒç´ ï¼Œæˆ‘ä»¬å‘æ¯ä¸ªåƒç´ æ·»åŠ å€¼åœ¨-0.5åˆ°0.5ä¹‹é—´çš„å™ªå£°ã€‚è¿™ä¸ªæƒ³æ³•æ˜¯ï¼Œä¸€äº›åƒç´ ç°åœ¨å°†è¢«é‡åŒ–ä¸ºâ€œé”™è¯¯â€çš„é¢œè‰²ï¼Œä½†æ˜¯è¿™ç§æƒ…å†µå‘ç”Ÿçš„é¢‘ç‡å–å†³äºåƒç´ çš„åŸå§‹äº®åº¦ã€‚é»‘è‰²å°†å§‹ç»ˆä¿æŒé»‘è‰²ï¼Œç™½è‰²å°†å§‹ç»ˆä¿æŒç™½è‰²ï¼Œä¸­ç°è‰²å¤§çº¦50ï¼…çš„æ—¶é—´ä¼šæŠ–åŠ¨ä¸ºé»‘è‰²ã€‚ä»ç»Ÿè®¡ä¸Šè®²ï¼Œæ•´ä½“é‡åŒ–è¯¯å·®æœ‰æ‰€å‡å°‘ï¼Œæˆ‘ä»¬çš„å¤§è„‘æ€¥äºè¿›è¡Œå…¶ä½™å·¥ä½œï¼Œå¹¶å¸®åŠ©æ‚¨äº†è§£å¤§å±€ã€‚</p><p>      I found this quite surprising! It is by no means  good â€” video games from the 90s have shown us that we can do better â€” but this is a very low effort and quick way to get more detail into a monochrome image. And if I was to take â€œditheringâ€ literally, Iâ€™d end my article here. But thereâ€™s moreâ€¦</p><p>      æˆ‘å‘ç°è¿™å¾ˆä»¤äººæƒŠè®¶ï¼è¿™ç»å¯¹ä¸æ˜¯ä¸€ä»¶å¥½äº‹â€” 90å¹´ä»£çš„è§†é¢‘æ¸¸æˆå‘æˆ‘ä»¬å±•ç¤ºäº†æˆ‘ä»¬å¯ä»¥åšå¾—æ›´å¥½â€”ä½†è¿™æ˜¯ä¸€ç§éå¸¸çœåŠ›ä¸”å¿«æ·çš„æ–¹æ³•ï¼Œå¯ä»¥å°†æ›´å¤šç»†èŠ‚å˜ä¸ºå•è‰²å›¾åƒã€‚å¦‚æœè¦æŒ‰å­—é¢æ„ä¹‰è¿›è¡Œâ€œæŠ–åŠ¨â€ï¼Œæˆ‘å°†åœ¨è¿™é‡Œç»“æŸæˆ‘çš„æ–‡ç« ã€‚ä½†æ˜¯è¿˜æœ‰æ›´å¤šâ€¦â€¦</p><p>    Instead of talking about what kind of noise to add to an image before quantizing it, we can also change our perspective and talk about adjusting the quantization threshold.</p><p>    é™¤äº†è®¨è®ºåœ¨å¯¹å›¾åƒè¿›è¡Œé‡åŒ–ä¹‹å‰è¦åœ¨å›¾åƒä¸Šæ·»åŠ å“ªç§å™ªå£°å¤–ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥æ›´æ”¹è§’åº¦å¹¶è®¨è®ºè°ƒæ•´é‡åŒ–é˜ˆå€¼ã€‚</p><p>  // Adding noise grayscaleImage . mapSelf ( brightness  =&gt;  brightness  + Math . random ( )  -  0.5  &gt;  0.5    ?  1.0    :  0.0  ) ;   // Adjusting the threshold grayscaleImage . mapSelf ( brightness  =&gt;   brightness  &gt; Math . random ( )    ?  1.0    :  0.0  ) ;</p><p>  //æ·»åŠ å™ªå£°grayscaleImageã€‚ mapSelfï¼ˆäº®åº¦=ï¼†gt;äº®åº¦+æ•°å­¦éšæœºï¼ˆï¼‰-0.5ï¼†gt; 0.5ï¼Ÿ1.0ï¼š0.0ï¼‰; //è°ƒæ•´é˜ˆå€¼grayscaleImageã€‚ mapSelfï¼ˆäº®åº¦=ï¼†gt;äº®åº¦ï¼†gt;æ•°å­¦éšæœºï¼ˆï¼‰ï¼Ÿ1.0ï¼š0.0ï¼‰; </p><p>  In the context of monochrome dithering, where the quantization threshold is 0.5, these two approaches are equivalent:</p><p>åœ¨å•è‰²æŠ–åŠ¨çš„æƒ…å†µä¸‹ï¼Œé‡åŒ–é˜ˆå€¼ä¸º0.5ï¼Œè¿™ä¸¤ç§æ–¹æ³•æ˜¯ç­‰æ•ˆçš„ï¼š</p><p>  b r i g h t n e s s +  r a n d ( ) âˆ’ 0.5   &gt;   0.5    â‡”    b r i g h t n e s s   &gt;    1.0 âˆ’  r a n d ( )    â‡”    b r i g h t n e s s   &gt;     r a n d ( ) \begin{array} {} &amp; \mathrm{brightness} + \mathrm{rand}() - 0.5 &amp; &gt; &amp; 0.5 \\ \Leftrightarrow &amp; \mathrm{brightness} &amp; &gt; &amp; 1.0 - \mathrm{rand}() \\ \Leftrightarrow &amp; \mathrm{brightness} &amp;&gt;&amp; \mathrm{rand}() \end{array}                  â‡”    â‡” â€‹              b r i g h t n e s s  +   r a n d ( )  âˆ’  0 . 5     b r i g h t n e s s     b r i g h t n e s s â€‹             &gt;    &gt;    &gt; â€‹             0 . 5    1 . 0  âˆ’   r a n d ( )     r a n d ( ) â€‹</p><p>  b r i g h t n e s s + ra n dï¼ˆï¼‰-0.5ï¼†gt; 0.5â‡”b s gï¼†gt; 1.0-r a n dï¼ˆï¼‰â‡”b r i g h t n e s sï¼†gt; r a n dï¼ˆï¼‰\ begin {array} {}ï¼†amp; \ mathrm {äº®åº¦} + \ mathrm {rand}ï¼ˆï¼‰-0.5ï¼†amp; ï¼†gt; ï¼†amp; 0.5 \\ \ Leftrightarrowï¼†amp; \ mathrm {äº®åº¦}ï¼†amp; ï¼†gt; ï¼†amp; 1.0-\ mathrm {rand}ï¼ˆï¼‰\\ \ Leftrightarrowï¼†amp; \ mathrm {brightness}ï¼†amp;ï¼†amp;ï¼†amp; \ mathrm {rand}ï¼ˆï¼‰\ end {array}â‡”â‡”Â¬b r i g h t n e s s + ra n dï¼ˆï¼‰-0ã€‚ 5 b r i g h t n e s s b r i g h t n e s sï¼†gt; ï¼†gt; ï¼†gt; 0ã€‚ 5 1ã€‚ 0 âˆ’ r a n dï¼ˆï¼‰r a n dï¼ˆï¼‰</p><p>  The upside of this approach is that we can talk about a â€œthreshold mapâ€. Threshold maps can be visualized to make it easier to reason about why a resulting image looks the way it does. They can also be precomputed and reused, which makes the dithering process deterministic and parallelizable per pixel. As a result, the dithering can happen on the GPU as a shader. This is what Obra Dinn does! There are a couple of different approaches to generating these threshold maps, but all of them introduce some kind of order to the noise that is added to the image, hence the name â€œordered ditheringâ€.</p><p>  è¿™ç§æ–¹æ³•çš„å¥½å¤„æ˜¯æˆ‘ä»¬å¯ä»¥è®¨è®ºâ€œé˜ˆå€¼å›¾â€ã€‚é˜ˆå€¼å›¾å¯ä»¥å¯è§†åŒ–ï¼Œä»¥ä¾¿æ›´å®¹æ˜“åœ°æ¨æ–­å‡ºä¸ºä»€ä¹ˆæœ€ç»ˆå›¾åƒçœ‹èµ·æ¥åƒå®ƒé‚£æ ·ã€‚å®ƒä»¬ä¹Ÿå¯ä»¥é¢„å…ˆè®¡ç®—å’Œé‡ç”¨ï¼Œä»è€Œä½¿æŠ–åŠ¨è¿‡ç¨‹ç¡®å®šæ€§ä¸”å¯å¹¶è¡ŒåŒ–æ¯ä¸ªåƒç´ ã€‚ç»“æœï¼ŒæŠ–åŠ¨å¯ä»¥åœ¨GPUä¸Šä½œä¸ºç€è‰²å™¨å‘ç”Ÿã€‚è¿™å°±æ˜¯Obra Dinnæ‰€åšçš„ï¼æœ‰ä¸¤ç§ä¸åŒçš„æ–¹æ³•å¯ä»¥ç”Ÿæˆè¿™äº›é˜ˆå€¼å›¾ï¼Œä½†æ˜¯æ‰€æœ‰è¿™äº›æ–¹æ³•éƒ½ä¼šä¸ºæ·»åŠ åˆ°å›¾åƒçš„å™ªå£°å¼•å…¥æŸç§é¡ºåºï¼Œå› æ­¤è¢«ç§°ä¸ºâ€œæœ‰åºæŠ–åŠ¨â€ã€‚</p><p>  The threshold map for the random dithering above, literally a map full of random thresholds, is also called â€œwhite noiseâ€. The name comes from a term in signal processing where every frequency has the same intensity, just like in white light.</p><p>  ä¸Šé¢ç”¨äºéšæœºæŠ–åŠ¨çš„é˜ˆå€¼å›¾ï¼Œå­—é¢ä¸Šå……æ»¡äº†éšæœºé˜ˆå€¼çš„å›¾ï¼Œä¹Ÿç§°ä¸ºâ€œç™½å™ªå£°â€ã€‚è¯¥åç§°æ¥è‡ªä¿¡å·å¤„ç†ä¸­çš„ä¸€ä¸ªæœ¯è¯­ï¼Œå…¶ä¸­æ¯ä¸ªé¢‘ç‡éƒ½å…·æœ‰ç›¸åŒçš„å¼ºåº¦ï¼Œå°±åƒåœ¨ç™½å…‰ä¸­ä¸€æ ·ã€‚</p><p>      â€œBayer ditheringâ€ uses a Bayer matrix as the threshold map. They are named after Bryce Bayer, inventor of the  Bayer filter, which is in use to this day in digital cameras. Each pixel on the sensor can only detect brightness, but by cleverly arranging colored filters in front of the individual pixels, we can reconstruct color images through  demosaicing. The pattern for the filters is the same pattern used in Bayer dithering.</p><p>      â€œæ‹œè€³æŠ–åŠ¨â€ä½¿ç”¨æ‹œè€³çŸ©é˜µä½œä¸ºé˜ˆå€¼å›¾ã€‚å®ƒä»¬ä»¥æ‹œè€³æ»¤é•œçš„å‘æ˜è€…å¸ƒè±æ–¯Â·æ‹œè€³ï¼ˆBryce Bayerï¼‰çš„åå­—å‘½åï¼Œè¯¥æ»¤é•œå¦‚ä»Šå·²åœ¨æ•°ç ç›¸æœºä¸­ä½¿ç”¨ã€‚ä¼ æ„Ÿå™¨ä¸Šçš„æ¯ä¸ªåƒç´ åªèƒ½æ£€æµ‹äº®åº¦ï¼Œä½†æ˜¯é€šè¿‡åœ¨å„ä¸ªåƒç´ çš„å‰é¢å·§å¦™åœ°å¸ƒç½®å½©è‰²æ»¤å…‰ç‰‡ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡å»é©¬èµ›å…‹æ¥é‡å»ºå½©è‰²å›¾åƒã€‚è¿‡æ»¤å™¨çš„å›¾æ¡ˆä¸æ‹œè€³æŠ–åŠ¨ä¸­ä½¿ç”¨çš„å›¾æ¡ˆç›¸åŒã€‚</p><p>  Bayer matrices come in various sizes which I ended up calling â€œlevelsâ€. Bayer Level 0 is       2 Ã— 2 2 \times 2    2  Ã—    2 matrix. Bayer Level 1 is a       4 Ã— 4 4 \times 4    4  Ã—    4 matrix. Bayer Level       n n    n is a        2  n + 1 Ã—  2  n + 1 2^{n+1} \times 2^{n+1}     2         n + 1  Ã—     2         n + 1 matrix. A level       n n    n matrix can be recursively calcuated from level       n âˆ’ 1 n-1    n  âˆ’    1 (although Wikipedia also lists an  per-cell algorithm). If your image happens to be bigger than your bayer matrix, you can tile the threshold map.</p><p>  æ‹œè€³çŸ©é˜µæœ‰å„ç§å°ºå¯¸ï¼Œæˆ‘æœ€ç»ˆç§°å…¶ä¸ºâ€œæ°´å¹³â€ã€‚æ‹œè€³0çº§æ˜¯2Ã—2 2 \ä¹˜ä»¥2 2Ã—2çŸ©é˜µã€‚æ‹œè€³1çº§æ˜¯4Ã—4 4 \ä¹˜ä»¥4 4Ã—4çŸ©é˜µã€‚æ‹œè€³çº§n n næ˜¯2 n + 1Ã—2 n + 1 2 ^ {n + 1} \ä¹˜ä»¥2 ^ {n + 1} 2 n + 1Ã—2 n +1çŸ©é˜µã€‚å¯ä»¥ä»n-1 n-1 n-1çº§é€’å½’è®¡ç®—n n nçº§çŸ©é˜µï¼ˆå°½ç®¡Wikipediaä¹Ÿåˆ—å‡ºäº†æ¯å•å…ƒç®—æ³•ï¼‰ã€‚å¦‚æœå›¾åƒæ°å¥½å¤§äºBayerçŸ©é˜µï¼Œåˆ™å¯ä»¥å¹³é“ºé˜ˆå€¼å›¾ã€‚</p><p>  Bayer ( 0 )   =    (     0   2    3   1 ) \begin{array}{rcl} \text{Bayer}(0) &amp; = &amp; \left( \begin{array}{cc} 0 &amp; 2 \\ 3 &amp; 1 \\ \end{array} \right) \\ \end{array}                Bayer ( 0 ) â€‹             = â€‹               (           0    3 â€‹             2    1 â€‹      ) â€‹</p><p>  æ‹œè€³ï¼ˆ0ï¼‰=ï¼ˆ0 2 3 1ï¼‰\ begin {array} {rcl} \ text {Bayer}ï¼ˆ0ï¼‰ï¼†amp; =ï¼†amp; \ leftï¼ˆ\ begin {array} {cc} 0ï¼†amp; 2 \\ 3ï¼†amp; 1 \\ \ end {array} \ rightï¼‰\\ \ end {array}æ‹œè€³ï¼ˆ0ï¼‰=ï¼ˆï¼ˆ0 3 2 1ï¼‰ </p><p>  Bayer ( n ) =     (      4 â‹… Bayer ( n âˆ’ 1 ) + 0    4 â‹… Bayer ( n âˆ’ 1 ) + 2     4 â‹… Bayer ( n âˆ’ 1 ) + 3    4 â‹… Bayer ( n âˆ’ 1 ) + 1 ) \begin{array}{c} \text{Bayer}(n) = \\ \left( \begin{array}{cc} 4 \cdot \text{Bayer}(n-1) + 0 &amp; 4 \cdot \text{Bayer}(n-1) + 2 \\ 4 \cdot \text{Bayer}(n-1) + 3 &amp; 4 \cdot \text{Bayer}(n-1) + 1 \\ \end{array} \right) \end{array}                Bayer ( n )  =      (           4  â‹…   Bayer ( n  âˆ’  1 )  +  0    4  â‹…   Bayer ( n  âˆ’  1 )  +  3 â€‹             4  â‹…   Bayer ( n  âˆ’  1 )  +  2    4  â‹…   Bayer ( n  âˆ’  1 )  +  1 â€‹      ) â€‹</p><p>æ‹œè€³ï¼ˆnï¼‰=ï¼ˆ4â‹…æ‹œè€³ï¼ˆn âˆ’ 1ï¼‰+ 0 4â‹…æ‹œè€³ï¼ˆn âˆ’ 1ï¼‰+ 2 4â‹…æ‹œè€³ï¼ˆn âˆ’ 1ï¼‰+ 3 4â‹…æ‹œè€³ï¼ˆn âˆ’ 1ï¼‰+ 1ï¼‰\å¼€å§‹{ array} {c} \ text {Bayer}ï¼ˆnï¼‰= \\ \ leftï¼ˆ\ begin {array} {cc} 4 \ cdot \ text {Bayer}ï¼ˆn-1ï¼‰+ 0ï¼†amp; 4 \ cdot \ text {æ‹œè€³}ï¼ˆn-1ï¼‰+ 2 \\ 4 \ cdot \ text {æ‹œè€³}ï¼ˆn-1ï¼‰+ 3ï¼†amp; 4 \ cdot \ text {æ‹œè€³}ï¼ˆn-1ï¼‰+ 1 \\ \ end {array} \ rightï¼‰\ end {array}æ‹œè€³ï¼ˆnï¼‰=ï¼ˆ4â‹…æ‹œè€³ï¼ˆn âˆ’ 1ï¼‰+ 0 4â‹…æ‹œè€³ï¼ˆn âˆ’ 1ï¼‰+ 3 4â‹…æ‹œè€³ï¼ˆn âˆ’ 1ï¼‰+ 2 4â‹…æ‹œè€³ï¼ˆn âˆ’ 1ï¼‰+ 1ï¼‰ï¼‰</p><p>  A level       n n    n Bayer matrix contains the numbers       0 0    0 to        2  2 n + 2 2^{2n+2}     2         2 n + 2. Once you normalize the Bayer matrix, i.e. divide by        2  2 n + 2 2^{2n+2}     2         2 n + 2, you can use it as a threshold map:</p><p>  çº§åˆ«ä¸ºnnnçš„æ‹œè€³çŸ©é˜µåŒ…å«æ•°å­—0 0 0åˆ°2 2 n + 2 2 ^ {2n + 2} 2 2 n +2ã€‚å¯¹æ‹œè€³çŸ©é˜µè¿›è¡Œå½’ä¸€åŒ–åï¼Œå³é™¤ä»¥2 2 n + 2 2 ^ {2n + 2} 2 2 n + 2ï¼Œæ‚¨å¯ä»¥å°†å…¶ç”¨ä½œé˜ˆå€¼å›¾ï¼š</p><p>  const bayer  =  generateBayerLevel (level ) ; grayscaleImage . mapSelf ( ( brightness ,  { x , y  } )  =&gt;  brightness  &gt; bayer . valueAt (x , y ,  { wrap :  true  } )    ?  1.0    :  0.0  ) ;</p><p>  const bayer = generateBayerLevelï¼ˆlevelï¼‰; grayscaleImageã€‚ mapSelfï¼ˆï¼ˆäº®åº¦ï¼Œ{xï¼Œy}ï¼‰=ï¼†gt;äº®åº¦ï¼†gt;æ‹œè€³ã€‚valueAtï¼ˆxï¼Œyï¼Œ{wrapï¼štrue}ï¼‰1.0ï¼š0.0ï¼‰;</p><p>  One thing to note: Bayer dithering using matrices as defined above will render an image lighter than it originally was. For example: An area where every pixel has a brightness of        1 255 = 0.4 % \frac{1}{255} = 0.4\%              2 5 5        1 â€‹      =    0 . 4 %, a level 0 Bayer matrix of size       2 Ã— 2 2\times2    2  Ã—    2 will make one out of the four pixels white, resulting in an average brightness of       25 % 25\%    2 5 %. This error gets smaller with higher Bayer levels, but a fundamental bias remains.</p><p>  éœ€è¦æ³¨æ„çš„ä¸€ä»¶äº‹ï¼šä½¿ç”¨ä¸Šè¿°å®šä¹‰çš„çŸ©é˜µè¿›è¡Œæ‹œè€³æŠ–åŠ¨å¤„ç†å°†ä½¿å›¾åƒæ¯”åŸæ¥çš„å›¾åƒæ›´äº®ã€‚ä¾‹å¦‚ï¼šæ¯ä¸ªåƒç´ çš„äº®åº¦ä¸º1255 = 0.4ï¼…\ frac {1} {255} = 0.4 \ï¼…2 5 5 1 = 0çš„åŒºåŸŸã€‚ 4ï¼…æ—¶ï¼Œå¤§å°ä¸º2Ã—2 2 \ times2 2Ã—2çš„0çº§BayerçŸ©é˜µå°†ä½¿å››ä¸ªåƒç´ ä¸­çš„ä¸€ä¸ªå˜ä¸ºç™½è‰²ï¼Œä»è€Œäº§ç”Ÿ25ï¼…25 \ï¼…2 5ï¼…çš„å¹³å‡äº®åº¦ã€‚æ‹œè€³æ°´å¹³è¶Šé«˜ï¼Œè¯¥è¯¯å·®å°±è¶Šå°ï¼Œä½†æ˜¯ä»ç„¶å­˜åœ¨åŸºæœ¬åå·®ã€‚</p><p>    In our dark test image, the sky is not pure black and made  significantly brighter when using Bayer Level 0. While it gets better with higher levels, an alternative solution is to flip the bias and make images render  darker by inverting the way we use the Bayer matrix:</p><p>    åœ¨æˆ‘ä»¬çš„é»‘æš—æµ‹è¯•å›¾åƒä¸­ï¼Œä½¿ç”¨æ‹œè€³çº§åˆ«0æ—¶å¤©ç©ºä¸æ˜¯çº¯é»‘çš„ï¼Œå¹¶ä¸”å˜å¾—æ˜æ˜¾æ›´äº®ã€‚å°½ç®¡åœ¨ä½¿ç”¨æ›´é«˜çº§åˆ«çš„æ°´å¹³æ—¶ä¼šå˜å¾—æ›´å¥½ï¼Œä½†æ˜¯å¦ä¸€ç§è§£å†³æ–¹æ¡ˆæ˜¯é€šè¿‡åè½¬ä½¿ç”¨æ–¹æ³•æ¥åç§»åæ–œå¹¶ä½¿å›¾åƒæ›´æš—ã€‚æ‹œè€³çŸ©é˜µï¼š</p><p>  const bayer  =  generateBayerLevel (level ) ; grayscaleImage . mapSelf ( ( brightness ,  { x , y  } )  =&gt;   // ğŸ‘‡  brightness  &gt;  1  - bayer . valueAt (x , y ,  { wrap :  true  } )    ?  1.0    :  0.0  ) ;</p><p>  const bayer = generateBayerLevelï¼ˆlevelï¼‰; grayscaleImageã€‚ mapSelfï¼ˆï¼ˆäº®åº¦ï¼Œ{xï¼Œy}ï¼‰=ï¼†gt; //äº®åº¦> 1æ‹œè€³ã€‚valueAtï¼ˆxï¼Œyï¼Œ{wrapï¼štrue}ï¼‰1.0ï¼š0.0ï¼‰;</p><p>  I have used the original Bayer definition for the light image and the inverted version for the dark image. I personally found Level 1 and 3 the most aesthetically pleasing.</p><p>  æˆ‘å°†åŸå§‹æ‹œè€³å®šä¹‰ç”¨äºäº®å›¾ï¼Œå°†åè½¬ç‰ˆæœ¬ç”¨äºæš—å›¾ã€‚æˆ‘ä¸ªäººå‘ç°1çº§å’Œ3çº§åœ¨ç¾å­¦ä¸Šæœ€ä»¤äººæ„‰æ‚¦ã€‚ </p><p>            Both white noise and Bayer dithering have drawbacks, of course. Bayer dithering, for example, is very structured and will look quite repetitive, especially at lower levels. White noise is random, meaning that there inevitably will be clusters of bright pixels and voids of darker pixels in the threshold map. This can be made more obvious by squinting or, if that is too much work for you, through blurring the threshold map algorithmically. These clusters and voids can affect the output of the dithering process negatively. If darker areas of the image fall into one of the clusters, details will get lost in the dithered output (and vice-versa for brighter areas falling into voids).</p><p>å½“ç„¶ï¼Œç™½å™ªå£°å’Œæ‹œè€³æŠ–åŠ¨éƒ½æœ‰ç¼ºç‚¹ã€‚ä¾‹å¦‚ï¼Œæ‹œè€³æŠ–åŠ¨ç»“æ„éå¸¸æœ‰æ¡ç†ï¼Œå¹¶ä¸”çœ‹èµ·æ¥ä¼šé‡å¤å¾ˆå¤šï¼Œå°¤å…¶æ˜¯åœ¨è¾ƒä½çº§åˆ«ã€‚ç™½å™ªå£°æ˜¯éšæœºçš„ï¼Œè¿™æ„å‘³ç€åœ¨é˜ˆå€¼å›¾ä¸­ä¸å¯é¿å…åœ°ä¼šæœ‰äº®åƒç´ çš„ç°‡å’Œæš—åƒç´ çš„ç©ºéš™ã€‚æ–œè§†æˆ–è€…å¦‚æœå¯¹æ‚¨æ¥è¯´å¤ªéº»çƒ¦äº†ï¼Œåˆ™å¯ä»¥é€šè¿‡ç®—æ³•æ¨¡ç³Šé˜ˆå€¼å›¾æ¥ä½¿è¿™ç§æƒ…å†µæ›´åŠ æ˜æ˜¾ã€‚è¿™äº›ç°‡å’Œç©ºéš™ä¼šè´Ÿé¢å½±å“æŠ–åŠ¨è¿‡ç¨‹çš„è¾“å‡ºã€‚å¦‚æœå›¾åƒçš„è¾ƒæš—åŒºåŸŸè½å…¥ç¾¤é›†ä¹‹ä¸€ï¼Œåˆ™æŠ–åŠ¨è¾“å‡ºä¸­çš„ç»†èŠ‚å°†ä¸¢å¤±ï¼ˆåä¹‹ï¼Œè¾ƒäº®åŒºåŸŸè½å…¥ç©ºéš™ä¸­åˆ™ç›¸åï¼‰ã€‚</p><p>    There is a variant of noise called â€œ blue noiseâ€, that addresses this issue. It is called blue noise because higher frequencies have higher intensities compared to the lower frequencies, just like blue light. By removing or dampening the lower frequencies, cluster and voids become less pronounced. Blue noise dithering is just as fast to apply to an image as white noise dithering â€” itâ€™s just a threshold map in the end â€” but  generating blue noise is a bit harder and expensive.</p><p>    æœ‰ä¸€ç§ç§°ä¸ºâ€œè“è‰²å™ªå£°â€çš„å™ªå£°å˜ä½“å¯ä»¥è§£å†³æ­¤é—®é¢˜ã€‚ä¹‹æ‰€ä»¥ç§°ä¸ºè“å™ªå£°ï¼Œæ˜¯å› ä¸ºä¸ä½é¢‘ç›¸æ¯”ï¼Œé«˜é¢‘ä¸ä½é¢‘ç›¸æ¯”å…·æœ‰æ›´é«˜çš„å¼ºåº¦ã€‚é€šè¿‡å»é™¤æˆ–æŠ‘åˆ¶è¾ƒä½çš„é¢‘ç‡ï¼Œç°‡å’Œç©ºéš™å˜å¾—ä¸å¤ªæ˜æ˜¾ã€‚è“å™ªå£°æŠ–åŠ¨ä¸ç™½å™ªå£°æŠ–åŠ¨ä¸€æ ·å¿«åœ°åº”ç”¨åˆ°å›¾åƒä¸Šï¼ˆæœ€ååªæ˜¯é˜ˆå€¼å›¾ï¼‰ï¼Œä½†æ˜¯ç”Ÿæˆè“å™ªå£°çš„éš¾åº¦å’Œæˆæœ¬æ›´é«˜ã€‚</p><p>  The most common algorithm to generate blue noise seems to be the â€œvoid-and-cluster methodâ€ by  Robert Ulichney. Here is the  original whitepaper. I found the way the algorithm is described quite unintuitive and, now that I have implemented it, I am convinced it is explained in an unnecessarily abstract fashion. But it is quite clever!</p><p>  äº§ç”Ÿè“å™ªå£°çš„æœ€å¸¸è§ç®—æ³•ä¼¼ä¹æ˜¯Robert Ulichneyæå‡ºçš„â€œæ— æ•ˆèšç±»æ–¹æ³•â€ã€‚è¿™æ˜¯åŸå§‹ç™½çš®ä¹¦ã€‚æˆ‘å‘ç°æè¿°ç®—æ³•çš„æ–¹å¼éå¸¸ä¸ç›´è§‚ï¼Œç°åœ¨ï¼Œæˆ‘å·²ç»å®ç°äº†å®ƒï¼Œæˆ‘ç¡®ä¿¡å®ƒä»¥ä¸å¿…è¦çš„æŠ½è±¡æ–¹å¼è¿›è¡Œäº†è§£é‡Šã€‚ä½†è¿™å¾ˆèªæ˜ï¼</p><p>  The algorithm is based on the idea that you can find a pixel that is part of cluster or a void by applying a  Gaussian Blur to the image and finding the brightest (or darkest) pixel in the blurred image respectively. After initializing a black image with a couple of randomly placed white pixels, the algorihtm proceeds to continuously swap cluster pixels and void pixels to spread the white pixels out as evenly as possible. Afterwards, every pixel gets a number between 0 and n (where n is the total number of pixels) according to their importance for forming clusters and voids. For more details, see the  paper.</p><p>  è¯¥ç®—æ³•åŸºäºä»¥ä¸‹æƒ³æ³•ï¼šå¯ä»¥é€šè¿‡å¯¹å›¾åƒåº”ç”¨é«˜æ–¯æ¨¡ç³Šå¹¶åˆ†åˆ«åœ¨æ¨¡ç³Šå›¾åƒä¸­æ‰¾åˆ°æœ€äº®ï¼ˆæˆ–æœ€æš—ï¼‰çš„åƒç´ æ¥æ‰¾åˆ°å±äºç¾¤é›†æˆ–ç©ºéš™çš„åƒç´ ã€‚åœ¨ç”¨å‡ ä¸ªéšæœºæ”¾ç½®çš„ç™½è‰²åƒç´ åˆå§‹åŒ–ä¸€ä¸ªé»‘è‰²å›¾åƒåï¼Œç®—æ³•ç»§ç»­è¿ç»­äº¤æ¢ç¾¤é›†åƒç´ å’Œç©ºç™½åƒç´ ï¼Œä»¥ä½¿ç™½è‰²åƒç´ å°½å¯èƒ½å‡åŒ€åœ°æ•£å¼€ã€‚ç„¶åï¼Œæ ¹æ®æ¯ä¸ªåƒç´ å½¢æˆç°‡å’Œç©ºéš™çš„é‡è¦æ€§ï¼Œæ¯ä¸ªåƒç´ å¾—åˆ°ä¸€ä¸ªä»‹äº0å’Œnä¹‹é—´çš„æ•°å­—ï¼ˆå…¶ä¸­næ˜¯åƒç´ çš„æ€»æ•°ï¼‰ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è§çº¸å¼ ã€‚</p><p>  My implementation works fine but is not very fast, as I didnâ€™t spend much time optimizing. It takes about 1 minute to generate a 64Ã—64 blue noise texture on my 2018 MacBook, which is sufficient for these purposes. If something faster is needed, a promising optimization would be to apply the Gaussian Blur not in the spatial domain but in the frequency domain instead.</p><p>  æˆ‘çš„å®æ–½æ•ˆæœä¸é”™ï¼Œä½†é€Ÿåº¦ä¸æ˜¯å¾ˆå¿«ï¼Œå› ä¸ºæˆ‘æ²¡æœ‰èŠ±å¤ªå¤šæ—¶é—´è¿›è¡Œä¼˜åŒ–ã€‚åœ¨æˆ‘çš„2018 MacBookä¸ŠèŠ±è´¹å¤§çº¦1åˆ†é’Ÿçš„æ—¶é—´å³å¯ç”Ÿæˆ64Ã—64çš„è“è‰²å™ªç‚¹çº¹ç†ï¼Œè¶³ä»¥æ»¡è¶³è¿™äº›ç›®çš„ã€‚å¦‚æœéœ€è¦æ›´å¿«çš„é€Ÿåº¦ï¼Œåˆ™æœ‰å¸Œæœ›çš„ä¼˜åŒ–å°†ä¸æ˜¯åœ¨ç©ºé—´åŸŸä¸­è€Œæ˜¯åœ¨é¢‘åŸŸä¸­åº”ç”¨é«˜æ–¯æ¨¡ç³Šã€‚</p><p>  Excursion: Of  course knowing this nerd-sniped me into implementing it. The reason this optimization is so promising is because convolution (which is the underlying operation of a Gaussian blur) has to loop over each field of the Gaussian kernel  for each pixel in the image. However, if you convert both the image as well as the Gaussian kernel to the frequency domain (using one of the many Fast Fourier Transform algorithms), convolution becomes an element-wise multiplication. Since my targeted blue noise size is a power of two, I could implement the well-explored  in-place variant of the Cooley-Tukey FFT algorithm. After  some initial hickups, it did end up cutting the blue noise generation time by 50%. I still wrote pretty garbage-y code, so thereâ€™s a lot more to room for optimizations.</p><p>  æ¸¸è§ˆï¼šå½“ç„¶ï¼Œäº†è§£è¿™ä¸ªä¹¦å‘†å­ä½¿æˆ‘æ— æ³•å®ç°å®ƒã€‚è¯¥ä¼˜åŒ–ä¹‹æ‰€ä»¥å¦‚æ­¤æœ‰å‰é€”ï¼Œæ˜¯å› ä¸ºå·ç§¯ï¼ˆé«˜æ–¯æ¨¡ç³Šçš„åŸºæœ¬æ“ä½œï¼‰å¿…é¡»é’ˆå¯¹å›¾åƒä¸­çš„æ¯ä¸ªåƒç´ éå†é«˜æ–¯å†…æ ¸çš„æ¯ä¸ªå­—æ®µã€‚ä½†æ˜¯ï¼Œå¦‚æœå°†å›¾åƒå’Œé«˜æ–¯æ ¸éƒ½è½¬æ¢åˆ°é¢‘åŸŸï¼ˆä½¿ç”¨è®¸å¤šå¿«é€Ÿå‚…ç«‹å¶å˜æ¢ç®—æ³•ä¹‹ä¸€ï¼‰ï¼Œåˆ™å·ç§¯å°†å˜æˆé€å…ƒç´ ä¹˜æ³•ã€‚ç”±äºæˆ‘çš„ç›®æ ‡è“å™ªå£°å¤§å°æ˜¯2çš„å¹‚ï¼Œå› æ­¤æˆ‘å¯ä»¥å®ç°Cooley-Tukey FFTç®—æ³•çš„å°±åœ°å¼€å‘å˜ä½“ã€‚ç»è¿‡ä¸€äº›åˆæ­¥çš„è®¨è®ºï¼Œæœ€ç»ˆå°†è“å™ªå£°çš„äº§ç”Ÿæ—¶é—´å‡å°‘äº†50ï¼…ã€‚æˆ‘ä»ç„¶ç¼–å†™äº†ç›¸å½“åƒåœ¾çš„ä»£ç ï¼Œå› æ­¤è¿˜æœ‰æ›´å¤šçš„ä¼˜åŒ–ç©ºé—´ã€‚</p><p>    As blue noise is based on a Gaussian Blur, which is calculated on a torus (a fancy way of saying that Gaussian blur wraps around at the edges), blue noise will also tile seamlessly. So we can use the 64Ã—64 blue noise and repeat it to cover the entire image. Blue noise dithering has a nice, even distribution without showing any obvious patterns, balancing rendering of details and organic look.</p><p>    ç”±äºè“è‰²å™ªå£°åŸºäºé«˜æ–¯æ¨¡ç³Šï¼Œé«˜æ–¯æ¨¡ç³Šæ˜¯åŸºäºåœ†ç¯è®¡ç®—çš„ï¼ˆé«˜æ–¯æ¨¡ç³Šåœ¨è¾¹ç¼˜å¤„ç¯ç»•çš„ä¸€ç§å¥‡ç‰¹çš„è¯´æ³•ï¼‰ï¼Œæ‰€ä»¥è“è‰²å™ªå£°ä¹Ÿä¼šæ— ç¼å¹³é“ºã€‚å› æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨64Ã—64çš„è“è‰²å™ªç‚¹å¹¶é‡å¤å®ƒä»¥è¦†ç›–æ•´ä¸ªå›¾åƒã€‚è“å™ªå£°æŠ–åŠ¨å…·æœ‰è‰¯å¥½çš„å‡åŒ€åˆ†å¸ƒï¼Œå¹¶ä¸”æ²¡æœ‰æ˜¾ç¤ºä»»ä½•æ˜æ˜¾çš„å›¾æ¡ˆï¼Œå¹³è¡¡äº†ç»†èŠ‚æ¸²æŸ“å’Œè‡ªç„¶å¤–è§‚ã€‚ </p><p>      All the previous techniques rely on the fact that quantization errors will  statistically even out because the thresholds in the threshold maps are uniformly distributed. A different approach to quantization is the concept of error diffusion, which is most likely what you have read about if you have ever researched image dithering before. In this approach we donâ€™t just quantize and hope that on average the quantization error remains negligible. Instead, we  measure the quantization error and diffuse the error onto neighboring pixels, influencing how they will get quantized. We are effectively changing the image we want to dither as we go along. This makes the process inherently sequential.</p><p>æ‰€æœ‰å…ˆå‰çš„æŠ€æœ¯éƒ½ä¾èµ–äºè¿™æ ·ä¸€ä¸ªäº‹å®ï¼Œå³ç”±äºé˜ˆå€¼å›¾ä¸­çš„é˜ˆå€¼æ˜¯å‡åŒ€åˆ†å¸ƒçš„ï¼Œå› æ­¤é‡åŒ–è¯¯å·®å°†åœ¨ç»Ÿè®¡ä¸Šå‡åŒ€ã€‚é‡åŒ–çš„å¦ä¸€ç§æ–¹æ³•æ˜¯è¯¯å·®æ‰©æ•£çš„æ¦‚å¿µï¼Œå¦‚æœæ‚¨ä»¥å‰æ›¾ç»ç ”ç©¶è¿‡å›¾åƒæŠ–åŠ¨ï¼Œåˆ™å¾ˆå¯èƒ½ä¼šè¯»æ‡‚å®ƒã€‚é€šè¿‡è¿™ç§æ–¹æ³•ï¼Œæˆ‘ä»¬ä¸ä»…å¯ä»¥é‡åŒ–ï¼Œè€Œä¸”å¸Œæœ›é‡åŒ–è¯¯å·®å¹³å‡å¯ä»¥å¿½ç•¥ä¸è®¡ã€‚å–è€Œä»£ä¹‹çš„æ˜¯ï¼Œæˆ‘ä»¬æµ‹é‡é‡åŒ–è¯¯å·®ï¼Œç„¶åå°†è¯¯å·®æ‰©æ•£åˆ°ç›¸é‚»åƒç´ ä¸Šï¼Œä»è€Œå½±å“åƒç´ çš„é‡åŒ–æ–¹å¼ã€‚æˆ‘ä»¬æ­£åœ¨æœ‰æ•ˆåœ°æ”¹å˜æˆ‘ä»¬æƒ³è¦æŠ–åŠ¨çš„å›¾åƒã€‚è¿™ä½¿è¿‡ç¨‹æœ¬è´¨ä¸Šæ˜¯é¡ºåºçš„ã€‚</p><p>  Foreshadowing: One big advantage of error diffusion algorithms that we wonâ€™t touch on  in this post is that they can handle arbitrary color palettes, while ordered dithering requires your color palette to be evenly spaced. More on that another time.</p><p>  é¢„ç¤ºï¼šæœ¬æ–‡ä¸­å°†ä¸æ¶‰åŠçš„è¯¯å·®æ‰©æ•£ç®—æ³•çš„ä¸€å¤§ä¼˜åŠ¿æ˜¯å®ƒä»¬å¯ä»¥å¤„ç†ä»»æ„è°ƒè‰²æ¿ï¼Œè€Œæœ‰åºæŠ–åŠ¨è¦æ±‚æ‚¨çš„è°ƒè‰²æ¿è¦å‡åŒ€åˆ†å¸ƒã€‚å†æ¥ä¸€æ¬¡ã€‚</p><p>  Almost all error diffusion ditherings that I am going to look at use a â€œdiffusion matrixâ€, which defines how the quantization error from the current pixel gets distributed across the neighboring pixels. For these matrices it is often assumed that the imageâ€™s pixels are traversed top-to-bottom, left-to-right â€” the same way us westerners read text. This is important as the error can only be diffused to pixels that havenâ€™t been quantized yet. If you find yourself traversing an image in a different order than the diffusion matrix assumes, flip the matrix accordingly.</p><p>  æˆ‘å°†è¦è®¨è®ºçš„å‡ ä¹æ‰€æœ‰è¯¯å·®æ‰©æ•£æŠ–åŠ¨éƒ½ä½¿ç”¨â€œæ‰©æ•£çŸ©é˜µâ€ï¼Œè¯¥çŸ©é˜µå®šä¹‰äº†å½“å‰åƒç´ çš„é‡åŒ–è¯¯å·®å¦‚ä½•åˆ†å¸ƒåœ¨ç›¸é‚»åƒç´ ä¹‹é—´ã€‚å¯¹äºè¿™äº›çŸ©é˜µï¼Œé€šå¸¸å‡è®¾å›¾åƒçš„åƒç´ æ˜¯ä»ä¸Šåˆ°ä¸‹ï¼Œä»å·¦åˆ°å³éå†çš„ï¼Œè¿™ä¸æˆ‘ä»¬è¥¿æ–¹äººé˜…è¯»æ–‡æœ¬çš„æ–¹å¼ç›¸åŒã€‚è¿™å¾ˆé‡è¦ï¼Œå› ä¸ºè¯¯å·®åªèƒ½æ‰©æ•£åˆ°å°šæœªé‡åŒ–çš„åƒç´ ã€‚å¦‚æœå‘ç°éå†å›¾åƒçš„é¡ºåºä¸æ‰©æ•£çŸ©é˜µå‡å®šçš„é¡ºåºä¸åŒï¼Œè¯·ç›¸åº”åœ°ç¿»è½¬çŸ©é˜µã€‚</p><p>    The naÃ¯ve approach to error diffusion shares the quantization error between the pixel below the current one and the one to the right, which can be described with the following matrix:</p><p>    å¹¼ç¨šçš„è¯¯å·®æ‰©æ•£æ–¹æ³•åœ¨å½“å‰åƒç´ ä¸‹æ–¹çš„åƒç´ ä¸å³ä¾§åƒç´ ä¹‹é—´çš„é‡åŒ–è¯¯å·®ä¹‹é—´å…±äº«é‡åŒ–è¯¯å·®ï¼Œå¯ç”¨ä»¥ä¸‹çŸ©é˜µæè¿°ï¼š</p><p>  (     âˆ—   0.5    0.5   0 ) \left(\begin{array}{cc} * &amp; 0.5 \\ 0.5 &amp; 0 \\ \end{array} \right)       (           âˆ—    0 . 5 â€‹             0 . 5    0 â€‹      )</p><p>  ï¼ˆâˆ— 0.5 0.5 0ï¼‰\ leftï¼ˆ\ begin {array} {cc} *ï¼†amp; 0.5 \\ 0.5ï¼†amp; 0 \\ \ end {array} \ rightï¼‰ï¼ˆâˆ— 0ã€‚5 0ã€‚5 0ï¼‰</p><p>  The diffusion algorithm visits each pixel in the image (in the right order!), quantizes the current pixel and measures the quantization error. Note that the quantization error is signed, i.e. it can be negative if the quantization made the pixel brighter than the original brightness value. We then add fractions of the quantization error to neighboring pixels as specified by the m</p><p>  æ‰©æ•£ç®—æ³•è®¿é—®å›¾åƒä¸­çš„æ¯ä¸ªåƒç´ ï¼ˆä»¥æ­£ç¡®çš„é¡ºåºï¼ï¼‰ï¼Œå¯¹å½“å‰åƒç´ è¿›è¡Œé‡åŒ–å¹¶æµ‹é‡é‡åŒ–è¯¯å·®ã€‚æ³¨æ„ï¼Œé‡åŒ–è¯¯å·®æ˜¯æœ‰ç¬¦å·çš„ï¼Œå³ï¼Œå¦‚æœé‡åŒ–ä½¿åƒç´ æ¯”åŸå§‹äº®åº¦å€¼æ›´äº®ï¼Œåˆ™å¯ä»¥ä¸ºè´Ÿã€‚ç„¶åï¼Œæˆ‘ä»¬å°†é‡åŒ–è¯¯å·®çš„åˆ†æ•°æ·»åŠ åˆ°ç”±mæŒ‡å®šçš„ç›¸é‚»åƒç´ </p><p>......</p><p>...... </p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://surma.dev/things/ditherpunk/">https://surma.dev/things/ditherpunk/</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/chrome/">#chrome</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/å¸Œæœ›/">#å¸Œæœ›</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/article/">#article</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/æŠ–åŠ¨/">#æŠ–åŠ¨</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/è®¾è®¡/">#è®¾è®¡</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/åˆ›æ„/">#åˆ›æ„</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/æ‘„å½±/">#æ‘„å½±</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/æ¸¸æˆ/">#æ¸¸æˆ</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/å›¾ç‰‡/">#å›¾ç‰‡</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/è½¯ä»¶/">#è½¯ä»¶</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/è§†é¢‘/">#è§†é¢‘</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/æ‰‹æœº/">#æ‰‹æœº</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/å¹¿å‘Š/">#å¹¿å‘Š</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/ç½‘ç«™/">#ç½‘ç«™</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/å…è´¹/">#å…è´¹</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/ä¸‹è½½/">#ä¸‹è½½</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/è‹¹æœ/">#è‹¹æœ</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/å¾®è½¯/">#å¾®è½¯</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/éŸ³ä¹/">#éŸ³ä¹</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/åšå®¢/">#åšå®¢</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/æ¶æ/">#æ¶æ</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/è‰ºæœ¯/">#è‰ºæœ¯</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/å·¥å…·/">#å·¥å…·</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/åˆ†äº«/">#åˆ†äº«</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy; 2020 diglog.com </div></div></body></html>