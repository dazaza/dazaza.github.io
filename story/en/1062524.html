<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>äº”è§’å¤§æ¥¼æœç€è®©AIæ§åˆ¶æ­¦å™¨ The Pentagon Inches Toward Letting AI Control Weapons</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">The Pentagon Inches Toward Letting AI Control Weapons<br/>äº”è§’å¤§æ¥¼æœç€è®©AIæ§åˆ¶æ­¦å™¨ </h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2021-05-14 03:10:59</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2021/5/1ed9767525457735cfcb5b952ccdd7d6.jpg"><img src="http://img2.diglog.com/img/2021/5/1ed9767525457735cfcb5b952ccdd7d6.jpg" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>Last August, several dozen military  drones and tanklike  robots took to the skies and roads 40 miles south of Seattle. Their mission: Find terrorists suspected of hiding among several buildings.</p><p>å»å¹´8æœˆï¼Œå‡ ååå†›äº‹æ— äººæœºå’Œå¦å…‹çš„æœºå™¨äººåˆ°äº†è¥¿é›…å›¾å—éƒ¨40è‹±é‡Œ40è‹±é‡Œçš„å¤©ç©ºå’Œé“è·¯ã€‚ä»–ä»¬çš„ä½¿å‘½ï¼šå‘ç°ææ€–åˆ†å­æ¶‰å«Œèº²è—åœ¨å‡ åº§å»ºç­‘ç‰©ä¸­ã€‚</p><p> So many robots were involved in the operation that no human operator could keep a close eye on all of them. So they were given instructions to findâ€”and eliminateâ€”enemy combatants when necessary.</p><p> è¿™ä¹ˆå¤šæœºå™¨äººå‚ä¸äº†æ“ä½œå‘˜å¯ä»¥ä¿æŒå¯†åˆ‡å…³æ³¨çš„æ“ä½œã€‚å› æ­¤ï¼Œåœ¨å¿…è¦æ—¶ï¼Œä»–ä»¬è¢«æŒ‡ç¤ºäº†è§£ - å¹¶æ¶ˆé™¤ - æ•Œäººçš„æˆ˜æ–—äººå‘˜ã€‚</p><p> The mission was just an exercise, organized by the  Defense Advanced Research Projects Agency, a blue-sky research division of the Pentagon; the robots were armed with nothing more lethal than radio transmitters designed to simulate interactions with both friendly and enemy robots.</p><p> ç‰¹æ´¾å›¢åªæ˜¯ä¸€é¡¹é”»ç‚¼ï¼Œç”±å›½é˜²é«˜çº§ç ”ç©¶é¡¹ç›®æœºæ„ï¼Œäº”è§’å¤§æ¥¼çš„è“å¤©ç ”ç©¶éƒ¨é—¨ç»„ç»‡;æœºå™¨äººè¢«æ­¦è£…ï¼Œè€Œä¸æ˜¯æ—¨åœ¨æ¨¡æ‹Ÿä¸å‹å¥½å’Œæ•Œäººæœºå™¨äººçš„ç›¸äº’ä½œç”¨çš„æ— çº¿ç”µå‘å°„æœºæ›´è‡´å‘½ã€‚</p><p> The drill was one of several conducted last summer to test how  artificial intelligence could help expand the use of automation in military systems, including in scenarios that are too complex and fast-moving for humans to make every critical decision. The demonstrations also reflect a subtle shift in the Pentagonâ€™s thinking about autonomous weapons, as it becomes clearer that machines can outperform humans at parsing complex situations or operating at high speed.</p><p> é’»æ¢æ˜¯å»å¹´å¤å¤©è¿›è¡Œçš„å‡ ä¸ªè¿›è¡Œçš„ï¼Œä»¥æµ‹è¯•äººå·¥æ™ºèƒ½å¦‚ä½•å¸®åŠ©æ‰©å¤§å†›äº‹ç³»ç»Ÿä¸­è‡ªåŠ¨åŒ–çš„ä½¿ç”¨ï¼ŒåŒ…æ‹¬åœ¨å¤ªå¤æ‚å’Œå¤ªå¿«çš„æƒ…æ™¯ä¸­ï¼Œä¸ºäººç±»åšå‡ºä¸€åˆ‡æ‰¹åˆ¤æ€§å†³å®šã€‚ç¤ºå¨æ´»åŠ¨ä¹Ÿåæ˜ äº†äº”è§’å¤§æ¥¼å¯¹è‡ªä¸»æ­¦å™¨çš„æ€è€ƒçš„å¾®å¦™è½¬å˜ï¼Œå› ä¸ºå®ƒå˜å¾—æ›´åŠ æ¸…æ™°ï¼Œæœºå™¨å¯ä»¥è¶…è¶Šåˆ†æå¤æ‚æƒ…å†µæˆ–ä»¥é«˜é€Ÿè¿è¡Œçš„äººã€‚</p><p>  General  John Murray of the US Army Futures Command told an audience at the US Military Academy last month that swarms of robots will force military planners, policymakers, and society to think about whether a person should make every decision about using lethal force in new autonomous systems. Murray asked: â€œIs it within a human&#39;s ability to pick out which ones have to be engagedâ€ and then make 100 individual decisions? â€œIs it even necessary to have a human in the loop?â€ he added.</p><p>  ç¾å›½é™†å†›æœŸè´§å§”å‘˜ä¼šçš„çº¦ç¿°Â·é»˜é‡Œä¸Šä¸ªæœˆåœ¨ç¾å›½å†›æ–¹å­¦é™¢è®²è¿°äº†ä¸€ä½å—ä¼—ï¼Œå³æœºå™¨äººçš„å¤§ç¾¤å°†è¿«ä½¿å†›é˜Ÿè§„åˆ’è€…ï¼Œæ”¿ç­–åˆ¶å®šè€…å’Œç¤¾ä¼šæ€è€ƒä¸€ä¸ªäººæ˜¯å¦åº”è¯¥åœ¨æ–°çš„è‡ªæ²»ç³»ç»Ÿä¸­ä½¿ç”¨è‡´å‘½åŠ›é‡çš„å†³å®šã€‚ ã€‚é»˜é‡Œé—®ï¼šâ€œå®ƒåœ¨äººç±»ä¸­ï¼†ï¼ƒ39;èƒ½å¤ŸæŒ‘é€‰å“ªäº›å¿…é¡»è®¢å©šçš„èƒ½åŠ›â€ç„¶ååˆ¶ä½œ100ä¸ªä¸ªäººå†³å®šï¼Ÿ â€œç”šè‡³æ˜¯æœ‰å¿…è¦åœ¨å¾ªç¯ä¸­æœ‰ä¸€ä¸ªäººå—ï¼Ÿâ€ä»–åŠ äº†ã€‚</p><p>  Other comments from military commanders suggest interest in giving autonomous weapons systems more agency. At a conference on AI in the Air Force last week, Michael Kanaan, director of operations for the Air Force Artificial Intelligence Accelerator at MIT and a leading voice on AI within the US military, said thinking is evolving. He says AI should perform more identifying and distinguishing potential targets while humans make high-level decisions. â€œI think that&#39;s where we&#39;re going,â€ Kanaan says.</p><p>  å†›äº‹æŒ‡æŒ¥å®˜çš„å…¶ä»–è¯„è®ºå»ºè®®å…´è¶£ç»™äºˆè‡ªä¸»æ­¦å™¨ç³»ç»Ÿæ›´å¤šæœºæ„ã€‚åœ¨ä¸Šå‘¨åœ¨ç©ºå†›çš„AIä¼šè®®ä¸Šï¼ŒMIC MITäººå·¥æ™ºèƒ½åŠ é€Ÿå™¨çš„ä¸šåŠ¡æ€»ç›‘Michael Kanaanå’Œç¾å›½å†›é˜Ÿå†…éƒ¨çš„é¢†å…ˆå£°éŸ³ï¼Œè¯´æ€è·¯æ­£åœ¨ä¸æ–­å‘å±•ã€‚ä»–è¯´ï¼Œå½“äººç±»åšå‡ºé«˜çº§åˆ«çš„å†³å®šæ—¶ï¼Œä»–åº”è¯¥è¡¨ç°æ›´å¤šçš„è¯†åˆ«å’ŒåŒºåˆ†æ½œåœ¨ç›®æ ‡ã€‚ â€œæˆ‘è®¤ä¸ºé‚£ä¸ªï¼†ï¼ƒ39;æˆ‘ä»¬åœ¨å“ªé‡Œï¼†ï¼ƒ39;é‡æ–°è¿›å…¥ï¼Œâ€Kanaanè¯´ã€‚</p><p>  At the same event, Lieutenant General  Clinton Hinote, deputy chief of staff for strategy, integration, and requirements at the Pentagon, says that whether a person can be removed from the loop of a lethal autonomous system is â€œone of the most interesting debates that is coming, [and] has not been settled yet.â€</p><p>  åœ¨åŒä¸€èµ›å­£ï¼Œæˆ˜ç•¥ï¼Œé›†æˆä»¥åŠäº”è§’å¤§æ¥¼çš„å‰¯èŒå‘˜å‰¯ä¸»ä»»å…‹æ—é¡¿æ–‡åŒ–å§”å‘˜ä¼šä¸­å°‰è¡¨ç¤ºï¼Œå¦‚æœä¸€ä¸ªäººå¯ä»¥ä»è‡´å‘½çš„è‡ªæ²»ç³»ç»Ÿçš„å¾ªç¯ä¸­åˆ é™¤æ˜¯â€œæœ€æœ‰è¶£çš„è¾©è®ºä¹‹ä¸€å³å°†åˆ°æ¥ï¼Œ[å’Œ]å°šæœªè§£å†³ã€‚â€œ </p><p> A report this month from the National Security Commission on Artificial Intelligence (NSCAI), an advisory group created by Congress, recommended, among other things, that the US resist calls for an international ban on the development of autonomous weapons.</p><p>æœ¬æœˆä»å›½å®¶å®‰å…¨æƒ…æŠ¥ï¼ˆNSCAIï¼‰çš„æŠ¥å‘Šï¼Œç”±å›½ä¼šåˆ›ä½œçš„å’¨è¯¢å°ç»„ï¼Œå…¶ä¸­åŒ…æ‹¬ç¾å›½æŠµåˆ¶å‘¼åå›½é™…ç¦æ­¢è‡ªä¸»æ­¦å™¨çš„å‘å±•ã€‚</p><p>  Timothy Chung, the Darpa program manager in charge of the swarming project, says last summerâ€™s exercises were designed to explore when a human drone operator should, and should not, make decisions for the autonomous systems. For example, when faced with attacks on several fronts, human control can sometimes get in the way of a mission, because people are unable to react quickly enough. â€œActually, the systems can do better from not having someone intervene,â€ Chung says.</p><p>  Timothy Chungè´Ÿè´£èœ‚æ‹¥é¡¹ç›®çš„DARPAè®¡åˆ’ç»ç†ï¼Œè¡¨ç¤ºï¼Œä¸Šå¤å¤©çš„ç»ƒä¹ æ—¨åœ¨æ¢ç´¢äººç±»æ— äººæœºè¿è¥å•†åº”è¯¥ï¼Œä¸åº”è¯¥ä¸ºè‡ªæ²»ç³»ç»Ÿåšå‡ºå†³å®šã€‚ä¾‹å¦‚ï¼Œå½“é¢å¯¹å‡ ä¸ªå‰é¢çš„æ”»å‡»æ—¶ï¼Œäººç±»çš„æ§åˆ¶æœ‰æ—¶ä¼šå¦¨ç¢ä½¿å‘½çš„æ–¹å¼ï¼Œå› ä¸ºäººä»¬æ— æ³•å¿«é€Ÿåœ°ååº”ã€‚ â€œå®é™…ä¸Šï¼Œç³»ç»Ÿå¯ä»¥ä»æ²¡æœ‰æœ‰äººå¹²é¢„æ–¹é¢åšå¾—æ›´å¥½ï¼Œâ€é’Ÿè¯´ã€‚</p><p> The drones and the wheeled robots, each about the size of a large backpack, were given an overall objective, then tapped AI algorithms to devise a plan to achieve it. Some of them surrounded buildings while others carried out surveillance sweeps. A few were destroyed by simulated explosives; some identified beacons representing enemy combatants and chose to attack.</p><p> æ— äººé©¾é©¶å’Œè½®å¼æœºå™¨äººï¼Œæ¯ä¸ªå¤§å°çš„å¤§èƒŒåŒ…çš„å¤§å°éƒ½è¢«èµ‹äºˆäº†æ•´ä½“ç›®æ ‡ï¼Œç„¶åç‚¹å‡»AIç®—æ³•è®¾è®¡äº†å®ç°å®ƒçš„è®¡åˆ’ã€‚å…¶ä¸­ä¸€äº›åŒ…å›´äº†å»ºç­‘ç‰©ï¼Œè€Œå…¶ä»–äººåˆ™è¿›è¡Œç›‘æ§æ‰«æã€‚ä¸€äº›è¢«æ¨¡æ‹Ÿç‚¸è¯æ‘§æ¯äº†ä¸€äº›;ä¸€äº›è¯†åˆ«çš„ä¿¡æ ‡ä»£è¡¨æ•Œäººçš„æˆ˜æ–—äººå‘˜å¹¶é€‰æ‹©æ”»å‡»ã€‚</p><p> The US and other nations have used autonomy in weapons systems for decades. Some missiles can, for instance, autonomously identify and attack enemies within a given area. But rapid advances in AI algorithms will change how the military uses such systems. Off-the-shelf AI code capable of controlling robots and identifying landmarks and targets, often with high reliability, will make it possible to deploy more systems in a wider range of situations.</p><p> å‡ åå¹´æ¥ï¼Œç¾å›½å’Œå…¶ä»–å›½å®¶åœ¨æ­¦å™¨ç³»ç»Ÿä¸­ä½¿ç”¨äº†è‡ªä¸»æƒã€‚ä¾‹å¦‚ï¼ŒæŸäº›å¯¼å¼¹å¯ä»¥åœ¨ç»™å®šåŒºåŸŸå†…è‡ªä¸»è¯†åˆ«å’Œæ”»å‡»æ•Œäººã€‚ä½†æ˜¯AIç®—æ³•çš„å¿«é€Ÿè¿›æ­¥å°†æ”¹å˜å†›é˜Ÿå¦‚ä½•ä½¿ç”¨æ­¤ç±»ç³»ç»Ÿã€‚èƒ½å¤Ÿæ§åˆ¶æœºå™¨äººå’Œè¯†åˆ«åœ°æ ‡å’Œç›®æ ‡çš„ç©ºç½®AIä»£ç ï¼Œé€šå¸¸å…·æœ‰é«˜å¯é æ€§ï¼Œå°†ä½¿å¯ä»¥åœ¨æ›´å¹¿æ³›çš„æƒ…å†µä¸‹éƒ¨ç½²æ›´å¤šç³»ç»Ÿã€‚</p><p>  But as the drone demonstrations highlight, more widespread use of AI will sometimes make it more difficult to keep a human in the loop. This might prove problematic, because AI technology  can harbor biases or behave unpredictably. A vision algorithm trained to recognize a particular uniform might mistakenly target someone wearing similar clothing. Chung says the swarm project presumes that AI algorithms will improve to a point where they can identify enemies with enough reliability to be trusted.</p><p>  ä½†éšç€å¯„ç”Ÿè™«ç¤ºèŒƒçªå‡ºï¼Œæ›´å¹¿æ³›ä½¿ç”¨AIæœ‰æ—¶ä¼šä½¿äººç±»ç•™åœ¨å¾ªç¯ä¸­æ›´åŠ å›°éš¾ã€‚è¿™å¯èƒ½è¯æ˜æ˜¯æœ‰é—®é¢˜çš„ï¼Œå› ä¸ºAIæŠ€æœ¯å¯ä»¥è¦†ç›–åè§æˆ–è¡¨ç°ä¸å¯é¢„æµ‹åœ°ã€‚åŸ¹è®­çš„è§†è§‰ç®—æ³•æ—¨åœ¨è¯†åˆ«ç‰¹å®šåˆ¶æœå¯èƒ½ä¼šè¯¯è®¤ä¸ºæ˜¯æˆ´ç€ç±»ä¼¼è¡£ç‰©çš„äººã€‚ Chungè¡¨ç¤ºï¼Œç¾¤ä½“é¡¹ç›®å‡å®šAIç®—æ³•å°†æ”¹è¿›åˆ°ä»–ä»¬å¯ä»¥è¯†åˆ«æœ‰è¶³å¤Ÿå¯é æ€§çš„æ•Œäººçš„ç‚¹ã€‚</p><p>  Use of AI in weapons systems has become controversial in recent years. Google faced employee protest and public outcry in 2018 after  supplying AI technology to the Air Force through a project known as  Maven.</p><p>  è¿‘å¹´æ¥ï¼Œåœ¨æ­¦å™¨ç³»ç»Ÿä¸­ä½¿ç”¨AIåœ¨æ­¦å™¨ç³»ç»Ÿä¸­å˜å¾—äº‰è®®ã€‚è°·æ­Œé¢ä¸´å‘˜å·¥æŠ—è®®å’Œ2018å¹´é€šè¿‡ç§°ä¸ºMavençš„é¡¹ç›®å‘ç©ºå†›æä¾›AIæŠ€æœ¯åï¼Œ2018å¹´ã€‚</p><p>  To some degree, the project is part of a long history of autonomy in weapons systems, with some missiles already capable of carrying out limited missions independent of human control. But it also shows how recent advances in AI will make autonomy more attractive and inevitable in certain situations. What&#39;s more, it highlights the trust that will be placed in technology that can still behave unpredictably.</p><p>  åœ¨æŸç§ç¨‹åº¦ä¸Šï¼Œè¯¥é¡¹ç›®æ˜¯æ­¦å™¨ç³»ç»Ÿä¸­æ‚ ä¹…çš„è‡ªä¸»æƒå†å²çš„ä¸€éƒ¨åˆ†ï¼Œä¸€äº›å¯¼å¼¹å·²ç»èƒ½å¤Ÿç‹¬ç«‹äºäººç±»å¯¹ç…§è¿›è¡Œæœ‰é™çš„ä»»åŠ¡ã€‚ä½†å®ƒè¿˜å±•ç¤ºäº†AIæœ€è¿‘çš„è¿‘æœŸè¿›æ­¥å°†ä½¿æŸäº›æƒ…å†µä¸‹çš„è‡ªä¸»æƒæ›´å…·å¸å¼•åŠ›å’Œä¸å¯é¿å…ã€‚ä»€ä¹ˆï¼†ï¼ƒ39;è¾ƒå¤šï¼Œå®ƒå¼ºè°ƒäº†å°†ä»ç„¶å¯ä»¥ä¸å¯é¢„æµ‹çš„æŠ€æœ¯çš„ä¿¡ä»»ã€‚ </p><p> Paul Scharre, an expert at the Center for New American Security and author of   Army of None: Autonomous Weapons and the Future of War, says it is time to have a more sophisticated discussion about autonomous weapons technology. â€œThe discussion surrounding â€˜humans in the loopâ€™ ought to be more sophisticated than simply a binary â€˜are they or aren&#39;t they?â€™â€ Scharre says. â€œIf a human makes a decision to engage a swarm of enemy drones, does the human need to individually select each target?â€</p><p>ä¿ç½—Scharreæ˜¯æ–°ç¾å›½å®‰å…¨ä¸­å¿ƒå’Œå†›é˜Ÿä½œè€…çš„ä¸“å®¶ï¼šè‡ªæ²»æ­¦å™¨å’Œæˆ˜äº‰çš„æœªæ¥ï¼Œè¯´ç°åœ¨æ˜¯æœ‰å…³äºè‡ªæ²»æ­¦å™¨æŠ€æœ¯æ›´å¤æ‚çš„è®¨è®ºã€‚ â€œå›´ç»•â€å¾ªç¯ä¸­çš„äººç±»çš„è®¨è®ºâ€œåº”è¯¥æ›´å¤æ‚ï¼Œè€Œä¸æ˜¯ç®€å•çš„äºŒè¿›åˆ¶'ä»–ä»¬è¿˜æ˜¯arenï¼†ï¼ƒ39; tä»–ä»¬ï¼Ÿ'â€scharreè¯´ã€‚ â€œå¦‚æœä¸€ä¸ªäººå†³å®šä»äº‹æ•Œäººæ— äººæœºçš„ç¾¤ä½“ï¼Œäººç±»éœ€è¦å•ç‹¬é€‰æ‹©æ¯ä¸ªç›®æ ‡å—ï¼Ÿâ€</p><p> The Defense Department issued a  policy on autonomous weapons in November 2012, stating that autonomous weapons systems need to have human oversightâ€”but this need not mean soldiers making every decision.</p><p> å›½é˜²éƒ¨äºäºŒé›¶ä¸€äºŒå¹´åä¸€æœˆå‘å¸ƒäº†ä¸€é¡¹å…³äºè‡ªæ²»æ­¦å™¨çš„æ”¿ç­–ï¼ŒæŒ‡å‡ºè‡ªä¸»æ­¦å™¨ç³»ç»Ÿéœ€è¦å…·æœ‰äººç±»ç›‘ç£çš„äºº - ä½†è¿™ä¸éœ€è¦å£«å…µåšå‡ºæ‰€æœ‰å†³å®šã€‚</p><p> Those who believe that militaries could use AI to cross a Rubicon when it comes to human responsibility for lethal force see things differently.</p><p> é‚£äº›ç›¸ä¿¡å†›é˜Ÿå¯ä»¥ä½¿ç”¨AIåœ¨äººç±»å¯¹è‡´å‘½åŠ›é‡çš„è´£ä»»æ–¹é¢è¶Šè¿‡Rubiconçœ‹åˆ°äº‹æƒ…çš„ä¸åŒä¹‹å¤„ã€‚</p><p> â€œLethal autonomous weapons cheap enough that every terrorist can afford them are not in America&#39;s national security interest,â€ says  Max Tegmark, a professor at MIT and cofounder of the  Future of Life Institute, a nonprofit that opposes autonomous weapons.</p><p> â€œè‡´å‘½çš„è‡ªä¸»æ­¦å™¨ä¾¿å®œï¼Œæ¯ä¸ªææ€–åˆ†å­éƒ½èƒ½è´Ÿæ‹…å¾—èµ·ä»–ä»¬ä¸åœ¨ç¾å›½ï¼Œè€Œä¸”å›½å®¶å®‰å…¨åˆ©ç›Šçš„å›½å®¶å®‰å…¨åˆ©ç›Šæœ€å¤šï¼Œâ€ç”Ÿå‘½ç ”ç©¶æ‰€æœªæ¥çš„æœªæ¥æ•™æˆï¼Œæ˜¯ä¸€ä¸ªåå¯¹è‡ªæ²»æ­¦å™¨çš„éè¥åˆ©ç»„ç»‡ã€‚</p><p> Tegmark says AI weapons should be â€œstigmatized and banned like biological weapons.â€ The NSCAI report&#39;s opposition a global ban is a strategic mistake, he says: â€œI think we&#39;ll one day regret it even more than we regret having armed the Taliban.â€</p><p> Tegmarkè¯´ï¼ŒAIæ­¦å™¨åº”è¯¥æ˜¯â€œè€»è¾±å’Œç¦æ­¢çš„ç”Ÿç‰©æ­¦å™¨â€ã€‚ NSCAIæŠ¥å‘Šï¼†ï¼ƒ39;ç›¸åçš„å…¨çƒç¦ä»¤æ˜¯ä¸€ä¸ªæˆ˜ç•¥é”™è¯¯ï¼Œä»–è¯´ï¼šâ€œæˆ‘è®¤ä¸ºæˆ‘ä»¬æœ‰ä¸€å¤©ç”šè‡³æ›´é—æ†¾åœ°æŠ±æ­‰ï¼Œæˆ‘ä»¬é—æ†¾åœ°æ­¦è£…å¡”åˆ©ç­ã€‚â€</p><p>   ğŸ§ Things not sounding right? Check out our favorite  wireless headphones,  soundbars, and  Bluetooth speakers</p><p>   ğŸ§å£°éŸ³ä¸å¯¹çš„ä¸œè¥¿ï¼ŸæŸ¥çœ‹æˆ‘ä»¬æœ€å–œæ¬¢çš„æ— çº¿è€³æœºï¼Œå£°æ å’Œè“ç‰™éŸ³ç®± </p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://www.wired.com/story/pentagon-inches-toward-letting-ai-control-weapons/">https://www.wired.com/story/pentagon-inches-toward-letting-ai-control-weapons/</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/ai/">#ai</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/inches/">#inches</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/äººç±»/">#äººç±»</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/è®¾è®¡/">#è®¾è®¡</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/åˆ›æ„/">#åˆ›æ„</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/æ‘„å½±/">#æ‘„å½±</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/å›¾ç‰‡/">#å›¾ç‰‡</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/æ¸¸æˆ/">#æ¸¸æˆ</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/è½¯ä»¶/">#è½¯ä»¶</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/è§†é¢‘/">#è§†é¢‘</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/å¹¿å‘Š/">#å¹¿å‘Š</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/æ‰‹æœº/">#æ‰‹æœº</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/ç½‘ç«™/">#ç½‘ç«™</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/å…è´¹/">#å…è´¹</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/ä¸‹è½½/">#ä¸‹è½½</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/å¾®è½¯/">#å¾®è½¯</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/è‹¹æœ/">#è‹¹æœ</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/éŸ³ä¹/">#éŸ³ä¹</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/åšå®¢/">#åšå®¢</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/æ¶æ/">#æ¶æ</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/è‰ºæœ¯/">#è‰ºæœ¯</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/å·¥å…·/">#å·¥å…·</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/åˆ†äº«/">#åˆ†äº«</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy;2012-2021 diglog.com </div></div></body></html>