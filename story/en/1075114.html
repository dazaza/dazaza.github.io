<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>å¦‚ä½•ä½¿ç”¨Pythonã€Transformerså’ŒScikitå¯¹æ–‡æœ¬è¿›è¡Œåˆ†ç±»How to Classify Text with Python, Transformers and Scikit-Learn</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">How to Classify Text with Python, Transformers and Scikit-Learn<br/>å¦‚ä½•ä½¿ç”¨Pythonã€Transformerså’ŒScikitå¯¹æ–‡æœ¬è¿›è¡Œåˆ†ç±»</h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2022-02-26 07:15:45</div><div class="page_narrow text-break page_content"><p>Thereâ€™s an enormous amount of text out there, and more and more of it is generated every day in the form of emails, social media posts, chats, websites, and articles. All these text documents are rich sources of information. But because of the unstructured nature of the text, understanding and analyzing it is difficult and time-consuming. As a result, most companies are not able to leverage this invaluable source of information. This is where Natural Language Processing (NLP) methods like text classification come in.</p><p>é‚£é‡Œæœ‰å¤§é‡çš„æ–‡æœ¬ï¼Œæ¯å¤©éƒ½æœ‰è¶Šæ¥è¶Šå¤šçš„æ–‡æœ¬ä»¥ç”µå­é‚®ä»¶ã€ç¤¾äº¤åª’ä½“å¸–å­ã€èŠå¤©ã€ç½‘ç«™å’Œæ–‡ç« çš„å½¢å¼ç”Ÿæˆã€‚æ‰€æœ‰è¿™äº›æ–‡æœ¬æ–‡ä»¶éƒ½æ˜¯ä¸°å¯Œçš„ä¿¡æ¯æ¥æºã€‚ä½†ç”±äºæ–‡æœ¬çš„éç»“æ„åŒ–æ€§è´¨ï¼Œç†è§£å’Œåˆ†æå®ƒæ—¢å›°éš¾åˆè€—æ—¶ã€‚å› æ­¤ï¼Œå¤§å¤šæ•°å…¬å¸æ— æ³•åˆ©ç”¨è¿™ä¸€å®è´µçš„ä¿¡æ¯æ¥æºã€‚è¿™å°±æ˜¯æ–‡æœ¬åˆ†ç±»ç­‰è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰æ–¹æ³•çš„ç”¨æ­¦ä¹‹åœ°ã€‚</p><p>       Text classification, also known as  text categorization or  text tagging, is the process of assigning a text document to one or more categories or classes. It enables organizations to automatically structure all types of relevant text in a quick and inexpensive way. By classifying their text data, organizations can get a quick overview of the trends and also narrow down sections for further analysis.</p><p>æ–‡æœ¬åˆ†ç±»ï¼Œä¹Ÿç§°ä¸ºæ–‡æœ¬åˆ†ç±»æˆ–æ–‡æœ¬æ ‡è®°ï¼Œæ˜¯å°†æ–‡æœ¬æ–‡æ¡£åˆ†é…ç»™ä¸€ä¸ªæˆ–å¤šä¸ªç±»åˆ«æˆ–ç±»åˆ«çš„è¿‡ç¨‹ã€‚å®ƒä½¿ç»„ç»‡èƒ½å¤Ÿä»¥å¿«é€Ÿã€å»‰ä»·çš„æ–¹å¼è‡ªåŠ¨æ„å»ºæ‰€æœ‰ç±»å‹çš„ç›¸å…³æ–‡æœ¬ã€‚é€šè¿‡å¯¹æ–‡æœ¬æ•°æ®è¿›è¡Œåˆ†ç±»ï¼Œç»„ç»‡å¯ä»¥å¿«é€Ÿäº†è§£è¶‹åŠ¿ï¼Œå¹¶ç¼©å°èŒƒå›´è¿›è¡Œè¿›ä¸€æ­¥åˆ†æã€‚</p><p>     Letâ€™s say you are hired by an organization to help them sort through their customer reviews. First things first, if the organization has a global customer base and there are reviews written in multiple languages, dividing them based on their language will help with downstream tasks.</p><p>å‡è®¾ä½ å—é›‡äºä¸€å®¶å…¬å¸ï¼Œå¸®åŠ©ä»–ä»¬æ•´ç†å®¢æˆ·è¯„è®ºã€‚é¦–å…ˆï¼Œå¦‚æœç»„ç»‡æœ‰ä¸€ä¸ªå…¨çƒå®¢æˆ·ç¾¤ï¼Œå¹¶ä¸”æœ‰å¤šç§è¯­è¨€ç¼–å†™çš„è¯„è®ºï¼Œæ ¹æ®å…¶è¯­è¨€è¿›è¡Œåˆ’åˆ†å°†æœ‰åŠ©äºå®Œæˆä¸‹æ¸¸ä»»åŠ¡ã€‚</p><p>     As uplifting and fulfilling as positive reviews are, they rarely contain any urgent issues that need to be addressed immediately. So, it might be a good idea to perform sentiment analysis and classify the reviews as positive and negative. Here your previous language classification will come in handy for making language-specific sentiment analysis models.</p><p>å°½ç®¡ç§¯æçš„è¯„ä»·ä»¤äººæŒ¯å¥‹å’Œæ»¡è¶³ï¼Œä½†å®ƒä»¬å¾ˆå°‘åŒ…å«ä»»ä½•éœ€è¦ç«‹å³è§£å†³çš„ç´§è¿«é—®é¢˜ã€‚å› æ­¤ï¼Œè¿›è¡Œæƒ…ç»ªåˆ†æå¹¶å°†è¯„è®ºåˆ†ä¸ºæ­£é¢å’Œè´Ÿé¢å¯èƒ½æ˜¯ä¸€ä¸ªå¥½ä¸»æ„ã€‚åœ¨è¿™é‡Œï¼Œæ‚¨ä»¥å‰çš„è¯­è¨€åˆ†ç±»å°†æœ‰åŠ©äºåˆ›å»ºç‰¹å®šäºè¯­è¨€çš„æƒ…æ„Ÿåˆ†ææ¨¡å‹ã€‚</p><p>  Once you have the negative reviews, you can further categorize them by feature/product mentioned. This will enable different teams to easily find relevant reviews and figure out what theyâ€™re doing wrong or what improvements need to be made.</p><p>ä¸€æ—¦ä½ æœ‰äº†è´Ÿé¢è¯„è®ºï¼Œä½ å¯ä»¥æ ¹æ®æåˆ°çš„åŠŸèƒ½/äº§å“å¯¹å…¶è¿›è¡Œè¿›ä¸€æ­¥åˆ†ç±»ã€‚è¿™å°†ä½¿ä¸åŒçš„å›¢é˜Ÿèƒ½å¤Ÿè½»æ¾æ‰¾åˆ°ç›¸å…³çš„è¯„è®ºï¼Œå¹¶æ‰¾å‡ºä»–ä»¬åšé”™äº†ä»€ä¹ˆæˆ–éœ€è¦è¿›è¡Œå“ªäº›æ”¹è¿›ã€‚</p><p>      Manual text classification involves a human annotator, who reads through the contents of the text documents and tags them. Now you might think that this method only causes problems when youâ€™re working with large amounts of text. But you would be wrong to think so, here are two reasons:</p><p>æ‰‹åŠ¨æ–‡æœ¬åˆ†ç±»æ¶‰åŠäººå·¥æ³¨é‡Šå‘˜ï¼Œä»–é€šè¯»æ–‡æœ¬æ–‡æ¡£çš„å†…å®¹å¹¶å¯¹å…¶è¿›è¡Œæ ‡è®°ã€‚ç°åœ¨ä½ å¯èƒ½ä¼šè®¤ä¸ºè¿™ç§æ–¹æ³•åªä¼šåœ¨å¤„ç†å¤§é‡æ–‡æœ¬æ—¶äº§ç”Ÿé—®é¢˜ã€‚ä½†ä½ è¿™ä¹ˆæƒ³æ˜¯ä¸å¯¹çš„ï¼Œæœ‰ä¸¤ä¸ªåŸå› ï¼š</p><p>   As a side effect of being slow, manual classification hinders an organizationâ€™s ability to quickly identify and respond to critical situations. For instance, letâ€™s say a cloud provider or an API goes down, if a person is sequentially going through the customer support tickets, it might take the organization a while to realize that their services are down.</p><p>ä½œä¸ºç¼“æ…¢çš„å‰¯ä½œç”¨ï¼Œæ‰‹åŠ¨åˆ†ç±»ä¼šå¦¨ç¢ç»„ç»‡å¿«é€Ÿè¯†åˆ«å’Œåº”å¯¹å…³é”®æƒ…å†µçš„èƒ½åŠ›ã€‚ä¾‹å¦‚ï¼Œå‡è®¾ä¸€ä¸ªäº‘æä¾›å•†æˆ–ä¸€ä¸ªAPIå®•æœºï¼Œå¦‚æœä¸€ä¸ªäººæ­£åœ¨æŒ‰é¡ºåºæŸ¥çœ‹å®¢æˆ·æ”¯æŒç¥¨è¯ï¼Œç»„ç»‡å¯èƒ½éœ€è¦ä¸€æ®µæ—¶é—´æ‰èƒ½æ„è¯†åˆ°ä»–ä»¬çš„æœåŠ¡å®•æœºã€‚</p><p>   Humans are imperfect beings even on their best days. Theyâ€™re prone to making mistakes due to factors like lack of sleep, boredom, distractions, etc. These can cause inconsistent classifications. For critical applications, these lapses can cost the organization thousands of dollars.</p><p>å³ä½¿åœ¨æœ€ç¾å¥½çš„æ—¥å­é‡Œï¼Œäººç±»ä¹Ÿæ˜¯ä¸å®Œç¾çš„ã€‚ç”±äºç¡çœ ä¸è¶³ã€æ— èŠã€åˆ†å¿ƒç­‰å› ç´ ï¼Œä»–ä»¬å®¹æ˜“çŠ¯é”™è¯¯ã€‚è¿™äº›å› ç´ å¯èƒ½å¯¼è‡´åˆ†ç±»ä¸ä¸€è‡´ã€‚å¯¹äºå…³é”®åº”ç”¨ç¨‹åºï¼Œè¿™äº›å¤±è¯¯å¯èƒ½ä¼šè®©å…¬å¸æŸå¤±æ•°åƒç¾å…ƒã€‚</p><p>  And beyond these disadvantages, human hours cost considerably more than running a Python script on a cloud server. So performing   automatic text classification by applying natural language processing and other AI techniques is the best choice for most cases. Automatic classification is faster and more cost-effective. And on top of that, once a text classification model is trained to satisfactory specifications, it performs consistently.</p><p>é™¤äº†è¿™äº›ç¼ºç‚¹ä¹‹å¤–ï¼Œäººå·¥æ—¶é—´çš„æˆæœ¬è¿œè¿œé«˜äºåœ¨äº‘æœåŠ¡å™¨ä¸Šè¿è¡ŒPythonè„šæœ¬ã€‚å› æ­¤ï¼Œåº”ç”¨è‡ªç„¶è¯­è¨€å¤„ç†å’Œå…¶ä»–äººå·¥æ™ºèƒ½æŠ€æœ¯è¿›è¡Œè‡ªåŠ¨æ–‡æœ¬åˆ†ç±»æ˜¯å¤§å¤šæ•°æƒ…å†µä¸‹çš„æœ€ä½³é€‰æ‹©ã€‚è‡ªåŠ¨åˆ†ç±»é€Ÿåº¦æ›´å¿«ï¼Œæˆæœ¬æ•ˆç›Šæ›´é«˜ã€‚æœ€é‡è¦çš„æ˜¯ï¼Œä¸€æ—¦æ–‡æœ¬åˆ†ç±»æ¨¡å‹è®­ç»ƒåˆ°ä»¤äººæ»¡æ„çš„è§„æ ¼ï¼Œå®ƒçš„æ€§èƒ½å°±ä¼šä¿æŒä¸€è‡´ã€‚</p><p>  There are many ways to automatically classify text documents, but all the methods can be  classified into three types:</p><p>æœ‰å¾ˆå¤šæ–¹æ³•å¯ä»¥è‡ªåŠ¨å¯¹æ–‡æœ¬æ–‡æ¡£è¿›è¡Œåˆ†ç±»ï¼Œä½†æ‰€æœ‰æ–¹æ³•éƒ½å¯ä»¥åˆ†ä¸ºä¸‰ç§ç±»å‹ï¼š</p><p>   Rule-based methods use a set of manually created linguistic rules to classify text. These rules consist of a pattern or a set of patterns for each of the categories. A very simple approach could be to classify documents based on the occurrences of category-specific words.</p><p>åŸºäºè§„åˆ™çš„æ–¹æ³•ä½¿ç”¨ä¸€ç»„æ‰‹åŠ¨åˆ›å»ºçš„è¯­è¨€è§„åˆ™å¯¹æ–‡æœ¬è¿›è¡Œåˆ†ç±»ã€‚è¿™äº›è§„åˆ™ç”±æ¯ä¸ªç±»åˆ«çš„ä¸€ä¸ªæ¨¡å¼æˆ–ä¸€ç»„æ¨¡å¼ç»„æˆã€‚ä¸€ç§éå¸¸ç®€å•çš„æ–¹æ³•æ˜¯æ ¹æ®ç‰¹å®šç±»åˆ«å•è¯çš„å‡ºç°æƒ…å†µå¯¹æ–‡æ¡£è¿›è¡Œåˆ†ç±»ã€‚</p><p>  Say that you want to classify news articles into two classes:  Business and  Science. To do this youâ€™ll need to create two lists of words that categorize each class. For instance, you could choose names of organizations like Goldman Sachs, Morgan Stanley, Apple, etc. for the business class, and for the science class, you could choose words like NASA, scientist, researchers, etc.</p><p>å‡è®¾ä½ æƒ³æŠŠæ–°é—»æ–‡ç« åˆ†ä¸ºä¸¤ç±»ï¼šå•†ä¸šå’Œç§‘å­¦ã€‚è¦åšåˆ°è¿™ä¸€ç‚¹ï¼Œä½ éœ€è¦åˆ›å»ºä¸¤ä¸ªå•è¯åˆ—è¡¨ï¼Œå¯¹æ¯ä¸ªç±»åˆ«è¿›è¡Œåˆ†ç±»ã€‚ä¾‹å¦‚ï¼Œä½ å¯ä»¥é€‰æ‹©é«˜ç››ã€æ‘©æ ¹å£«ä¸¹åˆ©ã€è‹¹æœç­‰æœºæ„çš„åç§°ã€‚åœ¨å•†åŠ¡è¯¾ä¸Šï¼Œä½ å¯ä»¥é€‰æ‹©NASAã€ç§‘å­¦å®¶ã€ç ”ç©¶äººå‘˜ç­‰è¯æ±‡ã€‚</p><p>  Now, when you want to classify a news article, the rule-based classifier will count the number of business-related words and science-related words. If the number of business-related words is greater than science-related words then the article will be classified as Business and vice versa.</p><p>ç°åœ¨ï¼Œå½“ä½ æƒ³å¯¹ä¸€ç¯‡æ–°é—»æ–‡ç« è¿›è¡Œåˆ†ç±»æ—¶ï¼ŒåŸºäºè§„åˆ™çš„åˆ†ç±»å™¨å°†ç»Ÿè®¡ä¸å•†ä¸šç›¸å…³çš„è¯å’Œä¸ç§‘å­¦ç›¸å…³çš„è¯çš„æ•°é‡ã€‚å¦‚æœä¸å•†ä¸šç›¸å…³çš„å•è¯æ•°é‡å¤§äºä¸ç§‘å­¦ç›¸å…³çš„å•è¯æ•°é‡ï¼Œåˆ™æ–‡ç« å°†è¢«å½’ç±»ä¸ºå•†ä¸šï¼Œåä¹‹äº¦ç„¶ã€‚</p><p>      International Space Station: How NASA Plans To Destroy Itâ€ as science because there is one science-related word - â€œNASAâ€ and no business-related words.</p><p>å›½é™…ç©ºé—´ç«™ï¼šç¾å›½å®‡èˆªå±€è®¡åˆ’å¦‚ä½•æ‘§æ¯å®ƒä½œä¸ºç§‘å­¦ï¼Œå› ä¸ºæœ‰ä¸€ä¸ªä¸ç§‘å­¦æœ‰å…³çš„è¯â€”â€”â€œNASAâ€ï¼Œè€Œæ²¡æœ‰ä¸å•†ä¸šæœ‰å…³çš„è¯ã€‚</p><p>  The biggest advantage of using rule-based systems is that there easy to understand by laymen. So once a bare-bones system is created, it can be incrementally improved over time. But the other side of this advantage is that the developers need deep knowledge of the domain to create the rules. Moreover, rule-based classification methods donâ€™t scale well as adding new rules without proper testing can affect the results of older rules.</p><p>ä½¿ç”¨åŸºäºè§„åˆ™çš„ç³»ç»Ÿçš„æœ€å¤§ä¼˜ç‚¹æ˜¯ï¼Œå¤–è¡Œå¾ˆå®¹æ˜“ç†è§£ã€‚å› æ­¤ï¼Œä¸€æ—¦åˆ›å»ºäº†ä¸€ä¸ªåŸºæœ¬ç³»ç»Ÿï¼Œå®ƒå°±å¯ä»¥éšç€æ—¶é—´çš„æ¨ç§»è€Œé€æ­¥æ”¹è¿›ã€‚ä½†è¿™ç§ä¼˜åŠ¿çš„å¦ä¸€æ–¹é¢æ˜¯ï¼Œå¼€å‘äººå‘˜éœ€è¦å¯¹é¢†åŸŸæœ‰æ·±å…¥çš„äº†è§£æ‰èƒ½åˆ›å»ºè§„åˆ™ã€‚æ­¤å¤–ï¼ŒåŸºäºè§„åˆ™çš„åˆ†ç±»æ–¹æ³•ä¸èƒ½å¾ˆå¥½åœ°æ‰©å±•ï¼Œåœ¨æ²¡æœ‰é€‚å½“æµ‹è¯•çš„æƒ…å†µä¸‹æ·»åŠ æ–°è§„åˆ™å¯èƒ½ä¼šå½±å“æ—§è§„åˆ™çš„ç»“æœã€‚</p><p>    Instead of defining the rules manually, you can choose a machine learning-based method that automatically learns the rules using past observations. Machine learning-based classifiers use labeled examples as training data to learn associations between words/phrases and the labels, i.e., the categories.</p><p>æ‚¨å¯ä»¥é€‰æ‹©ä¸€ç§åŸºäºæœºå™¨å­¦ä¹ çš„æ–¹æ³•ï¼Œä½¿ç”¨è¿‡å»çš„è§‚å¯Ÿè‡ªåŠ¨å­¦ä¹ è§„åˆ™ï¼Œè€Œä¸æ˜¯æ‰‹åŠ¨å®šä¹‰è§„åˆ™ã€‚åŸºäºæœºå™¨å­¦ä¹ çš„åˆ†ç±»å™¨ä½¿ç”¨å¸¦æ ‡ç­¾çš„ç¤ºä¾‹ä½œä¸ºè®­ç»ƒæ•°æ®æ¥å­¦ä¹ å•è¯/çŸ­è¯­å’Œæ ‡ç­¾ä¹‹é—´çš„å…³è”ï¼Œå³ç±»åˆ«ã€‚</p><p>  Now, that sounds easy enough to tackle, but thereâ€™s one problem you need to solve before you can train your machine learning classifier. Feature extraction. You see, computers donâ€™t understand the text as we do, they only understand numbers, 0s &amp; 1s. In the case of computer vision problems, the images are internally stored in the form of numbers representing the values of the individual pixels.</p><p>è¿™å¬èµ·æ¥å¾ˆå®¹æ˜“è§£å†³ï¼Œä½†åœ¨è®­ç»ƒæœºå™¨å­¦ä¹ åˆ†ç±»å™¨ä¹‹å‰ï¼Œæœ‰ä¸€ä¸ªé—®é¢˜éœ€è¦è§£å†³ã€‚ç‰¹å¾æå–ã€‚ä½ çœ‹ï¼Œè®¡ç®—æœºä¸åƒæˆ‘ä»¬é‚£æ ·ç†è§£æ–‡æœ¬ï¼Œå®ƒä»¬åªç†è§£æ•°å­—ã€0å’Œï¼›1sã€‚åœ¨è®¡ç®—æœºè§†è§‰é—®é¢˜çš„æƒ…å†µä¸‹ï¼Œå›¾åƒä»¥æ•°å­—çš„å½¢å¼å­˜å‚¨åœ¨å†…éƒ¨ï¼Œè¡¨ç¤ºå„ä¸ªåƒç´ çš„å€¼ã€‚</p><p>  But that isnâ€™t the case for text. So, the first step for training an NLP classifier is to transform the text into a numerical vector representation. One of the most commonly used text embedding methods is bag of words. It creates a vector that counts the occurrences of each word in a predefined dictionary.</p><p>ä½†æ–‡æœ¬å¹¶éå¦‚æ­¤ã€‚å› æ­¤ï¼Œè®­ç»ƒNLPåˆ†ç±»å™¨çš„ç¬¬ä¸€æ­¥æ˜¯å°†æ–‡æœ¬è½¬æ¢ä¸ºæ•°å­—å‘é‡è¡¨ç¤ºã€‚æœ€å¸¸ç”¨çš„æ–‡æœ¬åµŒå…¥æ–¹æ³•ä¹‹ä¸€æ˜¯å•è¯åŒ…ã€‚å®ƒåˆ›å»ºä¸€ä¸ªå‘é‡ï¼Œç»Ÿè®¡æ¯ä¸ªå•è¯åœ¨é¢„å®šä¹‰è¯å…¸ä¸­çš„å‡ºç°æ¬¡æ•°ã€‚</p><p>  Let&#39;s say you define the dictionary as:  â€œ(What, a, sunny, serene, beautiful, day, night)â€, and you want to create the vector embedding of the sentence â€œWhat a serene nightâ€. You would end up with the following vector representation for the sentence:  (1, 1, 0, 1, 0, 0, 1).</p><p>è®©&#39ï¼›å‡è®¾ä½ å°†å­—å…¸å®šä¹‰ä¸ºï¼šâ€œï¼ˆWhatï¼Œaï¼Œsunnyï¼Œsereneï¼Œbeautifulï¼Œdayï¼Œnightï¼‰â€ï¼Œä½ æƒ³åˆ›å»ºä¸€ä¸ªåµŒå…¥å¥å­â€œWhat a serene nightâ€çš„å‘é‡ã€‚ä½ ä¼šå¾—åˆ°ä»¥ä¸‹å¥å­çš„å‘é‡è¡¨ç¤ºæ³•ï¼šï¼ˆ1ï¼Œ1ï¼Œ0ï¼Œ1ï¼Œ0ï¼Œ0ï¼Œ0ï¼Œ1ï¼‰ã€‚</p><p>  After you have generated the vector representation of all the labeled text documents, you can use them to train a classifier. The vector representation of text documents is passed to the classifier with their correct categories. The model learns the associations between different linguistic features in the text and the categories:</p><p>ç”Ÿæˆæ‰€æœ‰å¸¦æ ‡ç­¾æ–‡æœ¬æ–‡æ¡£çš„å‘é‡è¡¨ç¤ºåï¼Œå¯ä»¥ä½¿ç”¨å®ƒä»¬æ¥è®­ç»ƒåˆ†ç±»å™¨ã€‚æ–‡æœ¬æ–‡æ¡£çš„å‘é‡è¡¨ç¤ºå°†ä¼ é€’ç»™åˆ†ç±»å™¨ï¼Œå¹¶å¸¦æœ‰æ­£ç¡®çš„ç±»åˆ«ã€‚è¯¥æ¨¡å‹å­¦ä¹ æ–‡æœ¬ä¸­ä¸åŒè¯­è¨€ç‰¹å¾ä¸ç±»åˆ«ä¹‹é—´çš„å…³è”ï¼š</p><p>     Once the model has been trained up to the required performance standards, it can be used to make accurate predictions. The same feature extraction method is used to create the vector representation of the new text documents. The classification model uses these feature vectors to predict the categories of the documents.</p><p>ä¸€æ—¦æ¨¡å‹è¢«è®­ç»ƒåˆ°æ‰€éœ€çš„æ€§èƒ½æ ‡å‡†ï¼Œå®ƒå°±å¯ä»¥ç”¨æ¥åšå‡ºå‡†ç¡®çš„é¢„æµ‹ã€‚ä½¿ç”¨ç›¸åŒçš„ç‰¹å¾æå–æ–¹æ³•åˆ›å»ºæ–°æ–‡æœ¬æ–‡æ¡£çš„çŸ¢é‡è¡¨ç¤ºã€‚åˆ†ç±»æ¨¡å‹ä½¿ç”¨è¿™äº›ç‰¹å¾å‘é‡æ¥é¢„æµ‹æ–‡æ¡£çš„ç±»åˆ«ã€‚</p><p>    Machine learning-based text classification methods are generally more accurate than rule-based classifiers. Besides that, machine learning classifiers are easier to scale as you can simply add new training examples to update the model. The only problem with machine learning classifiers is that they are hard to understand and debug. So if something goes wrong, it can be hard to figure out what caused the issue.</p><p>åŸºäºæœºå™¨å­¦ä¹ çš„æ–‡æœ¬åˆ†ç±»æ–¹æ³•é€šå¸¸æ¯”åŸºäºè§„åˆ™çš„åˆ†ç±»å™¨æ›´å‡†ç¡®ã€‚é™¤æ­¤ä¹‹å¤–ï¼Œæœºå™¨å­¦ä¹ åˆ†ç±»å™¨æ›´å®¹æ˜“æ‰©å±•ï¼Œå› ä¸ºæ‚¨å¯ä»¥ç®€å•åœ°æ·»åŠ æ–°çš„è®­ç»ƒç¤ºä¾‹æ¥æ›´æ–°æ¨¡å‹ã€‚æœºå™¨å­¦ä¹ åˆ†ç±»å™¨çš„å”¯ä¸€é—®é¢˜æ˜¯å®ƒä»¬å¾ˆéš¾ç†è§£å’Œè°ƒè¯•ã€‚å› æ­¤ï¼Œå¦‚æœå‡ºç°é—®é¢˜ï¼Œå¯èƒ½å¾ˆéš¾æ‰¾å‡ºé—®é¢˜çš„åŸå› ã€‚</p><p>  Hybrid text classification methods combine the best of both worlds. They combine the generalization ability of the machine learning classifier with the easy-to-understand and tweak rule-based methods. They can learn complex rules thanks to the machine learning model, and any conflicting classifications or erratic behavior can be fixed using rules.</p><p>æ··åˆæ–‡æœ¬åˆ†ç±»æ–¹æ³•ç»“åˆäº†è¿™ä¸¤ä¸ªæ–¹é¢çš„ä¼˜ç‚¹ã€‚å®ƒä»¬å°†æœºå™¨å­¦ä¹ åˆ†ç±»å™¨çš„æ³›åŒ–èƒ½åŠ›ä¸æ˜“äºç†è§£å’Œè°ƒæ•´çš„åŸºäºè§„åˆ™çš„æ–¹æ³•ç›¸ç»“åˆã€‚å¤šäºäº†æœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œä»–ä»¬å¯ä»¥å­¦ä¹ å¤æ‚çš„è§„åˆ™ï¼Œä»»ä½•å†²çªçš„åˆ†ç±»æˆ–ä¸ç¨³å®šçš„è¡Œä¸ºéƒ½å¯ä»¥ä½¿ç”¨è§„åˆ™ä¿®å¤ã€‚</p><p>  Take for instance the task of classifying financial news articles based on their industrial sectors such as pharma, finance, automotive, mining, etc. To do this you can create a hybrid system. First, train a named entity recognition model that extracts company names from the news articles. Then, create a list of the companies in each sector. And that&#39;s it, using these two things you can create a competent classifier.</p><p>ä¾‹å¦‚ï¼Œæ ¹æ®è¡Œä¸šå¯¹é‡‘èæ–°é—»æ–‡ç« è¿›è¡Œåˆ†ç±»ï¼Œå¦‚åˆ¶è¯ã€é‡‘èã€æ±½è½¦ã€é‡‡çŸ¿ç­‰ã€‚è¦åšåˆ°è¿™ä¸€ç‚¹ï¼Œä½ å¯ä»¥åˆ›å»ºä¸€ä¸ªæ··åˆç³»ç»Ÿã€‚é¦–å…ˆï¼Œè®­ç»ƒä¸€ä¸ªå‘½åå®ä½“è¯†åˆ«æ¨¡å‹ï¼Œä»æ–°é—»æ–‡ç« ä¸­æå–å…¬å¸åç§°ã€‚ç„¶åï¼Œåˆ›å»ºæ¯ä¸ªéƒ¨é—¨çš„å…¬å¸åˆ—è¡¨ã€‚é‚£&#39ï¼›å°±æ˜¯è¿™æ ·ï¼Œä½¿ç”¨è¿™ä¸¤ä»¶äº‹ä½ å¯ä»¥åˆ›å»ºä¸€ä¸ªåˆæ ¼çš„åˆ†ç±»å™¨ã€‚</p><p>         You&#39;ll be working with some of our old Google News data dumps. The news data is stored in the JSONL format. Normally you can load JSONL files into a   DataFrame using the   read_json method with the   lines=True argument, but our data is structured a bit weirdly.</p><p>ä½ &#39ï¼›æˆ‘ä»¬å°†å¤„ç†ä¸€äº›æ—§çš„è°·æ­Œæ–°é—»æ•°æ®è½¬å‚¨ã€‚æ–°é—»æ•°æ®ä»¥JSONLæ ¼å¼å­˜å‚¨ã€‚é€šå¸¸ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨read_jsonæ–¹æ³•å°†JSONLæ–‡ä»¶åŠ è½½åˆ°æ•°æ®å¸§ä¸­ï¼Œå¹¶ä½¿ç”¨lines=Trueå‚æ•°ï¼Œä½†æˆ‘ä»¬çš„æ•°æ®ç»“æ„æœ‰ç‚¹å¥‡æ€ªã€‚</p><p>     Each of the individual entries is stored within an Object ( enclosed within    {&#39;item&#39;:}). So, if you try to load it straight away with the   read_json method   it will load all of it as one column.</p><p>æ¯ä¸ªæ¡ç›®éƒ½å­˜å‚¨åœ¨ä¸€ä¸ªå¯¹è±¡ä¸­ï¼ˆåŒ…å«åœ¨{&#39ï¼›item&#39ï¼›ï¼š}ä¸­ï¼‰ã€‚å› æ­¤ï¼Œå¦‚æœæ‚¨å°è¯•ä½¿ç”¨read_jsonæ–¹æ³•ç›´æ¥åŠ è½½å®ƒï¼Œå®ƒä¼šå°†æ‰€æœ‰å†…å®¹ä½œä¸ºä¸€åˆ—åŠ è½½ã€‚</p><p>     To fix this, you can read the file like a normal text file and use the   json.loads method to create a list of dictionaries.</p><p>è¦è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œå¯ä»¥åƒè¯»å–æ™®é€šæ–‡æœ¬æ–‡ä»¶ä¸€æ ·è¯»å–è¯¥æ–‡ä»¶ï¼Œå¹¶ä½¿ç”¨jsonã€‚åŠ è½½æ–¹æ³•ä»¥åˆ›å»ºå­—å…¸åˆ—è¡¨ã€‚</p><p>     There is still an issue to deal with ğŸ˜¬. The value of the attributes for each headline is stored inside its own object. Fret not, you can quickly fix it with some more dictionary manipulation.</p><p>è¿˜æœ‰ä¸€ä¸ªé—®é¢˜éœ€è¦è§£å†³ğŸ˜¬. æ¯ä¸ªæ ‡é¢˜çš„å±æ€§å€¼å­˜å‚¨åœ¨å®ƒè‡ªå·±çš„å¯¹è±¡ä¸­ã€‚ä¸ç”¨æ‹…å¿ƒï¼Œä½ å¯ä»¥é€šè¿‡æ›´å¤šçš„å­—å…¸æ“ä½œå¿«é€Ÿä¿®å¤å®ƒã€‚</p><p>             You don&#39;t really need the other attributes like   country,   lang, or   cleaned_url.  And the  topic labels-&#39;WORLD&#39; and &#39;NATION&#39; are not very informative as their definition is very loose. So, you can  drop them off.</p><p>ä½ æ²¡æœ‰&#39ï¼›æˆ‘çœŸçš„ä¸éœ€è¦å…¶ä»–å±æ€§ï¼Œæ¯”å¦‚å›½å®¶ã€è¯­è¨€æˆ–urlã€‚ä»¥åŠä¸»é¢˜æ ‡ç­¾&#39ï¼›ä¸–ç•Œ&#39ï¼›å’Œ&#39ï¼›å›½å®¶&#39ï¼›å®ƒä»¬çš„å®šä¹‰éå¸¸æ¾æ•£ï¼Œå› æ­¤ä¿¡æ¯é‡ä¸å¤§ã€‚æ‰€ä»¥ï¼Œä½ å¯ä»¥æŠŠå®ƒä»¬æ”¾ä¸‹ã€‚</p><p>      Next, you should take a look at how many training examples we have for each category.</p><p>æ¥ä¸‹æ¥ï¼Œæ‚¨åº”è¯¥çœ‹çœ‹æˆ‘ä»¬ä¸ºæ¯ä¸ªç±»åˆ«æä¾›äº†å¤šå°‘åŸ¹è®­ç¤ºä¾‹ã€‚</p><p>      More than 350000 articles for the two biggest categories and even the small group has about 40000 examples!</p><p>ä¸¤å¤§ç±»è¶…è¿‡35ä¸‡ç¯‡æ–‡ç« ï¼Œç”šè‡³å°ç»„ä¹Ÿæœ‰å¤§çº¦4ä¸‡ä¸ªä¾‹å­ï¼</p><p>          Jokes aside, as you&#39;re going to use the state-of-the-art BERT transformer model to create the vector representations, I recommend that you train the models with a subset of the available dataset.</p><p>é™¤äº†ç¬‘è¯ï¼Œå°±åƒä½ &#39ï¼›æˆ‘ä»¬å°†ä½¿ç”¨æœ€å…ˆè¿›çš„BERT transformeræ¨¡å‹æ¥åˆ›å»ºå‘é‡è¡¨ç¤ºï¼Œæˆ‘å»ºè®®æ‚¨ä½¿ç”¨å¯ç”¨æ•°æ®é›†çš„å­é›†æ¥è®­ç»ƒæ¨¡å‹ã€‚</p><p>   Now you can load the BERT sentence transformer and create the vector embedding for the headlines.</p><p>ç°åœ¨ï¼Œæ‚¨å¯ä»¥åŠ è½½BERTå¥å­è½¬æ¢å™¨ï¼Œå¹¶ä¸ºæ ‡é¢˜åˆ›å»ºå‘é‡åµŒå…¥ã€‚</p><p>            The Support Vector Classifier(SVM) comes out on top. You can use this to predict the topic of new news headlines.</p><p>æ”¯æŒå‘é‡åˆ†ç±»å™¨ï¼ˆSVMï¼‰ä½å±…æ¦œé¦–ã€‚ä½ å¯ä»¥ç”¨å®ƒæ¥é¢„æµ‹æ–°æ–°é—»æ ‡é¢˜çš„ä¸»é¢˜ã€‚</p><p>           There you have it. You now know what text classification is, how it works, and how you can train your own machine learning text classifiers. But hey, what about neural networks? That&#39;s a good question! The thing is, as good as neural networks are they are not really necessary for this task. Both SVMs and NNs can approximate non-linear decision boundaries, and they both achieve comparable results on the same dataset. Neural networks can pull ahead in performance but they need a lot more computational power, training data, and time.</p><p>ç»™ä½ ã€‚ç°åœ¨ï¼Œæ‚¨çŸ¥é“ä»€ä¹ˆæ˜¯æ–‡æœ¬åˆ†ç±»ï¼Œå®ƒæ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Œä»¥åŠå¦‚ä½•åŸ¹è®­è‡ªå·±çš„æœºå™¨å­¦ä¹ æ–‡æœ¬åˆ†ç±»å™¨ã€‚ä½†æ˜¯ï¼Œç¥ç»ç½‘ç»œå‘¢ï¼Ÿé‚£&#39ï¼›è¿™æ˜¯ä¸ªå¥½é—®é¢˜ï¼é—®é¢˜æ˜¯ï¼Œå°½ç®¡ç¥ç»ç½‘ç»œå¾ˆå¥½ï¼Œä½†å¯¹äºè¿™é¡¹ä»»åŠ¡æ¥è¯´ï¼Œå®ƒä»¬å¹¶ä¸æ˜¯çœŸæ­£å¿…è¦çš„ã€‚æ”¯æŒå‘é‡æœºå’Œç¥ç»ç½‘ç»œéƒ½èƒ½é€¼è¿‘éçº¿æ€§å†³ç­–è¾¹ç•Œï¼Œåœ¨åŒä¸€ä¸ªæ•°æ®é›†ä¸Šéƒ½èƒ½å¾—åˆ°å¯æ¯”çš„ç»“æœã€‚ç¥ç»ç½‘ç»œå¯ä»¥åœ¨æ€§èƒ½ä¸Šé¢†å…ˆï¼Œä½†å®ƒä»¬éœ€è¦æ›´å¤šçš„è®¡ç®—èƒ½åŠ›ã€è®­ç»ƒæ•°æ®å’Œæ—¶é—´ã€‚</p><p>  On the other hand, support vector machines can reliably identify the decision boundary based on the sole support vectors. Therefore, you can train an SVM classifier with a small subset of the data you would need to train a neural network that achieves similar performance. If, however, any marginal increase in performance is beneficial for your application feel free to go with neural networks.</p><p>å¦ä¸€æ–¹é¢ï¼Œæ”¯æŒå‘é‡æœºèƒ½å¤ŸåŸºäºå”¯ä¸€çš„æ”¯æŒå‘é‡å¯é åœ°è¯†åˆ«å†³ç­–è¾¹ç•Œã€‚å› æ­¤ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨è®­ç»ƒè¾¾åˆ°ç±»ä¼¼æ€§èƒ½çš„ç¥ç»ç½‘ç»œæ‰€éœ€çš„ä¸€å°éƒ¨åˆ†æ•°æ®æ¥è®­ç»ƒSVMåˆ†ç±»å™¨ã€‚ç„¶è€Œï¼Œå¦‚æœæ€§èƒ½çš„ä»»ä½•å¾®å°æé«˜éƒ½æœ‰åˆ©äºåº”ç”¨ç¨‹åºï¼Œé‚£ä¹ˆå¯ä»¥ä½¿ç”¨ç¥ç»ç½‘ç»œã€‚</p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/python/">#python</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/text/">#text</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/åˆ†ç±»/">#åˆ†ç±»</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/è®¾è®¡/">#è®¾è®¡</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/åˆ›æ„/">#åˆ›æ„</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/æ‘„å½±/">#æ‘„å½±</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/å›¾ç‰‡/">#å›¾ç‰‡</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/æ¸¸æˆ/">#æ¸¸æˆ</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/è½¯ä»¶/">#è½¯ä»¶</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/å¹¿å‘Š/">#å¹¿å‘Š</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/è§†é¢‘/">#è§†é¢‘</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/æ‰‹æœº/">#æ‰‹æœº</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/ç½‘ç«™/">#ç½‘ç«™</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/å…è´¹/">#å…è´¹</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/ä¸‹è½½/">#ä¸‹è½½</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/å¾®è½¯/">#å¾®è½¯</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/è‹¹æœ/">#è‹¹æœ</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/éŸ³ä¹/">#éŸ³ä¹</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/åšå®¢/">#åšå®¢</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/æ¶æ/">#æ¶æ</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/è°·æ­Œ/">#è°·æ­Œ</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/è‰ºæœ¯/">#è‰ºæœ¯</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/å·¥å…·/">#å·¥å…·</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy;2012-2021 diglog.com </div></div></body></html>