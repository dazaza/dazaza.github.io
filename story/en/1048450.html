<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>æ¯ç§’12ä¸ªè¯·æ±‚â€“ç°å®çš„Python Webæ¡†æ¶ 12 requests per second â€“ Realistic Python web frameworks</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">12 requests per second â€“ Realistic Python web frameworks<br/>æ¯ç§’12ä¸ªè¯·æ±‚â€“ç°å®çš„Python Webæ¡†æ¶ </h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2021-02-19 10:35:39</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2021/2/f41f962f6231a5b67d33cf1b8bcacb57.jpeg"><img src="http://img2.diglog.com/img/2021/2/f41f962f6231a5b67d33cf1b8bcacb57.jpeg" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>If you take a look around the blogosphere at various benchmarks for Python web frameworks, you might start to feel pretty bad about your own setup. Or, alternatively, super-hyped about the possibilities.</p><p>å¦‚æœæ‚¨åœ¨Python Webæ¡†æ¶çš„å„ç§åŸºå‡†ä¸ŠæŸ¥çœ‹åšå®¢åœˆï¼Œæ‚¨å¯èƒ½ä¼šå¼€å§‹å¯¹è‡ªå·±çš„è®¾ç½®æ„Ÿåˆ°éå¸¸ç³Ÿç³•ã€‚æˆ–è€…ï¼Œæˆ–è€…ï¼Œè¶…çº§ä¼°é‡å…³äºå¯èƒ½æ€§ã€‚</p><p> Consider, for instance, the incredible work of the guys at  magic stack, getting  100,000 requests per second from  uvloop in a single thread. This is on par with compiled language like Go&#39;s performance.</p><p> ä¾‹å¦‚ï¼Œè€ƒè™‘é­”æœ¯å †æ ˆä¸­çš„äººå‘˜çš„éš¾ä»¥ç½®ä¿¡çš„å·¥ä½œï¼Œä»å•ä¸ªçº¿ç¨‹ä¸­ä»UVLoopè·å¾—æ¯ç§’100,000ä¸ªè¯·æ±‚ã€‚è¿™ä¸ç¼–è¯‘è¯­è¨€ç›¸ä¼¼ï¼Œå¦‚Goï¼†ï¼ƒ39; sè¡¨ç°ã€‚</p><p> But that benchmark doesn&#39;t really cover a fully fleshed out web framework, right? We need a lot more functionality and structure from our frameworks than reading and writing bytes. What about fully fleshed-out web-frameworks in python?</p><p> ä½†é‚£ä¸ªåŸºå‡†å¹¶ä¸çœŸçš„è¦†ç›–ä¸€ä¸ªå®Œå…¨å……å®çš„Webæ¡†æ¶ï¼Œå¯¹å—ï¼Ÿæˆ‘ä»¬éœ€è¦æˆ‘ä»¬æ¡†æ¶çš„æ›´å¤šåŠŸèƒ½å’Œç»“æ„ï¼Œè€Œä¸æ˜¯è¯»å†™å­—èŠ‚ã€‚åœ¨Pythonä¸­å®Œå…¨å……å®çš„ç½‘é¡µæ¡†æ¶æ€ä¹ˆæ ·ï¼Ÿ</p><p> One such framework is  Sanic, which again has been shown to have similar performance:  100,000 requests per-second. Or there&#39;s  Vibora. Not only does this claim to be a drop-in replacement for  Flask, but it also has its own templating engine. And it handles  350,000 requests per second!</p><p> ä¸€ä¸ªè¿™æ ·çš„æ¡†æ¶æ˜¯SANICï¼Œå®ƒå†æ¬¡è¢«è¯æ˜å…·æœ‰ç±»ä¼¼çš„æ€§èƒ½ï¼šæ¯ç§’100,000ä¸ªè¯·æ±‚ã€‚æˆ–è€…ï¼†ï¼ƒ39; s viboraã€‚è¿™ä¸€å£°ç§°ä¸ä»…æ˜¯çƒ§ç“¶çš„æ›¿ä»£å“ï¼Œè€Œä¸”è¿˜æœ‰è‡ªå·±çš„æ¨¡æ¿å‘åŠ¨æœºã€‚å®ƒæ¯ç§’å¤„ç†350,000ä¸ªè¯·æ±‚ï¼</p><p> Even more mind-blowing is  Japronto which claims an insane  1.2 million requests per-second in a single thread ğŸ¤¯ trouncing the performance of other languages and frameworks:</p><p> æ›´ä»¤äººå…´å¥‹çš„æ˜¯æ—¥æœ¬å¹å˜˜ï¼Œå…¶ä¸­ç´¢èµ”äº†ä¸€ä¸ªç–¯ç‹‚çš„120ä¸‡æ¬¡åœ¨ä¸€ä¸ªçº¿ç¨‹ä¸­çš„è¯·æ±‚â™ªä¿ƒè¿›å…¶ä»–è¯­è¨€å’Œæ¡†æ¶çš„è¡¨ç°ï¼š</p><p>  Recently we&#39;ve been doing a lot of work improving the performance of our Python APIs. Currently we&#39;re running  Flask, and we initially had a single question:  how can we serve more requests from a single worker thread? But looking at these benchmarks had us asking more:</p><p>  æœ€è¿‘æˆ‘ä»¬ä¸€ç›´åœ¨åšå¾ˆå¤šå·¥ä½œï¼Œæé«˜äº†æˆ‘ä»¬Python APIçš„è¡¨ç°ã€‚ç›®å‰æˆ‘ä»¬ï¼†ï¼ƒ39;é‡æ–°è¿è¡Œçƒ§ç“¶ï¼Œæˆ‘ä»¬æœ€åˆæœ‰ä¸€ä¸ªé—®é¢˜ï¼šæˆ‘ä»¬å¦‚ä½•ä»å•ä¸ªå·¥äººçº¿ç¨‹æä¾›æ›´å¤šè¯·æ±‚ï¼Ÿä½†æ˜¯çœ‹ç€è¿™äº›åŸºå‡†è®©æˆ‘ä»¬è¯¢é—®æ›´å¤šï¼š</p><p>  In other words, how much should we trust these benchmarks? And to what extent should they influence our choice of technology?</p><p>  æ¢å¥è¯è¯´ï¼Œæˆ‘ä»¬åº”è¯¥ç›¸ä¿¡è¿™äº›åŸºå‡†å¤šå°‘é’±ï¼Ÿä»–ä»¬åº”è¯¥åœ¨å¤šå¤§ç¨‹åº¦ä¸Šå½±å“æˆ‘ä»¬çš„æŠ€æœ¯é€‰æ‹©ï¼Ÿ </p><p> In order to answer these questions, in this post, I benchmark a realistic Flask application along with it&#39;s  Sanic equivalent. I&#39;m going to guess that most readers come from a background with one of the more &#34;traditional&#34; Python frameworks ( Flask or  Django), and it&#39;s certainly more relevant to devs here at Suade Labs. For this reason, I run the Flask app in a number of different ways, to see what the best bang for our buck is: how performant can we make our application with (almost) zero changes to the code? Along the way we&#39;ll pick up some tips for the original question:  how can we serve more requests from a single worker thread?</p><p>ä¸ºäº†å›ç­”è¿™äº›é—®é¢˜ï¼Œåœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘å°†ä¸€ä¸ªç°å®çš„çƒ§ç“¶ç”³è¯·ä¸å®ƒä¸€èµ·åŸºå‡†ã€‚æˆ‘å°†çŒœæµ‹å¤§å¤šæ•°è¯»è€…æ¥è‡ªä¸€ä¸ªï¼†ï¼ƒ34ä¹‹ä¸€çš„èƒŒæ™¯;ä¼ ç»Ÿï¼†ï¼ƒ34; Pythonæ¡†æ¶ï¼ˆçƒ§ç“¶æˆ–Djangoï¼‰ï¼Œå®ƒï¼†ï¼ƒ39;åœ¨Suade Labsçš„Devsè‚¯å®šæ›´ç›¸å…³ã€‚å‡ºäºè¿™ä¸ªåŸå› ï¼Œæˆ‘ä»¥å¤šç§ä¸åŒçš„æ–¹å¼è¿è¡Œçƒ§ç“¶åº”ç”¨ç¨‹åºï¼Œçœ‹çœ‹æˆ‘ä»¬çš„é™ä»·æœ€å¥½çš„çˆ†ç‚¸æ˜¯ï¼šæˆ‘ä»¬å¦‚ä½•ä½¿ç”¨ï¼ˆå‡ ä¹ï¼‰å¯¹ä»£ç è¿›è¡Œé›¶å˜åŒ–çš„åº”ç”¨ç¨‹åºï¼Ÿæ²¿ç€æˆ‘ä»¬ï¼†ï¼ƒ39; llä¸ºåŸå§‹é—®é¢˜æå–äº†ä¸€äº›æç¤ºï¼šæˆ‘ä»¬å¦‚ä½•ä»å•ä¸ªå·¥äººçº¿ç¨‹æä¾›æ›´å¤šè¯·æ±‚ï¼Ÿ</p><p> Sidenote: if you&#39;re new to Python&#39;s web frameworks, or its asynchronous libraries, take a look at [1] from the addenda at the bottom of this post for a quick explainer. This post mostly assumes you know these things.</p><p> Sidenoteï¼šå¦‚æœä½ ï¼†ï¼ƒ39;é‡æ–°åˆ°Pythonï¼†ï¼ƒ39;å®ƒçš„Webæ¡†æ¶æˆ–å…¶å¼‚æ­¥åº“ï¼Œä»æ­¤å¸–å­åº•éƒ¨çš„Addendaçœ‹çœ‹[1]ä»¥è·å¾—å¿«é€Ÿè§£é‡Šè€…ã€‚è¿™ç¯‡æ–‡ç« ä¸»è¦å‡è®¾æ‚¨çŸ¥é“è¿™äº›äº‹æƒ…ã€‚</p><p>  First let&#39;s run some simple &#34;Hello, World!&#34; benchmarks on our system to get a meaningful baseline for comparison. For reference, the Flask benchmarks on  techempower give 25,000 requests per second.</p><p>  é¦–å…ˆè®©ï¼†ï¼ƒ39;è·‘äº†ä¸€äº›ç®€å•çš„ï¼†ï¼ƒ34;ä½ å¥½ï¼Œä¸–ç•Œï¼ï¼†ï¼ƒ34;æˆ‘ä»¬ç³»ç»Ÿçš„åŸºå‡†æµ‹è¯•ä»¥è·å¾—æœ‰æ„ä¹‰çš„åŸºçº¿è¿›è¡Œæ¯”è¾ƒã€‚ä¾›å‚è€ƒï¼ŒTechEmpowerä¸Šçš„çƒ§ç“¶åŸºå‡†å°†æ¯ç§’æä¾›25,000ä¸ªè¯·æ±‚ã€‚</p><p>  app = Flask(__name__)@app.route(&#34;/&#34;, methods=[&#34;GET&#34;, &#34;POST&#34;])def hello(): if request.method == &#34;GET&#34;: return &#34;Hello, World!&#34; data = request.get_json(force=True) try: return &#34;Hello, {id}&#34;.format(**data) except KeyError: return &#34;Missing required parameter &#39;id&#39;&#34;, 400</p><p>  app = flaskï¼ˆ__ name __ï¼‰@ app.routeï¼ˆï¼†ï¼ƒ34; /ï¼†ï¼ƒ34;æ–¹æ³•= [ï¼†ï¼ƒ34; getï¼†ï¼ƒ34; postï¼†ï¼ƒ34;]ï¼‰def helloï¼ˆï¼‰ï¼šå¦‚æœè¯·æ±‚.Method ==ï¼†ï¼ƒ34; Getï¼†ï¼ƒ34 ;:è¿”å›ï¼†ï¼ƒ34;ä½ å¥½ï¼Œä¸–ç•Œï¼ï¼†ï¼ƒ34; data = request.get_jsonï¼ˆforce = trueï¼‰å°è¯•ï¼šè¿”å›ï¼†ï¼ƒ34; helloï¼Œ{id}â€‹â€‹ï¼†ï¼ƒ34; .formatï¼ˆ**æ•°æ®ï¼‰é™¤keyerrorä¹‹å¤–ï¼šè¿”å›ï¼†ï¼ƒ34;ç¼ºå°‘å¿…éœ€å‚æ•°ï¼†ï¼ƒ39; idï¼†ï¼ƒ 39;ï¼†ï¼ƒ34 ;,400</p><p> I ran it under a variety of conditions. First &#34;raw&#34; via  python app.py, and then under  Gunicorn with a single  sync worker via  gunicorn -k sync app:app and finally Gunicorn with a single  gevent worker via  gunicorn -k gevent app:app. In theory Gunicorn should handle concurrency and dropped connections much better than the raw python, and using the gevent worker should allow us to do asynchronous IO without changing our code [2a]. We also ran these benchmarks under  PyPy, which in theory should speed up any CPU-bound code without making any changes (if you haven&#39;t heard of PyPy see [2b] in the addenda below for a quick explanation and some terminology).</p><p> æˆ‘åœ¨å„ç§æƒ…å†µä¸‹è·‘äº†å®ƒã€‚ç¬¬ä¸€ä¸ªï¼†ï¼ƒ34;ç”Ÿï¼†ï¼ƒ34;é€šè¿‡Python app.pyï¼Œç„¶ååœ¨Gunicornä¸‹é€šè¿‡Gunicorn -kåŒæ­¥åº”ç”¨ç¨‹åºï¼šåº”ç”¨ç¨‹åºå’Œæœ€åæªæ‰‹é€šè¿‡Gunicorn -K Geventåº”ç”¨ç¨‹åºï¼šåº”ç”¨ç¨‹åºçš„æªæ‰‹ï¼Œå¹¶ç»ˆäºä½¿ç”¨å•ä¸ªGeventå·¥ä½œè€…åœ¨ç†è®ºä¸Šï¼Œä¸˜é™µåº”è¯¥å¤„ç†å¹¶å‘æ€§å’Œæ‰è½çš„è¿æ¥ï¼Œæ¯”åŸå§‹Pythonå¥½å¾—å¤šï¼Œå¹¶ä¸”ä½¿ç”¨Gevent Worltåº”è¯¥è®©æˆ‘ä»¬åœ¨ä¸æ”¹å˜ä»£ç [2a]çš„æƒ…å†µä¸‹è¿›è¡Œå¼‚æ­¥IOã€‚æˆ‘ä»¬ä¹Ÿåœ¨å°æ˜è¯¾ç¨‹ä¸‹è¿è¡Œäº†è¿™äº›åŸºå‡†ï¼Œä»ç†è®ºä¸Šåº”è¯¥åŠ å¿«ä»»ä½•CPUç»‘å®šçš„ä»£ç è€Œä¸è¿›è¡Œä»»ä½•å˜åŒ–ï¼ˆå¦‚æœæ‚¨æ²¡æœ‰å¬åˆ°Pypyåœ¨ä¸‹é¢çš„addendaä¸­çœ‹åˆ°[2b]ï¼Œä»¥ä¾¿å¿«é€Ÿè§£é‡Šå’Œä¸€äº›æœ¯è¯­ï¼‰ ã€‚</p><p>  app = Sanic(__name__)@app.route(&#34;/&#34;, methods=[&#34;GET&#34;, &#34;POST&#34;])async def hello(request): if request.method == &#34;GET&#34;: return text(&#34;Hello, World!&#34;) data = request.json try: return text(&#34;Hello, {id}&#34;.format(**data)) except KeyError: raise InvalidUsage(&#34;Missing required parameter &#39;id&#39;&#34;)</p><p>  app = sanicï¼ˆ__ name __ï¼‰@ app.routeï¼ˆï¼†ï¼ƒ34; /ï¼†ï¼ƒ34;æ–¹æ³•= [ï¼†ï¼ƒ34; getï¼†ï¼ƒ34; postï¼†ï¼ƒ34; postï¼†ï¼ƒ34;]ï¼‰async def helloï¼ˆè¯·æ±‚ï¼‰ï¼šå¦‚æœè¯·æ±‚..ethod ==ï¼†ï¼ƒ34; getï¼†ï¼ƒ34 ;:è¿”å›æ–‡æœ¬ï¼ˆï¼†ï¼ƒ34;æ‚¨å¥½ï¼Œä¸–ç•Œï¼ï¼†ï¼ƒ34;ï¼‰data = request.json tryï¼šè¿”å›æ–‡æœ¬ï¼ˆï¼†ï¼ƒ34; helloï¼Œ{id} ï¼†ï¼ƒ34; .formatï¼ˆ**æ•°æ®ï¼‰ï¼‰é™¤äº†KeyErrorä¹‹å¤–ï¼šæé«˜Invalidusageï¼ˆï¼†ï¼ƒ34;ç¼ºå°‘æ‰€éœ€å‚æ•°ï¼†ï¼ƒ39; idï¼†ï¼ƒ39;ï¼†ï¼ƒ34;ï¼‰</p><p>   Some technical details: I used Python 3.7 with the regular CPython interpreter and Python 3.6 with PyPy 7.3.3. At the time of writing, running 3.6 is the latest PyPy interpreter, and their Python 2.7 interpreter is faster in some edge cases, but as Python 2 is  officially dead, I don&#39;t believe it productive to benchmark. My system details are available in the addenda [3]. I used  wrk to actually execute the benchmarks.  I&#39;ll break the results down in two parts. First: Sanic dominates, with 23,000 requests a second, although running our Flask app under Guncorn + gevent and PyPy does a pretty good job at keeping up. Second: what&#39;s going on with the performance range for our Flask app?</p><p>   ä¸€äº›æŠ€æœ¯ç»†èŠ‚ï¼šæˆ‘ä½¿ç”¨Python 3.7ä¸å¸¸è§„CPythonè§£é‡Šå™¨å’ŒPython 3.6ï¼Œå…·æœ‰Pypy 7.3.3ã€‚åœ¨æ’°å†™æœ¬æ–‡æ—¶ï¼Œè¿è¡Œ3.6æ˜¯æœ€æ–°çš„Pypyè§£é‡Šå™¨ï¼Œä»–ä»¬çš„Python 2.7è§£é‡Šå™¨åœ¨ä¸€äº›è¾¹ç¼˜æ¡ˆä»¶ä¸­æ›´å¿«ï¼Œä½†éšç€Python 2æ­£å¼æ­»äº¡ï¼Œæˆ‘ä¸ç›¸ä¿¡å®ƒä¸ºåŸºå‡†æé«˜äº†å®ƒã€‚æˆ‘çš„ç³»ç»Ÿç»†èŠ‚å¯åœ¨é™„å½•[3]ä¸­æä¾›ã€‚æˆ‘ç”¨WRKå®é™…æ‰§è¡ŒåŸºå‡†ã€‚æˆ‘ï¼†ï¼ƒ39; llåœ¨ä¸¤éƒ¨åˆ†ä¸­æ–­ç»“æœã€‚ç¬¬ä¸€ï¼šSanicå ä¸»å¯¼åœ°ä½ï¼Œæ¯ç§’æœ‰23,000ä¸ªè¯·æ±‚ï¼Œè™½ç„¶åœ¨æªå‡»+ Geventå’ŒPypyä¸‹è¿è¡Œæˆ‘ä»¬çš„çƒ§ç“¶åº”ç”¨ç¨‹åºï¼Œä½†åœ¨è·Ÿä¸ŠæŒç»­å¾ˆå¥½çš„å·¥ä½œã€‚ç¬¬äºŒï¼šä»€ä¹ˆï¼†ï¼ƒ39;æˆ‘ä»¬çš„çƒ§ç“¶åº”ç”¨ç¨‹åºçš„æ€§èƒ½èŒƒå›´ï¼Ÿ </p><p> Under CPython, we see that using Gunicorn quadruples the number of Flask requests per second from 1,000 to 4,000 and using a gevent worker adds a mild (sub 10%) speed boost to this. The PyPy results are more impressive. In the raw test, it is churning through 3,000 requests a second; it received the same 4x speed boost from Gunicorn, getting us to 12,000 requests a second; finally with the addition of gevent, it cranks up to 17,000 requests a second, 17x more than the raw CPython version without changing a single line of code.</p><p>åœ¨CPythonä¸‹ï¼Œæˆ‘ä»¬çœ‹åˆ°ä½¿ç”¨Gunicornå°†æ¯ç§’Flaskè¯·æ±‚çš„æ•°é‡å¢åŠ äº†ä¸‰å€ï¼Œä»1000å¢è‡³4,000ï¼Œè€Œä½¿ç”¨gevent workerå¢åŠ äº†é€‚åº¦ï¼ˆä½äº10ï¼…ï¼‰çš„é€Ÿåº¦ã€‚ PyPyçš„ç»“æœæ›´ä»¤äººå°è±¡æ·±åˆ»ã€‚åœ¨åŸå§‹æµ‹è¯•ä¸­ï¼Œå®ƒæ¯ç§’å¤„ç†3,000ä¸ªè¯·æ±‚ã€‚å®ƒè·å¾—äº†Gunicornç›¸åŒçš„4å€é€Ÿåº¦æå‡ï¼Œä½¿æˆ‘ä»¬æ¯ç§’è¾¾åˆ°12,000ä¸ªè¯·æ±‚ï¼›æœ€åï¼ŒåŠ ä¸Šgeventï¼Œå®ƒæ¯ç§’å¤„ç†å¤šè¾¾17,000ä¸ªè¯·æ±‚ï¼Œæ¯”åŸå§‹CPythonç‰ˆæœ¬é«˜å‡º17å€ï¼Œè€Œæ— éœ€æ›´æ”¹ä»»ä½•ä»£ç è¡Œã€‚</p><p> I was quite struck by the fact that gevent had such little effect on the CPython process - probably this is because the CPU is maxed out at this point. On the other hand, it seems that PyPy&#39;s better speed means it is still spending time waiting on system calls / IO, even under Gunicorn. Adding gevent to the mix means that it switches between concurrent connections, processing them as fast as the CPU will let it.</p><p> geventå¯¹CPythonè¿›ç¨‹çš„å½±å“å¾ˆå°ï¼Œè¿™è®©æˆ‘æ„Ÿåˆ°éå¸¸éœ‡æƒŠ-å¯èƒ½æ˜¯å› ä¸ºæ­¤æ—¶CPUå·²è¾¾åˆ°æé™ã€‚å¦ä¸€æ–¹é¢ï¼ŒPyPyçš„é€Ÿåº¦ä¼¼ä¹æ›´å¿«ï¼Œè¿™æ„å‘³ç€å³ä½¿åœ¨Gunicornçš„æ”¯æŒä¸‹ï¼ŒPyPyä»åœ¨èŠ±æ—¶é—´ç­‰å¾…ç³»ç»Ÿè°ƒç”¨/ IOã€‚åœ¨æ··åˆä¸­æ·»åŠ geventæ„å‘³ç€å®ƒå¯ä»¥åœ¨å¹¶å‘è¿æ¥ä¹‹é—´åˆ‡æ¢ï¼Œå¹¶ä»¥CPUå…è®¸çš„é€Ÿåº¦è¿›è¡Œå¤„ç†ã€‚</p><p> To get a real sense of this, I ran the benchmark whilst monitoring CPU usage. Here&#39;s a short test against the raw app under PyPy:</p><p> ä¸ºäº†çœŸæ­£ç†è§£è¿™ä¸€ç‚¹ï¼Œæˆ‘åœ¨ç›‘è§†CPUä½¿ç”¨ç‡çš„åŒæ—¶è¿è¡Œäº†åŸºå‡†æµ‹è¯•ã€‚ä»¥ä¸‹æ˜¯é’ˆå¯¹PyPyä¸‹åŸå§‹åº”ç”¨çš„ç®€çŸ­æµ‹è¯•ï¼š</p><p>  You can see that the program hops between CPU cores and rarely utilises 100% of a given core. On the other hand, here&#39;s part of a much longer test against the Gunicorn gevent worker under PyPy:</p><p>  æ‚¨å¯ä»¥çœ‹åˆ°è¯¥ç¨‹åºåœ¨CPUå†…æ ¸ä¹‹é—´è·³è½¬ï¼Œå¾ˆå°‘ä½¿ç”¨ç»™å®šå†…æ ¸çš„100ï¼…ã€‚å¦ä¸€æ–¹é¢ï¼Œè¿™æ˜¯åœ¨PyPyä¸‹é’ˆå¯¹Gunicorn geventå·¥ä½œè€…è¿›è¡Œçš„æ›´é•¿æµ‹è¯•çš„ä¸€éƒ¨åˆ†ï¼š</p><p>  Now it&#39;s evident that there is no switching between CPU cores (the process has become &#34;sticky&#34;) and the individual core is being utilised to a far higher degree.</p><p>  ç°åœ¨ï¼Œå¾ˆæ˜æ˜¾ï¼ŒCPUå†…æ ¸ä¹‹é—´æ²¡æœ‰åˆ‡æ¢ï¼ˆè¯¥è¿‡ç¨‹å˜å¾—â€œç²˜æ»â€ï¼‰ï¼Œå¹¶ä¸”å•ä¸ªå†…æ ¸çš„ä½¿ç”¨ç¨‹åº¦æ›´é«˜ã€‚</p><p>   The benchmark above, while fun, is pretty meaningless for real-world applications. Let&#39;s add some more functionality to our app!  First, we&#39;ll allow users to actually store data in a database, which we&#39;ll retrieve via an ORM (in our case  SQLAlchemy, the de-facto stand-alone ORM in python). Second, we&#39;ll add input-validation to make sure our users get meaningful error messages, and that we&#39;re not accepting junk that crashes our app. Finally we&#39;ll add a response marshaller to automate the process of converting our database object to JSON.</p><p>   ä¸Šé¢çš„åŸºå‡†æµ‹è¯•è™½ç„¶å¾ˆæœ‰è¶£ï¼Œä½†å¯¹äºç°å®ä¸–ç•Œçš„åº”ç”¨ç¨‹åºå´æ¯«æ— æ„ä¹‰ã€‚è®©æˆ‘ä»¬ä¸ºæˆ‘ä»¬çš„åº”ç”¨æ·»åŠ æ›´å¤šåŠŸèƒ½ï¼é¦–å…ˆï¼Œæˆ‘ä»¬å°†å…è®¸ç”¨æˆ·å°†æ•°æ®å®é™…å­˜å‚¨åœ¨æ•°æ®åº“ä¸­ï¼Œå¹¶é€šè¿‡ORMï¼ˆåœ¨æˆ‘ä»¬çš„ç¤ºä¾‹ä¸­ä¸ºSQLAlchemyï¼Œå®é™…ä¸Šæ˜¯pythonä¸­çš„ç‹¬ç«‹ORMï¼‰æ£€ç´¢æ•°æ®åº“ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬å°†æ·»åŠ è¾“å…¥éªŒè¯ï¼Œä»¥ç¡®ä¿æˆ‘ä»¬çš„ç”¨æˆ·æ”¶åˆ°æœ‰æ„ä¹‰çš„é”™è¯¯æ¶ˆæ¯ï¼Œå¹¶ä¸”æˆ‘ä»¬ä¸æ¥å—ä½¿åº”ç”¨ç¨‹åºå´©æºƒçš„åƒåœ¾é‚®ä»¶ã€‚æœ€åï¼Œæˆ‘ä»¬å°†æ·»åŠ ä¸€ä¸ªå“åº”ç¼–ç»„å™¨ä»¥è‡ªåŠ¨åŒ–å°†æ•°æ®åº“å¯¹è±¡è½¬æ¢ä¸ºJSONçš„è¿‡ç¨‹ã€‚</p><p> We&#39;ll write a simple book store app, for a publishing house. We have a number of authors each writing zero or more books in several genres. For simplicity, each book has only a single author, but can have multiple genres - for example we could have a book which is in both the &#34;Existential Fiction&#34; and &#34;Beatnik Poetry&#34; categories. We&#39;re going to add 1 million authors to our database and roughly 10 million books. [4]</p><p> æˆ‘ä»¬å°†ä¸ºå‡ºç‰ˆç¤¾ç¼–å†™ä¸€ä¸ªç®€å•çš„ä¹¦åº—åº”ç”¨ã€‚æˆ‘ä»¬æœ‰è®¸å¤šä½œè€…ï¼Œæ¯æœ¬ä¹¦å†™ä½œå‡ ç±»æˆ–é›¶æœ¬æˆ–æ›´å¤šæœ¬ã€‚ä¸ºç®€å•èµ·è§ï¼Œæ¯æœ¬ä¹¦åªæœ‰ä¸€ä½ä½œè€…ï¼Œä½†å¯ä»¥æœ‰å¤šç§ä½“è£-ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥æœ‰ä¸€æœ¬ä¹¦åŒæ—¶å­˜åœ¨äºï¼†ï¼ƒ34; Existential Fictionï¼†ï¼ƒ34;ä¸­ã€‚å’Œï¼†ï¼ƒ34;è´ç‰¹å°¼å…‹è¯—æ­Œï¼†ï¼ƒ34;ç±»åˆ«ã€‚æˆ‘ä»¬å°†å‘æ•°æ®åº“ä¸­å¢åŠ 100ä¸‡åä½œè€…å’Œå¤§çº¦1000ä¸‡æœ¬ä¹¦ã€‚ [4] </p><p>  class Author(db.Model): id = db.Column(UUIDType, primary_key=True) name = db.Column(db.String, nullable=False) ... # snip!class Book(db.Model): author_id = db.Column( UUIDType, db.ForeignKey(&#34;author.id&#34;), nullable=False, index=True ) author = db.relationship(&#34;Author&#34;, backref=&#34;books&#34;) ... # snip!</p><p>ç±»Authorï¼ˆdb.Modelï¼‰ï¼šid = db.Columnï¼ˆUUIDTypeï¼Œprimary_key = Trueï¼‰åç§°= db.Columnï¼ˆdb.Stringï¼Œnullable = Falseï¼‰...ï¼ƒsnipï¼class Bookï¼ˆdb.Modelï¼‰ï¼šauthor_id = db.Columnï¼ˆUUIDTypeï¼Œdb.ForeignKeyï¼ˆï¼†ï¼ƒ34; author.idï¼†ï¼ƒ34;ï¼‰ï¼Œnullable = Falseï¼Œindex = Trueï¼‰author = db.relationshipï¼ˆï¼†ï¼ƒ34; Authorï¼†ï¼ƒ34 ;, backref =ï¼†ï¼ƒ34 ; booksï¼†ï¼ƒ34;ï¼‰...ï¼ƒå‰ªï¼</p><p> To marshal these, we use  Marshmallow, which is a popular Python marshalling library. Here&#39;s an example of the Marshmallow model for the Author overview:</p><p> è¦å°é€è¿™äº›æ–‡ä»¶ï¼Œæˆ‘ä»¬ä½¿ç”¨æ£‰èŠ±ç³–ï¼Œè¿™æ˜¯ä¸€ä¸ªæµè¡Œçš„Pythonå°é€åº“ã€‚è¿™æ˜¯ä½œè€…æ¦‚è¿°çš„æ£‰èŠ±ç³–æ¨¡å‹çš„ç¤ºä¾‹ï¼š</p><p> class Author(Schema): id = fields.Str(dump_only=True) name = fields.Str(required=True) country_code = EnumField(CountryCodes, required=True) email = fields.Str(required=True) phone = fields.Str(required=True) contact_address = fields.Str(required=True) contract_started = fields.DateTime(format=&#34;iso&#34;) contract_finished = fields.DateTime(format=&#34;iso&#34;) contract_value = fields.Integer()</p><p> ç±»Authorï¼ˆSchemaï¼‰ï¼šid =å­—æ®µ.Strï¼ˆdump_only = Trueï¼‰åç§°=å­—æ®µ.Strï¼ˆrequired = Trueï¼‰country_code = EnumFieldï¼ˆCountryCodesï¼Œrequired = Trueï¼‰email =å­—æ®µ.Strï¼ˆrequired = Trueï¼‰phone =å­—æ®µã€‚ Strï¼ˆrequired = Trueï¼‰contact_address =å­—æ®µ.Strï¼ˆrequired = Trueï¼‰contract_started =å­—æ®µ.DateTimeï¼ˆformat =ï¼†ï¼ƒ34; isoï¼†ï¼ƒ34;ï¼‰contract_finished =å­—æ®µ.DateTimeï¼ˆformat =ï¼†ï¼ƒ34; isoï¼†ï¼ƒ34;ï¼‰ contract_value = fields.Integerï¼ˆï¼‰</p><p>  @bp.route(&#34;/author&#34;, methods=[&#34;GET&#34;, &#34;POST&#34;])def author(): &#34;&#34;&#34;View all authors, or create a new one.&#34;&#34;&#34; if request.method == &#34;GET&#34;: args = validate_get(marshallers.LimitOffsetSchema()) limit = args[&#34;limit&#34;] offset = args[&#34;offset&#34;] authors = Author.query.limit(limit).offset(offset).all() return jsonify(marshallers.authors.dump(authors)) if request.method == &#34;POST&#34;: author = Author(**validate_post(marshallers.author)) db.session.add(author) db.session.commit() return jsonify({&#34;id&#34;: author.id})</p><p>  @ bp.routeï¼ˆï¼†ï¼ƒ34; / authorï¼†ï¼ƒ34 ;, methods = [ï¼†ï¼ƒ34; GETï¼†ï¼ƒ34 ;,ï¼†ï¼ƒ34; POSTï¼†ï¼ƒ34;]ï¼‰def authorï¼ˆï¼‰ï¼šï¼†ï¼ƒ34;ï¼†ï¼ƒ34; ï¼†ï¼ƒ34;æŸ¥çœ‹æ‰€æœ‰ä½œè€…ï¼Œæˆ–åˆ›å»ºä¸€ä¸ªæ–°ä½œè€…ã€‚ï¼†ï¼ƒ34;ï¼†ï¼ƒ34;ï¼†ï¼ƒ34;å¦‚æœrequest.method ==ï¼†ï¼ƒ34; GETï¼†ï¼ƒ34 ;ï¼š args = validate_getï¼ˆmarshallers.LimitOffsetSchemaï¼ˆï¼‰ï¼‰limit = args [ï¼†ï¼ƒ34; limitï¼†ï¼ƒ34;] offset = args [ï¼†ï¼ƒ34; offsetï¼†ï¼ƒ34; ] authors = Author.query.limitï¼ˆlimitï¼‰.offsetï¼ˆoffsetï¼‰.allï¼ˆï¼‰å¦‚æœrequest.method ==ï¼†ï¼ƒ34; POSTï¼†ï¼ƒ34;åˆ™è¿”å›jsonifyï¼ˆmarshallers.authors.dumpï¼ˆauthorsï¼‰ï¼‰ï¼šauthor = Author ï¼ˆ** validate_postï¼ˆmarshallers.authorï¼‰ï¼‰db.session.addï¼ˆä½œè€…ï¼‰db.session.commitï¼ˆï¼‰è¿”å›jsonifyï¼ˆ{ï¼†ï¼ƒ34; idï¼†ï¼ƒ34 ;: author.id}ï¼‰</p><p> The full source code can be viewed in the  GitHub repo. Here, the thing to note is that  marshallers.foo is an instance of a  Marshmallow schema, which can be used both to validate a Foo input, for instance in a POST request, as well as to marshal Foo instances ready for returning as JSON.</p><p> å®Œæ•´çš„æºä»£ç å¯ä»¥åœ¨GitHubå­˜å‚¨åº“ä¸­æŸ¥çœ‹ã€‚åœ¨è¿™é‡Œï¼Œéœ€è¦æ³¨æ„çš„æ˜¯marshallers.fooæ˜¯Marshmallowæ¨¡å¼çš„å®ä¾‹ï¼Œå¯ç”¨äºéªŒè¯Fooè¾“å…¥ï¼ˆä¾‹å¦‚åœ¨POSTè¯·æ±‚ä¸­ï¼‰ä»¥åŠå°é€å‡†å¤‡ä½œä¸ºJSONè¿”å›çš„Fooå®ä¾‹ã€‚</p><p> In order to actually perform asynchronous database requests, some fancy footwork is required with patching libraries, which depends on which postgres connector you use. SQLAlchemy does not support this out of the box, and in fact its primary developer has a great post arguing that  an async ORM is not always a great idea. Juicy technical details in addenda [5], but beware that just using a Gunicorn gevent worker will not necessarily get you what you want.</p><p> ä¸ºäº†å®é™…æ‰§è¡Œå¼‚æ­¥æ•°æ®åº“è¯·æ±‚ï¼Œä¿®è¡¥åº“éœ€è¦èŠ±å“¨çš„æ­¥ä¼ï¼Œè¿™å–å†³äºæ‚¨ä½¿ç”¨çš„postgresè¿æ¥å™¨ã€‚ SQLAlchemyä¸æ”¯æŒæ­¤åŠŸèƒ½ï¼Œå®é™…ä¸Šï¼Œå®ƒçš„ä¸»è¦å¼€å‘äººå‘˜åœ¨ä¸€ç¯‡å¾ˆæ£’çš„æ–‡ç« ä¸­æŒ‡å‡ºï¼Œå¼‚æ­¥ORMå¹¶ä¸æ€»æ˜¯ä¸€ä¸ªå¥½ä¸»æ„ã€‚é™„å½•[5]ä¸­æœ‰è®¸å¤šæŠ€æœ¯ç»†èŠ‚ï¼Œä½†æ˜¯è¯·æ³¨æ„ï¼Œä»…ä½¿ç”¨Gunicorn gevent workerå¹¶ä¸ä¸€å®šèƒ½ä¸ºæ‚¨æä¾›æ‰€éœ€çš„ä¸œè¥¿ã€‚</p><p> PyPy tends to suffer a performance hit when using C-extensions and libraries instead of pure python, conversely CPython should get a performance boost from the C-based libs. To take account of this I tested two different underlying database connectors: both  psycopg2 and a pure-python counterpart  pg8000, and two different classes of async gunicorn worker:  gevent and a pure-python counterpart  eventlet.</p><p> å½“ä½¿ç”¨Cæ‰©å±•åå’Œåº“è€Œä¸æ˜¯çº¯pythonæ—¶ï¼ŒPyPyå¾€å¾€ä¼šé­å—æ€§èƒ½ä¸‹é™ï¼Œç›¸åï¼ŒCPythonåº”è¯¥ä»åŸºäºCçš„åº“ä¸­è·å¾—æ€§èƒ½æå‡ã€‚è€ƒè™‘åˆ°è¿™ä¸€ç‚¹ï¼Œæˆ‘æµ‹è¯•äº†ä¸¤ä¸ªä¸åŒçš„åŸºç¡€æ•°æ®åº“è¿æ¥å™¨ï¼špsycopg2å’Œä¸€ä¸ªçº¯Pythonå¯¹åº”çš„pg8000ï¼Œä»¥åŠä¸¤ä¸ªä¸åŒç±»çš„å¼‚æ­¥gunicorn workerï¼šgeventå’Œä¸€ä¸ªçº¯pythonå¯¹åº”çš„eventletã€‚ </p><p> What about the Sanic rewrite of our app? Well, as mentioned SQLAlchemy is not really async, and it definitely doesn&#39;t support python&#39;s  await syntax. So if we want non-blocking database requests we have three choices:</p><p>Sanicé‡å†™æˆ‘ä»¬çš„åº”ç”¨ç¨‹åºæ€ä¹ˆæ ·ï¼Ÿå¥½å§ï¼Œå¦‚ä¸Šæ‰€è¿°ï¼ŒSQLAlchemyå¹¶ä¸æ˜¯çœŸæ­£å¼‚æ­¥çš„ï¼Œå®ƒç»å¯¹ä¸æ”¯æŒpythonçš„awaitè¯­æ³•ã€‚å› æ­¤ï¼Œå¦‚æœæˆ‘ä»¬è¦éé˜»å¡æ•°æ®åº“è¯·æ±‚ï¼Œæˆ‘ä»¬æœ‰ä¸‰ä¸ªé€‰æ‹©ï¼š</p><p> choose a library like  databases which allows us to keep the models / SQLAlchemy core for queries, but loose a lot of the features</p><p> é€‰æ‹©ä¸€ä¸ªåƒæ•°æ®åº“è¿™æ ·çš„åº“ï¼Œå®ƒä½¿æˆ‘ä»¬èƒ½å¤Ÿä¿ç•™æ¨¡å‹/ SQLAlchemyæ ¸å¿ƒè¿›è¡ŒæŸ¥è¯¢ï¼Œä½†ä¼šå¤±å»å¾ˆå¤šåŠŸèƒ½</p><p> We&#39;ll get the best code from 1, but it will also involve the most thought and re-writing. It pulls in many other considerations: for instance, schema migrations, testing, how to deal with missing features (SQLAlchemy just does a lot of  advanced stuff that other ORMs don&#39;t do). The fastest application will probably come from 3, but also the most technical debt, pain and opacity.</p><p> æˆ‘ä»¬å°†ä»1ä¸­è·å¾—æœ€å¥½çš„ä»£ç ï¼Œä½†å®ƒä¹Ÿå°†æ¶‰åŠæœ€å¤šçš„æ€è€ƒå’Œé‡å†™ã€‚å®ƒå¼•å…¥äº†è®¸å¤šå…¶ä»–è€ƒè™‘å› ç´ ï¼šä¾‹å¦‚ï¼Œæ¶æ„è¿ç§»ï¼Œæµ‹è¯•ï¼Œå¦‚ä½•å¤„ç†ç¼ºå°‘çš„åŠŸèƒ½ï¼ˆSQLAlchemyåªæ˜¯åšäº†è®¸å¤šå…¶ä»–ORMä¸ä¼šåšçš„é«˜çº§äº‹æƒ…ï¼‰ã€‚æœ€å¿«çš„åº”ç”¨ç¨‹åºå¯èƒ½æ¥è‡ª3ï¼Œä½†ä¹Ÿæœ‰æŠ€æœ¯æ¬ ä½³ï¼Œç—›è‹¦å’Œä¸é€æ˜æ€§ã€‚</p><p> In the end I opted for 2 and almost immediately wished I&#39;d done 1. In part this was due to some incompatibilities between the various libraries. But it also made joins very tedious and hacky to marshal correctly. After this brief diversion, I switched to  Tortoise ORM which was really pleasant in comparison!</p><p> æœ€åï¼Œæˆ‘é€‰æ‹©äº†2ï¼Œå‡ ä¹ç«‹å³å¸Œæœ›æˆ‘å®Œæˆ1ã€‚éƒ¨åˆ†åŸå› æ˜¯å„ä¸ªåº“ä¹‹é—´å­˜åœ¨ä¸€äº›ä¸å…¼å®¹æ€§ã€‚ä½†æ˜¯ï¼Œè¿™ä¹Ÿä½¿åŠ å…¥å˜å¾—éå¸¸ä¹å‘³å’Œhackyï¼Œæ— æ³•æ­£ç¡®åœ°è¿›è¡Œå°é€ã€‚ç»è¿‡çŸ­æš‚çš„è½¬ç§»ä¹‹åï¼Œæˆ‘åˆ‡æ¢åˆ°äº†Tortoise ORMï¼Œç›¸æ¯”ä¹‹ä¸‹ï¼Œè¿™çœŸçš„å¾ˆä»¤äººæ„‰å¿«ï¼</p><p>  @bp.route(&#34;/author&#34;, methods=[&#34;GET&#34;, &#34;POST&#34;])async def author(request): &#34;&#34;&#34;View all authors, or create a new one.&#34;&#34;&#34; if request.method == &#34;GET&#34;: args = validate_get(request, marshallers.LimitOffsetSchema()) limit = args[&#34;limit&#34;] offset = args[&#34;offset&#34;] authors = await Author.all().prefetch_related( &#34;country_code&#34; ).limit(limit).offset(offset) return json(marshallers.authors.dump(authors)) if request.method == &#34;POST&#34;: author = Author(**validate_post(marshallers.author)) await author.save() return json({&#34;id&#34;: author.id})</p><p>  @ bp.routeï¼ˆï¼†ï¼ƒ34; / authorï¼†ï¼ƒ34 ;, Methods = [ï¼†ï¼ƒ34; GETï¼†ï¼ƒ34 ;,ï¼†ï¼ƒ34; POSTï¼†ï¼ƒ34;]ï¼‰å¼‚æ­¥å®šä¹‰ä½œè€…ï¼ˆè¯·æ±‚ï¼‰ï¼šï¼†ï¼ƒ34;ï¼†ï¼ƒ 34;ï¼†ï¼ƒ34;æŸ¥çœ‹æ‰€æœ‰ä½œè€…ï¼Œæˆ–åˆ›å»ºä¸€ä¸ªæ–°ä½œè€…ã€‚ï¼†ï¼ƒ34;ï¼†ï¼ƒ34;ï¼†ï¼ƒ34;å¦‚æœrequest.method ==ï¼†ï¼ƒ34; GETï¼†ï¼ƒ34 ;ï¼š args = validate_getï¼ˆrequestï¼Œmarshallers.LimitOffsetSchemaï¼ˆï¼‰ï¼‰limit = args [ï¼†ï¼ƒ34; limitï¼†ï¼ƒ34;] offset = args [ï¼†ï¼ƒ34; offsetï¼†ï¼ƒ 34;] authors = await Author.allï¼ˆï¼‰ã€‚prefetch_relatedï¼ˆï¼†ï¼ƒ34; country_codeï¼†ï¼ƒ34;ï¼‰.limitï¼ˆlimitï¼‰.offsetï¼ˆoffsetï¼‰å¦‚æœè¯·æ±‚request.method =ï¼Œåˆ™è¿”å›jsonï¼ˆmarshallers.authors.dumpï¼ˆauthorsï¼‰ï¼‰ã€‚ =ï¼†ï¼ƒ34; POSTï¼†ï¼ƒ34 ;ï¼šä½œè€…= Authorï¼ˆ** validate_postï¼ˆmarshallers.authorï¼‰ï¼‰ç­‰å¾…author.saveï¼ˆï¼‰è¿”å›jsonï¼ˆ{ï¼†ï¼ƒ34; idï¼†ï¼ƒ34 ;: author.id}ï¼‰</p><p> Notice in the above that I had to &#34;prefetch&#34; (i.e. join) the country code table.  This had to do with difficulty expressing that I wanted a foreign key constraint, but not a relationship/join in Tortoise ORM. There is undoubtably some voodoo I can do to fix this, but it&#39;s not super-obvious. The country code table just consists of the 300 or so ISO 3166 country codes, so is probably in memory and any overhead will be marginal.</p><p> è¯·æ³¨æ„ï¼Œåœ¨ä¸Šæ–‡ä¸­ï¼Œæˆ‘å¿…é¡»ï¼†ï¼ƒ34; prefetchï¼†ï¼ƒ34; ï¼ˆå³åŠ å…¥ï¼‰å›½å®¶/åœ°åŒºä»£ç è¡¨ã€‚è¿™ä¸è¡¨è¾¾æˆ‘æƒ³è¦å¤–é”®çº¦æŸè€Œä¸æ˜¯Tortoise ORMä¸­çš„å…³ç³»/è”æ¥å¾ˆå›°éš¾ã€‚æ¯«æ— ç–‘é—®ï¼Œæˆ‘å¯ä»¥é‡‡å–ä¸€äº›ä¼éƒ½æ•™æ¥è§£å†³æ­¤é—®é¢˜ï¼Œä½†è¿™å¹¶ä¸æ˜¯å¾ˆæ˜æ˜¾ã€‚å›½å®¶/åœ°åŒºä»£ç è¡¨ä»…ç”±300ä¸ªå·¦å³çš„ISO 3166å›½å®¶/åœ°åŒºä»£ç ç»„æˆï¼Œå› æ­¤å¯èƒ½åœ¨å†…å­˜ä¸­ï¼Œä»»ä½•å¼€é”€éƒ½æ˜¯å¾ˆå°çš„ã€‚</p><p> Key takeaways: Switching frameworks requires you to evaluate and choose an entire ecosystem of libraries, along with their peculiarities. Sanic and Tortoise are really nice and have great ergonomics for working with  asyncio. Working without an ORM is tedious.</p><p> å…³é”®è¦ç‚¹ï¼šè½¬æ¢æ¡†æ¶è¦æ±‚æ‚¨è¯„ä¼°å’Œé€‰æ‹©æ•´ä¸ªåº“ç”Ÿæ€ç³»ç»ŸåŠå…¶ç‰¹æ€§ã€‚ Sanicå’ŒTortoiseçœŸçš„å¾ˆæ£’ï¼Œå¹¶ä¸”åœ¨ä½¿ç”¨asyncioæ–¹é¢å…·æœ‰å‡ºè‰²çš„äººä½“å·¥ç¨‹å­¦ã€‚æ²¡æœ‰ORMçš„å·¥ä½œå¾ˆä¹å‘³ã€‚ </p><p>  Let&#39;s start with the  /author/&lt;author_id&gt; endpoint. Here we select a single author, by primary key, from the database - collect a summary of each of their books and package the whole lot up to return to the user.</p><p>è®©æˆ‘ä»¬ä»/ author /ï¼†lt; author_idï¼†gt;å¼€å§‹ç«¯ç‚¹ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬é€šè¿‡ä¸»é”®ä»æ•°æ®åº“ä¸­é€‰æ‹©ä¸€ä½ä½œè€…-æ”¶é›†ä»–ä»¬æ¯æœ¬ä¹¦çš„æ‘˜è¦ï¼Œå¹¶å°†å…¨éƒ¨ä¹¦ç±æ‰“åŒ…ä»¥è¿”å›ç»™ç”¨æˆ·ã€‚</p><p> Since I wanted at least some business logic in our app, I added what I consider to be an interesting field to the  Author model and  AuthorDetail marshaller:</p><p> ç”±äºæˆ‘å¸Œæœ›åœ¨æˆ‘ä»¬çš„åº”ç”¨ç¨‹åºä¸­è‡³å°‘åŒ…å«ä¸€äº›ä¸šåŠ¡é€»è¾‘ï¼Œå› æ­¤æˆ‘åœ¨Authoræ¨¡å‹å’ŒAuthorDetail marshallerä¸­æ·»åŠ äº†æˆ‘è®¤ä¸ºæ˜¯æœ‰è¶£çš„å­—æ®µï¼š</p><p>  This essentially says that, to return the author&#39;s genres, we have to pull out all of their books&#39;  genres, and then merge into a deduplicated and sorted list.</p><p>  ä»æœ¬è´¨ä¸Šè®²ï¼Œè¦è¿”å›ä½œè€…çš„ä½“è£ï¼Œæˆ‘ä»¬å¿…é¡»æ‹¿å‡ºä»–ä»¬æ‰€æœ‰çš„ä¹¦ã€‚ç§ç±»ï¼Œç„¶ååˆå¹¶ä¸ºå·²åˆ é™¤é‡å¤æ•°æ®å’Œæ’åºçš„åˆ—è¡¨ã€‚</p><p>  As expected, the pure python libraries performed a little better than their C-based counterparts under PyPy and a little worse under CPython. Because nothing outside of a micro-benchmark is entirely neat, this was not always the case, and in fact the difference was completely marginal, so I didn&#39;t include all of the results. See addenda [6] for full results.</p><p>  ä¸å‡ºæ‰€æ–™ï¼Œçº¯pythonåº“åœ¨PyPyä¸‹çš„æ€§èƒ½æ¯”å…¶åŸºäºCçš„åŒç±»è¦å¥½ä¸€äº›ï¼Œè€Œåœ¨CPythonä¸‹åˆ™è¦å·®ä¸€äº›ã€‚å› ä¸ºå¾®åŸºå‡†æµ‹è¯•ä¹‹å¤–æ²¡æœ‰ä»€ä¹ˆæ˜¯å®Œå…¨æ•´æ´çš„ï¼Œæ‰€ä»¥æƒ…å†µå¹¶éæ€»æ˜¯å¦‚æ­¤ï¼Œå®é™…ä¸Šå·®å¼‚å®Œå…¨æ˜¯å¾®ä¸è¶³é“çš„ï¼Œå› æ­¤æˆ‘æ²¡æœ‰åŒ…æ‹¬æ‰€æœ‰ç»“æœã€‚æœ‰å…³å®Œæ•´ç»“æœï¼Œè¯·å‚è§é™„å½•[6]ã€‚</p><p> No matter what libraries or setup we use here, we&#39;re performing less requests than the worst &#34;Hello, World!&#34; example in the intro. What&#39;s more, it seems like the asynchronous PyPy worker does worse than the synchronous one with high concurrency - which sort of flips the original benchmark on its head! Which pretty conclusively answers the other questions we had: &#34;Hello, World!&#34; benchmarks are not realistic and bear little relation to our actual application.</p><p> æ— è®ºæˆ‘ä»¬åœ¨è¿™é‡Œä½¿ç”¨ä»€ä¹ˆåº“æˆ–è®¾ç½®ï¼Œä¸æœ€å·®çš„â€œ Helloï¼ŒWorldï¼â€ç›¸æ¯”ï¼Œæˆ‘ä»¬æ‰§è¡Œçš„è¯·æ±‚éƒ½æ›´å°‘ã€‚ç®€ä»‹ä¸­çš„ç¤ºä¾‹ã€‚æ›´æœ‰ä»€è€…ï¼Œå¼‚æ­¥PyPy workerä¼¼ä¹æ¯”å…·æœ‰é«˜å¹¶å‘æ€§çš„åŒæ­¥PyPy workeræ›´ç³Ÿ-è¿™åœ¨æŸç§ç¨‹åº¦ä¸Šé¢ è¦†äº†åŸå§‹åŸºå‡†ï¼å“ªä¸€ä¸ªæœ€ç»ˆå¯ä»¥å›ç­”æˆ‘ä»¬é‡åˆ°çš„å…¶ä»–é—®é¢˜ï¼šï¼†nbsp; Helloï¼ŒWorldï¼ï¼†ï¼ƒ34;åŸºå‡†å¹¶ä¸ç°å®ï¼Œä¸æˆ‘ä»¬çš„å®é™…åº”ç”¨å…³ç³»ä¸å¤§ã€‚</p><p> Another conclusion we can draw is clear: if the database is fast, use PyPy to make the Python app fast too. Whatever interpreter you choose, the difference between asynchronous and synchronous workers is not really too big: certainly we could pick the best performing in each case, but it may have been noise [7]. Sanic performs a little less than twice as well as CPython + Flask, which is impressive, but probably not worth the effort of rewriting the app if we can get this for free under PyPy.</p><p> æˆ‘ä»¬å¯ä»¥å¾—å‡ºçš„å¦ä¸€ä¸ªç»“è®ºå¾ˆæ˜ç¡®ï¼šå¦‚æœæ•°æ®åº“æ˜¯å¿«é€Ÿçš„ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨PyPyæ¥ä½¿Pythonåº”ç”¨ç¨‹åºå¿«é€Ÿã€‚æ— è®ºæ‚¨é€‰æ‹©å“ªç§è§£é‡Šå™¨ï¼Œå¼‚æ­¥å·¥ä½œè€…å’ŒåŒæ­¥å·¥ä½œè€…ä¹‹é—´çš„åŒºåˆ«å¹¶ä¸æ˜¯å¤ªå¤§ï¼šå½“ç„¶ï¼Œåœ¨æ¯ç§æƒ…å†µä¸‹æˆ‘ä»¬éƒ½å¯ä»¥é€‰æ‹©æ€§èƒ½æœ€å¥½çš„ï¼Œä½†æ˜¯å®ƒå¯èƒ½æ˜¯å™ªéŸ³[7]ã€‚ Sanicçš„æ€§èƒ½ä¸åˆ°CPython + Flaskçš„ä¸¤å€ï¼Œè¿™æ˜¯ä»¤äººå°è±¡æ·±åˆ»çš„ï¼Œä½†å¦‚æœæˆ‘ä»¬å¯ä»¥åœ¨PyPyä¸‹å…è´¹è·å¾—å®ƒï¼Œåˆ™å¯èƒ½ä¸å€¼å¾—é‡å†™åº”ç”¨ç¨‹åºã€‚</p><p> The  /author overview endpoint gives pretty much the same results. But let&#39;s see what happens if we put a little more load on the database. To simulate a complex query we&#39;re going to hit  /author?limit=20&amp;offset=50000, which should give the database something other to do than looking up by primary key. There&#39;s also some python work to be done validating parameters and marshalling 20 authors. Here&#39;s the result:</p><p> / authoræ¦‚è¿°ç«¯ç‚¹ç»™å‡ºçš„ç»“æœå‡ ä¹ç›¸åŒã€‚ä½†æ˜¯ï¼Œè®©æˆ‘ä»¬çœ‹çœ‹å¦‚æœå¯¹æ•°æ®åº“æ–½åŠ æ›´å¤šçš„è´Ÿè½½ä¼šå‘ç”Ÿä»€ä¹ˆã€‚ä¸ºäº†æ¨¡æ‹Ÿå¤æ‚çš„æŸ¥è¯¢ï¼Œæˆ‘ä»¬å°†å‘½ä¸­/ authorï¼Ÿlimit = 20ï¼†amp; offset = 50000ï¼Œè¿™åº”è¯¥ä½¿æ•°æ®åº“é™¤é€šè¿‡ä¸»é”®æŸ¥æ‰¾å¤–è¿˜å¯ä»¥åšå…¶ä»–äº‹æƒ…ã€‚è¿˜éœ€è¦å®Œæˆä¸€äº›Pythonå·¥ä½œï¼Œä»¥éªŒè¯å‚æ•°å¹¶ç¼–ç»„20ä½ä½œè€…ã€‚ç»“æœå¦‚ä¸‹ï¼š </p><p>  This time it&#39;s clear that, along with PyPy, using asynchronous gunicorn workers, or an async framework like Sanic goes a long way to speeding up our app. This is the mantra of async: if you make long / irregular requests in your application, use asyncio, so that you can perform other work while waiting for a reply. At a certain point, our database hits maximum capacity and the number of requests per second stops increasing. We can take this to the extreme, by increasing the offset to 500,000:</p><p>è¿™æ¬¡å¾ˆæ˜æ˜¾ï¼Œä¸PyPyä¸€èµ·ä½¿ç”¨å¼‚æ­¥gunicornå·¥ä½œè€…æˆ–Sanicä¹‹ç±»çš„å¼‚æ­¥æ¡†æ¶å¯¹äºåŠ é€Ÿæˆ‘ä»¬çš„åº”ç”¨ç¨‹åºå¤§æœ‰å¸®åŠ©ã€‚è¿™å°±æ˜¯å¼‚æ­¥çš„å£å¤´ç¦…ï¼šå¦‚æœæ‚¨åœ¨åº”ç”¨ç¨‹åºä¸­å‘å‡ºé•¿æ—¶é—´/ä¸å®šæœŸçš„è¯·æ±‚ï¼Œè¯·ä½¿ç”¨å¼‚æ­¥ï¼Œä»¥ä¾¿æ‚¨å¯ä»¥åœ¨ç­‰å¾…å›å¤çš„åŒæ—¶æ‰§è¡Œå…¶ä»–å·¥ä½œã€‚åœ¨æŸä¸ªæ—¶åˆ»ï¼Œæˆ‘ä»¬çš„æ•°æ®åº“è¾¾åˆ°æœ€å¤§å®¹é‡ï¼Œå¹¶ä¸”æ¯ç§’çš„è¯·æ±‚æ•°é‡åœæ­¢å¢åŠ ã€‚é€šè¿‡å°†åç§»é‡å¢åŠ åˆ°500,000ï¼Œæˆ‘ä»¬å¯ä»¥å°†è¿™ä¸€ç‚¹å‘æŒ¥åˆ°æè‡´ï¼š</p><p>  Both our sync workers are now hitting a blazing  12  requests per second ğŸ˜… Using async workers seems to help a lot, but oddly Sanic struggles here. I think the Sanic result was more to do with the extra join in my Tortoise ORM code I mentioned earlier. I expect it put a tiny bit of extra load on the database. It&#39;s a valuable lesson in switching frameworks: to maintain performance you also have to choose, evaluate and tune several libraries, not just the one.  For reference, during the async benchmarks, the database was hitting 1050% CPU usage, while the API was cruising along at 50%. If we want to serve more users, one thing is clear: we&#39;re going to need to upgrade our database! Let&#39;s hope we don&#39;t have any other applications using this database, because they&#39;re probably going to be in trouble!</p><p>  ç°åœ¨ï¼Œæˆ‘ä»¬ä¸¤ä¸ªåŒæ­¥å·¥ä½œäººå‘˜éƒ½è¾¾åˆ°äº†æ¯ç§’12ä¸ªè¯·æ±‚çš„é€Ÿåº¦ã€‚ğŸ˜…ä½¿ç”¨å¼‚æ­¥å·¥ä½œç¨‹åºä¼¼ä¹æœ‰å¾ˆå¤§å¸®åŠ©ï¼Œä½†å¥‡æ€ªçš„æ˜¯Sanicåœ¨è¿™é‡ŒæŒ£æ‰ã€‚æˆ‘è®¤ä¸ºSanicçš„ç»“æœæ›´å¤šä¸å‰é¢æåˆ°çš„Tortoise ORMä»£ç ä¸­çš„é¢å¤–è”æ¥æœ‰å…³ã€‚æˆ‘å¸Œæœ›å®ƒä¼šç»™æ•°æ®åº“å¸¦æ¥ä¸€ç‚¹é¢å¤–çš„è´Ÿè½½ã€‚è¿™æ˜¯äº¤æ¢æ¡†æ¶æ–¹é¢çš„å®è´µä¸€è¯¾ï¼šè¦ä¿æŒæ€§èƒ½ï¼Œæ‚¨è¿˜å¿…é¡»é€‰æ‹©ï¼Œè¯„ä¼°å’Œè°ƒæ•´å¤šä¸ªåº“ï¼Œè€Œä¸ä»…ä»…æ˜¯ä¸€ä¸ªã€‚ä½œä¸ºå‚è€ƒï¼Œåœ¨å¼‚æ­¥åŸºå‡†æµ‹è¯•æœŸé—´ï¼Œæ•°æ®åº“çš„CPUä½¿ç”¨ç‡è¾¾åˆ°1050ï¼…ï¼Œè€ŒAPIçš„ä½¿ç”¨ç‡è¾¾åˆ°äº†50ï¼…ã€‚å¦‚æœæˆ‘ä»¬æƒ³ä¸ºæ›´å¤šçš„ç”¨æˆ·æä¾›æœåŠ¡ï¼Œé‚£å°±å¾ˆæ¸…æ¥šäº†ï¼šæˆ‘ä»¬å°†éœ€è¦å‡çº§æ•°æ®åº“ï¼å¸Œæœ›æˆ‘ä»¬æ²¡æœ‰å…¶ä»–ä»»ä½•ä½¿ç”¨æ­¤æ•°æ®åº“çš„åº”ç”¨ç¨‹åºï¼Œå› ä¸ºå®ƒä»¬å¯èƒ½ä¼šé‡åˆ°éº»çƒ¦ï¼</p><p> Key takeaways: PyPy wins. Sanic is fast, but not  that fast. You should probably run your &#34;traditional&#34; app with an async worker.</p><p> å…³é”®è¦ç‚¹ï¼šPyPyè·èƒœã€‚ Sanicå¾ˆå¿«ï¼Œä½†æ²¡æœ‰é‚£ä¹ˆå¿«ã€‚æ‚¨å¯èƒ½åº”è¯¥è¿è¡Œä¼ ç»Ÿçš„ï¼†ï¼ƒ34;å¸¦æœ‰å¼‚æ­¥å·¥ä½œç¨‹åºçš„åº”ç”¨ç¨‹åºã€‚</p><p>  In reality most of the &#34;super-fast&#34; benchmarks mean very little except for a few niche use-cases. If you look at the code in detail, you&#39;ll see that they&#39;re either simple &#34;Hello, World!&#34; or echo servers and all of them spend most of their time calling hand-crafted C code with Python bindings.</p><p>  å®é™…ä¸Šï¼Œå¤§å¤šæ•°ï¼†ï¼ƒ34; super-fastï¼†ï¼ƒ34;é™¤äº†ä¸€äº›åˆ©åŸºç”¨ä¾‹ä¹‹å¤–ï¼ŒåŸºå‡†æµ‹è¯•å‡ ä¹æ²¡æœ‰æ„ä¹‰ã€‚å¦‚æœæ‚¨ä»”ç»†æŸ¥çœ‹ä»£ç ï¼Œæ‚¨ä¼šå‘ç°å®ƒä»¬è¦ä¹ˆå¾ˆç®€å•ï¼Œè¦ä¹ˆæ˜¯Helloï¼ŒWorld !ï¼æˆ–echoæœåŠ¡å™¨ï¼Œå¹¶ä¸”æ‰€æœ‰äººéƒ½èŠ±è´¹å¤§é‡æ—¶é—´è°ƒç”¨å¸¦æœ‰Pythonç»‘å®šçš„æ‰‹å·¥Cä»£ç ã€‚</p><p> That means that these tools are great if you want to build a proxy, or serve static content, possibly even for streaming. But as soon as you introduce any actual Python work into the code you&#39;ll see those numbers plunge. If you rely upon the speed of these frameworks, then it will be hard to maintain that level of performance without e.g.  cythonising all of your code. If you plan on writing almost no Python, then choosing these frameworks is the best option. But presumably, you&#39;re writing an application in Python because you need more than a simple &#34;Hello, World!&#34; and you&#39;d actually like to write quite a bit of Python, thank you very much!</p><p> è¿™æ„å‘³ç€å¦‚æœæ‚¨æƒ³æ„å»ºä»£ç†æˆ–æä¾›é™æ€å†…å®¹ï¼ˆç”šè‡³å¯èƒ½ç”¨äºæµå¼ä¼ è¾“ï¼‰ï¼Œè¿™äº›å·¥å…·ä¹Ÿéå¸¸æœ‰ç”¨ã€‚ä½†æ˜¯ï¼Œä¸€æ—¦æ‚¨å°†ä»»ä½•å®é™…çš„Pythonå·¥ä½œå¼•å…¥ä»£ç ä¸­ï¼Œæ‚¨å°±ä¼šå‘ç°è¿™äº›æ•°å­—æ€¥å‰§ä¸‹é™ã€‚å¦‚æœæ‚¨ä¾é è¿™äº›æ¡†æ¶çš„é€Ÿåº¦ï¼Œé‚£ä¹ˆåœ¨æ²¡æœ‰è¯¸å¦‚æ­¤ç±»çš„æƒ…å†µä¸‹å¾ˆéš¾ä¿æŒè¯¥æ€§èƒ½æ°´å¹³ã€‚ cythonizeæ‚¨çš„æ‰€æœ‰ä»£ç ã€‚å¦‚æœæ‚¨æ‰“ç®—å‡ ä¹ä¸ç¼–å†™Pythonï¼Œé‚£ä¹ˆé€‰æ‹©è¿™äº›æ¡†æ¶æ˜¯æœ€å¥½çš„é€‰æ‹©ã€‚ä½†æ˜¯æƒ³å¿…æ‚¨æ­£åœ¨ç”¨Pythonç¼–å†™åº”ç”¨ç¨‹åºï¼Œå› ä¸ºæ‚¨éœ€è¦çš„ä¸ä»…ä»…æ˜¯ä¸€ä¸ªç®€å•çš„ï¼†nbsp; Helloï¼ŒWorldï¼ï¼†ï¼ƒ34;ã€‚å¹¶ä¸”æ‚¨å®é™…ä¸Šæƒ³ç¼–å†™å¾ˆå¤šPythonï¼Œéå¸¸æ„Ÿè°¢ï¼</p><p> If your service is receiving 100,000 requests a second, it&#39;s likely that the specific Python framework you use is not going to be the bottleneck. Especially if your API is stateless and you can scale it via Kubernetes or similar. At that point, a good database, with decent schema design and good architecture are going to matter far more. Having said that, if you do want more processing power, use PyPy.</p><p> å¦‚æœæ‚¨çš„æœåŠ¡æ¯ç§’æ¥æ”¶100,000ä¸ªè¯·æ±‚ï¼Œåˆ™æ‚¨ä½¿ç”¨çš„ç‰¹å®šPythonæ¡†æ¶å¯èƒ½ä¸ä¼šæˆä¸ºç“¶é¢ˆã€‚ç‰¹åˆ«æ˜¯å¦‚æœæ‚¨çš„APIæ˜¯æ— çŠ¶æ€çš„ï¼Œå¹¶ä¸”æ‚¨å¯ä»¥é€šè¿‡Kubernetesæˆ–ç±»ä¼¼çš„æ–¹æ³•è¿›è¡Œæ‰©å±•ã€‚åˆ°é‚£æ—¶ï¼Œæ‹¥æœ‰è‰¯å¥½çš„æ•°æ®åº“ï¼Œè‰¯å¥½çš„æ¶æ„è®¾è®¡å’Œè‰¯å¥½çš„ä½“ç³»ç»“æ„å°†å˜å¾—è‡³å…³é‡è¦ã€‚è¯è™½å¦‚æ­¤ï¼Œå¦‚æœæ‚¨ç¡®å®æƒ³è¦æ›´å¤šçš„å¤„ç†èƒ½åŠ›ï¼Œè¯·ä½¿ç”¨PyPyã€‚</p><p> Having the ability to run with some asynchronous capability offers clear advantages if database or service requests are likely to be anything other than instantaneous. Even if requests are usually instantaneous, picking an asynchronous runner is a low-cost way to bullet proof your app against intermittent delays. Whilst async-first frameworks like Sanic give you this out of the box, you can just as easily use a different Gunicorn worker with your Flask or Django app.</p><p> å¦‚æœæ•°æ®åº“æˆ–æœåŠ¡è¯·æ±‚å¯èƒ½ä¸æ˜¯å³æ—¶çš„ï¼Œåˆ™å…·æœ‰ä»¥æŸç§å¼‚æ­¥åŠŸèƒ½è¿è¡Œçš„èƒ½åŠ›æä¾›äº†æ˜æ˜¾çš„ä¼˜åŠ¿ã€‚å³ä½¿è¯·æ±‚é€šå¸¸æ˜¯ç¬æ—¶çš„ï¼Œé€‰æ‹©å¼‚æ­¥è¿è¡Œç¨‹åºä¹Ÿæ˜¯ä¸€ç§ä½¿åº”ç”¨ç¨‹åºå…å—é—´æ­‡æ€§å»¶è¿Ÿå½±å“çš„ä½æˆæœ¬æ–¹æ³•ã€‚è™½ç„¶åƒSanicè¿™æ ·çš„å¼‚æ­¥ä¼˜å…ˆæ¡†æ¶ä¸ºæ‚¨æä¾›äº†å¼€ç®±å³ç”¨çš„åŠŸèƒ½ï¼Œä½†æ‚¨å¯ä»¥è½»æ¾åœ°åœ¨Flaskæˆ–Djangoåº”ç”¨ä¸­ä½¿ç”¨å…¶ä»–Gunicorn workerã€‚ </p><p> What we&#39;ve seen in the benchmarks is that schema design, database choice and architecture will be the bottlenecks. Going with one of the new fully async frameworks purely for speed will probably not be as effective as just using PyPy and an async Gunicorn worker. I also found it gave me a kind of decision paralysis, asking many more questions like:  if we can keep our latency low, is it more or less performant to use a synchronous Foo client written in C, or an async one written in pure Python?</p><p>æˆ‘ä»¬åœ¨åŸºå‡†æµ‹è¯•ä¸­çœ‹åˆ°çš„æ˜¯æ¶æ„è®¾è®¡ï¼Œæ•°æ®åº“é€‰æ‹©å’Œä½“ç³»ç»“æ„å°†æˆä¸ºç“¶é¢ˆã€‚ä»…å‡ºäºé€Ÿåº¦è€ƒè™‘ï¼Œä½¿ç”¨ä¸€ç§æ–°çš„å®Œå…¨å¼‚æ­¥æ¡†æ¶å¯èƒ½ä¸ä¼šåƒä»…ä½¿ç”¨PyPyå’Œå¼‚æ­¥Gunicornå·¥äººé‚£æ ·æœ‰æ•ˆã€‚æˆ‘è¿˜å‘ç°å®ƒç»™æˆ‘å¸¦æ¥äº†å†³ç­–ç˜«ç—ªï¼Œå®ƒæå‡ºäº†è®¸å¤šå…¶ä»–é—®é¢˜ï¼Œä¾‹å¦‚ï¼šæ˜¯å¦å¯ä»¥ä¿æŒè¾ƒä½çš„å»¶è¿Ÿï¼Œä½¿ç”¨Cç¼–å†™çš„åŒæ­¥Fooå®¢æˆ·ç«¯è¿˜æ˜¯çº¯Pythonç¼–å†™çš„å¼‚æ­¥Fooå®¢æˆ·ç«¯ï¼Œæˆ–å¤šæˆ–å°‘åœ°è¡¨ç°å‡ºæ€§èƒ½ï¼Ÿ ï¼Ÿ</p><p> That doesn&#39;t mean that these frameworks aren&#39;t great pieces of engineering, or that they&#39;re not fun to write code in - they are! Actually I ended up loving the usability of Tortoise ORM when compared to kludging something together with SQLAlchemy core and databases, and I loved the explicitness of writing  await Foo.all() over an implicit query queue and connection pool.</p><p> è¿™å¹¶ä¸æ„å‘³ç€è¿™äº›æ¡†æ¶ä¸æ˜¯å¾ˆå¥½çš„å·¥ç¨‹ï¼Œä¹Ÿä¸æ˜¯è¯´ç”¨å®ƒä»¬ç¼–å†™ä»£ç å¹¶ä¸æ˜¯ä¸€ä»¶å¾ˆæœ‰è¶£çš„äº‹æƒ…ï¼å®é™…ä¸Šï¼Œä¸å°†æŸäº›ä¸œè¥¿ä¸SQLAlchemyæ ¸å¿ƒå’Œæ•°æ®åº“æ··åˆåœ¨ä¸€èµ·ç›¸æ¯”ï¼Œæˆ‘æœ€ç»ˆçˆ±ä¸Šäº†Tortoise ORMçš„å¯ç”¨æ€§ï¼Œå¹¶ä¸”æˆ‘å–œæ¬¢åœ¨éšå¼æŸ¥è¯¢é˜Ÿåˆ—å’Œè¿æ¥æ± ä¸Šç¼–å†™await Foo.allï¼ˆï¼‰çš„æ˜ç¡®æ€§ã€‚</p><p> For me, all of this emphasises the fact that unless you have some super-niche use-case in mind, it&#39;s actually a better idea to choose your framework based upon ergonomics and features, rather than speed. One framework I haven&#39;t mentioned that seems to have next-level ergonomics for industrial applications (request parsing, marshalling, automatic API documentation) is  FastAPI.</p><p> å¯¹æˆ‘è€Œè¨€ï¼Œæ‰€æœ‰è¿™äº›éƒ½å¼ºè°ƒäº†ä¸€ä¸ªäº‹å®ï¼Œé™¤éæ‚¨ç‰¢è®°ä¸€äº›è¶…çº§å°ä¼—ç”¨ä¾‹ï¼Œå¦åˆ™æ ¹æ®äººä½“å·¥ç¨‹å­¦å’ŒåŠŸèƒ½è€Œéé€Ÿåº¦æ¥é€‰æ‹©æ¡†æ¶å®é™…ä¸Šæ˜¯ä¸€ä¸ªæ›´å¥½çš„ä¸»æ„ã€‚æˆ‘æ²¡æœ‰æåˆ°çš„ä¸€ä¸ªæ¡†æ¶ä¼¼ä¹å…·æœ‰é’ˆå¯¹å·¥ä¸šåº”ç”¨ç¨‹åºçš„ä¸‹ä¸€çº§äººä½“å·¥ç¨‹å­¦ï¼ˆè¯·æ±‚è§£æï¼Œç¼–ç»„ï¼Œè‡ªåŠ¨APIæ–‡æ¡£ï¼‰ã€‚</p><p> Right now I&#39;m satisfied that our combination of Flask, Gunicorn and gevent running under PyPy is pretty much the fastest we can go in all scenarios. We&#39;ll be actively exporing FastAPI in the near future, not for its benchmarks, but for its features.  Like working on interesting problems and digging deep in to tech? We&#39;re hiring:  https://suade.org/lead/</p><p> ç°åœ¨ï¼Œæˆ‘æ„Ÿåˆ°æ»¡æ„çš„æ˜¯ï¼Œåœ¨PyPyä¸‹è¿è¡Œçš„Flaskï¼ŒGunicornå’Œgeventçš„ç»„åˆå‡ ä¹å¯ä»¥åœ¨æ‰€æœ‰æƒ…å†µä¸‹å®ç°æœ€å¿«çš„é€Ÿåº¦ã€‚æˆ‘ä»¬å°†åœ¨ä¸ä¹…çš„å°†æ¥ç§¯æå¼€å‘FastAPIï¼Œè¿™ä¸æ˜¯å› ä¸ºå®ƒçš„åŸºå‡†ï¼Œè€Œæ˜¯å› ä¸ºå®ƒçš„åŠŸèƒ½ã€‚å–œæ¬¢ç ”ç©¶æœ‰è¶£çš„é—®é¢˜å¹¶æ·±å…¥ç ”ç©¶æŠ€æœ¯å—ï¼Ÿæˆ‘ä»¬æ­£åœ¨æ‹›è˜ï¼šhttpsï¼š//suade.org/lead/</p><p>  (1) Â Most &#34;traditional&#34; Python web frameworks fall under a standard called  WSGI, where requests are handled in sequence: request comes in, is processed, reply is sent, next request comes in, etc. Most of the &#34;new-school&#34; Python frameworks use Python&#39;s  asyncio library and a different standard called  ASGI, which means that while waiting for IO (e.g. for bytes to arrive over the web) the application can switch to working on a d</p><p>  ï¼ˆ1ï¼‰å¤§éƒ¨åˆ†ï¼†ï¼ƒ34;ä¼ ç»Ÿï¼†ï¼ƒ34; Python Webæ¡†æ¶å±äºç§°ä¸ºWSGIçš„æ ‡å‡†ï¼Œå…¶ä¸­æŒ‰é¡ºåºå¤„ç†è¯·æ±‚ï¼šè¯·æ±‚è¿›å…¥ï¼Œå¤„ç†ï¼Œå‘é€ç­”å¤ï¼Œä¸‹ä¸€ä¸ªè¯·æ±‚è¿›å…¥ï¼Œç­‰ç­‰ã€‚å¤§å¤šæ•°ï¼†ï¼ƒ34; new-schoolï¼†ï¼ƒ34; Pythonæ¡†æ¶ä½¿ç”¨Pythonçš„asyncioåº“å’Œå¦ä¸€ä¸ªç§°ä¸ºASGIçš„æ ‡å‡†ï¼Œè¿™æ„å‘³ç€åœ¨ç­‰å¾…IOï¼ˆä¾‹å¦‚ï¼Œå­—èŠ‚é€šè¿‡Webåˆ°è¾¾ï¼‰æ—¶ï¼Œåº”ç”¨ç¨‹åºå¯ä»¥åˆ‡æ¢åˆ°åœ¨dä¸Šå·¥ä½œ</p><p>......</p><p>...... </p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://suade.org/dev/12-requests-per-second-with-python/">https://suade.org/dev/12-requests-per-second-with-python/</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/python/">#python</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/ç°å®/">#ç°å®</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/realistic/">#realistic</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/æ•°æ®åº“/">#æ•°æ®åº“</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/è®¾è®¡/">#è®¾è®¡</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/åˆ›æ„/">#åˆ›æ„</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/æ‘„å½±/">#æ‘„å½±</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/æ¸¸æˆ/">#æ¸¸æˆ</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/å›¾ç‰‡/">#å›¾ç‰‡</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/è½¯ä»¶/">#è½¯ä»¶</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/è§†é¢‘/">#è§†é¢‘</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/å¹¿å‘Š/">#å¹¿å‘Š</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/æ‰‹æœº/">#æ‰‹æœº</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/ç½‘ç«™/">#ç½‘ç«™</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/å…è´¹/">#å…è´¹</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/ä¸‹è½½/">#ä¸‹è½½</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/å¾®è½¯/">#å¾®è½¯</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/è‹¹æœ/">#è‹¹æœ</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/éŸ³ä¹/">#éŸ³ä¹</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/åšå®¢/">#åšå®¢</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/æ¶æ/">#æ¶æ</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/è‰ºæœ¯/">#è‰ºæœ¯</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/å·¥å…·/">#å·¥å…·</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/åˆ†äº«/">#åˆ†äº«</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy; 2020 diglog.com </div></div></body></html>