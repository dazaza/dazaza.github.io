<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>æ•°æ®åˆ†å‘å’Œç›‘æ§Data Distribution Shifts and Monitoring</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">Data Distribution Shifts and Monitoring<br/>æ•°æ®åˆ†å‘å’Œç›‘æ§</h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2022-02-17 00:53:57</div><div class="page_narrow text-break page_content"><p>Note:  This note is a work-in-progress, created for the course  CS 329S: Machine Learning Systems Design  (Stanford, 2022). For the fully developed text, see  the book   Designing Machine Learning Systems (Chip Huyen, Oâ€™Reilly 2022).  Slides (much shorter ğŸ˜).  Original Google Docs version.</p><p>æ³¨ï¼šæœ¬è¯´æ˜æ˜¯ä¸ºè¯¾ç¨‹CS 329Sï¼šæœºå™¨å­¦ä¹ ç³»ç»Ÿè®¾è®¡ï¼ˆæ–¯å¦ç¦å¤§å­¦ï¼Œ2022å¹´ï¼‰ç¼–å†™çš„æ­£åœ¨è¿›è¡Œä¸­çš„å·¥ä½œã€‚å¯¹äºå……åˆ†å¼€å‘çš„æ–‡æœ¬ï¼Œè¯·å‚é˜…ã€Šè®¾è®¡æœºå™¨å­¦ä¹ ç³»ç»Ÿã€‹ï¼ˆChip Huyenï¼ŒOâ€™Reilly 2022ï¼‰ä¸€ä¹¦ã€‚å¹»ç¯ç‰‡ï¼ˆçŸ­å¾—å¤šï¼‰ğŸ˜).  è°·æ­Œæ–‡æ¡£çš„åŸå§‹ç‰ˆæœ¬ã€‚</p><p> Letâ€™s start the note with a story I was told by an executive that many readers might be able to relate to. About two years ago, his company hired a consulting firm to develop an ML model to help them predict how many of each grocery item theyâ€™d need next week, so they could restock the items accordingly. The consulting firm took six months to develop the model. When the consulting firm handed the model over, his company deployed it and was very happy with its performance. They could finally boast to their investors that they were an AI-powered company.</p><p>è®©æˆ‘ä»¬ä»ä¸€ä½é«˜ç®¡ç»™æˆ‘è®²çš„ä¸€ä¸ªæ•…äº‹å¼€å§‹ï¼Œè®¸å¤šè¯»è€…å¯èƒ½éƒ½èƒ½ç†è§£è¿™ä¸ªæ•…äº‹ã€‚å¤§çº¦ä¸¤å¹´å‰ï¼Œä»–çš„å…¬å¸è˜è¯·äº†ä¸€å®¶å’¨è¯¢å…¬å¸å¼€å‘äº†ä¸€ä¸ªMLæ¨¡å‹ï¼Œä»¥å¸®åŠ©ä»–ä»¬é¢„æµ‹ä¸‹å‘¨ä»–ä»¬éœ€è¦å¤šå°‘ç§æ‚è´§ï¼Œè¿™æ ·ä»–ä»¬å°±å¯ä»¥ç›¸åº”åœ°é‡æ–°è¿›è´§ã€‚è¿™å®¶å’¨è¯¢å…¬å¸èŠ±äº†å…­ä¸ªæœˆçš„æ—¶é—´å¼€å‘è¿™ä¸ªæ¨¡å‹ã€‚å½“å’¨è¯¢å…¬å¸äº¤å‡ºæ¨¡å‹æ—¶ï¼Œä»–çš„å…¬å¸éƒ¨ç½²äº†å®ƒï¼Œå¹¶å¯¹å…¶æ€§èƒ½éå¸¸æ»¡æ„ã€‚ä»–ä»¬ç»ˆäºå¯ä»¥å‘æŠ•èµ„è€…å¹å˜˜è‡ªå·±æ˜¯ä¸€å®¶äººå·¥æ™ºèƒ½é©±åŠ¨çš„å…¬å¸ã€‚</p><p> However, a year later, their numbers went down. The demand for some items was consistently being overestimated, which caused the extra items to expire. At the same time, the demand for some items was consistently being underestimated, leading to lost sales. Initially, his inventory team manually changed the modelâ€™s predictions to correct the patterns they noticed, but eventually, the modelâ€™s predictions had become so bad that they could no longer use it. They had three options: pay the same consulting firm an obscene amount of money to update the model, pay another consulting firm even more money because this firm would need time to get up to speed, or hire an in-house team to maintain the model onwards.</p><p>ç„¶è€Œï¼Œä¸€å¹´åï¼Œä»–ä»¬çš„äººæ•°ä¸‹é™äº†ã€‚ä¸€äº›å•†å“çš„éœ€æ±‚ä¸€ç›´è¢«é«˜ä¼°ï¼Œè¿™å¯¼è‡´é¢å¤–çš„å•†å“è¿‡æœŸã€‚ä¸æ­¤åŒæ—¶ï¼Œä¸€äº›å•†å“çš„éœ€æ±‚ä¸€ç›´è¢«ä½ä¼°ï¼Œå¯¼è‡´é”€é‡ä¸‹é™ã€‚æœ€åˆï¼Œä»–çš„åº“å­˜å›¢é˜Ÿæ‰‹åŠ¨æ›´æ”¹æ¨¡å‹çš„é¢„æµ‹ï¼Œä»¥çº æ­£ä»–ä»¬æ³¨æ„åˆ°çš„æ¨¡å¼ï¼Œä½†æœ€ç»ˆï¼Œæ¨¡å‹çš„é¢„æµ‹å˜å¾—å¦‚æ­¤ç³Ÿç³•ï¼Œä»¥è‡³äºä»–ä»¬æ— æ³•å†ä½¿ç”¨å®ƒã€‚ä»–ä»¬æœ‰ä¸‰ä¸ªé€‰æ‹©ï¼šä»˜ç»™åŒä¸€å®¶å’¨è¯¢å…¬å¸ä¸€å¤§ç¬”é’±æ¥æ›´æ–°æ¨¡å‹ï¼Œä»˜ç»™å¦ä¸€å®¶å’¨è¯¢å…¬å¸æ›´å¤šçš„é’±ï¼Œå› ä¸ºè¿™å®¶å…¬å¸éœ€è¦æ—¶é—´æ¥è·Ÿä¸Šè¿›åº¦ï¼Œæˆ–è€…é›‡ä½£ä¸€ä¸ªå†…éƒ¨å›¢é˜Ÿæ¥ç»´æŠ¤æ¨¡å‹ã€‚</p><p> His company learned the hard way an important lesson that the rest of the industry is also discovering: deploying a model isnâ€™t the end of the process. A modelâ€™s performance degrades over time in production. Once a model has been deployed, we still have to continually monitor its performance to detect issues as well as deploy updates to fix these issues.</p><p>ä»–çš„å…¬å¸è‰°éš¾åœ°å¸å–äº†ä¸€ä¸ªé‡è¦çš„æ•™è®­ï¼Œä¸šå†…å…¶ä»–äººä¹Ÿå‘ç°äº†è¿™ä¸€ç‚¹ï¼šéƒ¨ç½²æ¨¡å‹å¹¶ä¸æ˜¯è¿‡ç¨‹çš„ç»ˆç‚¹ã€‚æ¨¡å‹åœ¨ç”Ÿäº§ä¸­çš„æ€§èƒ½ä¼šéšç€æ—¶é—´çš„æ¨ç§»è€Œä¸‹é™ã€‚ä¸€æ—¦éƒ¨ç½²äº†ä¸€ä¸ªæ¨¡å‹ï¼Œæˆ‘ä»¬ä»ç„¶å¿…é¡»æŒç»­ç›‘æ§å…¶æ€§èƒ½ä»¥æ£€æµ‹é—®é¢˜ï¼Œå¹¶éƒ¨ç½²æ›´æ–°ä»¥ä¿®å¤è¿™äº›é—®é¢˜ã€‚</p><p>      Tasks with natural ground truth labels are tasks where the modelâ€™s predictions can be automatically evaluated or partially evaluated by the system. An example is the model that estimates time of arrival on Google Maps. By the end of a trip, Google Maps knows how long the trip actually took, and thus can evaluate the accuracy of the predicted time of arrival.</p><p>å¸¦æœ‰è‡ªç„¶åœ°é¢çœŸå€¼æ ‡ç­¾çš„ä»»åŠ¡æ˜¯ç³»ç»Ÿå¯ä»¥è‡ªåŠ¨è¯„ä¼°æˆ–éƒ¨åˆ†è¯„ä¼°æ¨¡å‹é¢„æµ‹çš„ä»»åŠ¡ã€‚è°·æ­Œåœ°å›¾ä¸Šä¼°è®¡åˆ°è¾¾æ—¶é—´çš„æ¨¡å‹å°±æ˜¯ä¸€ä¸ªä¾‹å­ã€‚åœ¨æ—…è¡Œç»“æŸæ—¶ï¼Œè°·æ­Œåœ°å›¾çŸ¥é“æ—…è¡Œå®é™…èŠ±è´¹äº†å¤šé•¿æ—¶é—´ï¼Œå› æ­¤å¯ä»¥è¯„ä¼°é¢„æµ‹åˆ°è¾¾æ—¶é—´çš„å‡†ç¡®æ€§ã€‚</p><p> Natural labels are ideal for evaluating a modelâ€™s performance. However, even if your task doesnâ€™t inherently have natural labels, itâ€™s possible to set up your system in a way that allows you to collect some feedback on your model. For example, if youâ€™re building a translation system like Google Translate, you can have the option for the community to submit alternative translations for bad translations. Newsfeed ranking is not a task with inherent labels, but by adding the like button and other reactions to each newsfeed item, Facebook is able to collect feedback on their ranking algorithm.</p><p>è‡ªç„¶æ ‡ç­¾æ˜¯è¯„ä¼°æ¨¡å‹æ€§èƒ½çš„ç†æƒ³é€‰æ‹©ã€‚ç„¶è€Œï¼Œå³ä½¿ä½ çš„ä»»åŠ¡æœ¬èº«æ²¡æœ‰è‡ªç„¶çš„æ ‡ç­¾ï¼Œä¹Ÿå¯ä»¥é€šè¿‡æŸç§æ–¹å¼è®¾ç½®ä½ çš„ç³»ç»Ÿï¼Œè®©ä½ å¯ä»¥æ”¶é›†ä¸€äº›å…³äºæ¨¡å‹çš„åé¦ˆã€‚ä¾‹å¦‚ï¼Œå¦‚æœä½ æ­£åœ¨æ„å»ºä¸€ä¸ªåƒGoogle Translateè¿™æ ·çš„ç¿»è¯‘ç³»ç»Ÿï¼Œä½ å¯ä»¥é€‰æ‹©è®©ç¤¾åŒºä¸ºç³Ÿç³•çš„ç¿»è¯‘æäº¤æ›¿ä»£ç¿»è¯‘ã€‚æ–°é—»æºæ’åä¸æ˜¯ä¸€é¡¹å¸¦æœ‰å›ºæœ‰æ ‡ç­¾çš„ä»»åŠ¡ï¼Œä½†é€šè¿‡åœ¨æ¯ä¸ªæ–°é—»æºé¡¹ç›®ä¸­æ·»åŠ likeæŒ‰é’®å’Œå…¶ä»–ååº”ï¼ŒFacebookèƒ½å¤Ÿæ”¶é›†å…³äºå…¶æ’åç®—æ³•çš„åé¦ˆã€‚</p><p> For tasks with natural ground truth labels, the time it takes from when a prediction is served until when the feedback on it is provided is the feedback loop length.</p><p>å¯¹äºå…·æœ‰è‡ªç„¶åœ°é¢çœŸå€¼æ ‡ç­¾çš„ä»»åŠ¡ï¼Œä»æä¾›é¢„æµ‹åˆ°æä¾›åé¦ˆæ‰€éœ€çš„æ—¶é—´æ˜¯åé¦ˆå›è·¯é•¿åº¦ã€‚</p><p> Tasks with short feedback loops are tasks where ground truth labels are generally available within minutes. The canonical example of this type of task is recommender systems. The goal of a recommender system is to recommend users items they would like. Whether a user clicks on the recommended item or not can be seen as the feedback for that recommendation. A recommendation that gets clicked on can be presumed to be a good recommendation (i.e. the label is POSITIVE) and a recommendation that doesnâ€™t get clicked on can be presumed to be bad (i.e. the label is NEGATIVE). Many tasks can be framed as recommendation tasks. For example, you can frame the task of predicting adsâ€™ click-through rates as recommending the most relevant ads to users based on their activity histories and profiles.</p><p>å…·æœ‰çŸ­åé¦ˆå›è·¯çš„ä»»åŠ¡é€šå¸¸åœ¨å‡ åˆ†é’Ÿå†…å°±å¯ä»¥è·å¾—åœ°é¢çœŸç›¸æ ‡ç­¾ã€‚è¿™ç±»ä»»åŠ¡çš„å…¸å‹ä¾‹å­æ˜¯æ¨èç³»ç»Ÿã€‚æ¨èç³»ç»Ÿçš„ç›®æ ‡æ˜¯å‘ç”¨æˆ·æ¨èä»–ä»¬æƒ³è¦çš„é¡¹ç›®ã€‚æ— è®ºç”¨æˆ·æ˜¯å¦ç‚¹å‡»äº†æ¨èé¡¹ç›®ï¼Œéƒ½å¯ä»¥è¢«è§†ä¸ºå¯¹è¯¥æ¨èçš„åé¦ˆã€‚è¢«ç‚¹å‡»çš„æ¨èå¯ä»¥è¢«è®¤ä¸ºæ˜¯å¥½çš„æ¨èï¼ˆå³æ ‡ç­¾æ˜¯è‚¯å®šçš„ï¼‰ï¼Œè€Œæ²¡æœ‰è¢«ç‚¹å‡»çš„æ¨èå¯ä»¥è¢«è®¤ä¸ºæ˜¯åçš„æ¨èï¼ˆå³æ ‡ç­¾æ˜¯å¦å®šçš„ï¼‰ã€‚è®¸å¤šä»»åŠ¡å¯ä»¥è¢«å®šä¹‰ä¸ºæ¨èä»»åŠ¡ã€‚ä¾‹å¦‚ï¼Œä½ å¯ä»¥å°†é¢„æµ‹å¹¿å‘Šç‚¹å‡»ç‡çš„ä»»åŠ¡è®¾å®šä¸ºæ ¹æ®ç”¨æˆ·çš„æ´»åŠ¨å†å²å’Œä¸ªäººèµ„æ–™å‘ç”¨æˆ·æ¨èæœ€ç›¸å…³çš„å¹¿å‘Šã€‚</p><p> However, not all recommender systems have short feedback loops. Depending on the nature of the item to be recommended, the delay until labels can be seconds to hours, and in some extreme cases, days or weeks. If the recommended items are subreddits to subscribe to on Reddit, people to follow on Twitter, videos to watch next on Tiktok, etc., the time between when the item is recommended until itâ€™s clicked on, if itâ€™s clicked on at all, is seconds. If you work with longer content types like blog posts or articles or YouTube videos, it can be minutes, even hours. However, if you build a system to recommend clothes for users like the one Stitch Fix has, you wouldnâ€™t get feedback until users have received the items and tried them on, which could be weeks later.</p><p>ç„¶è€Œï¼Œå¹¶ä¸æ˜¯æ‰€æœ‰çš„æ¨èç³»ç»Ÿéƒ½æœ‰çŸ­åé¦ˆå›è·¯ã€‚æ ¹æ®æ‰€æ¨èç‰©å“çš„æ€§è´¨ï¼Œæ ‡ç­¾çš„å»¶è¿Ÿæ—¶é—´å¯ä»¥æ˜¯å‡ ç§’åˆ°å‡ å°æ—¶ï¼Œåœ¨æŸäº›æç«¯æƒ…å†µä¸‹ï¼Œå¯ä»¥æ˜¯å‡ å¤©æˆ–å‡ å‘¨ã€‚å¦‚æœæ¨èçš„é¡¹ç›®æ˜¯è¦åœ¨Redditä¸Šè®¢é˜…çš„SubRedditã€è¦åœ¨Twitterä¸Šå…³æ³¨çš„äººã€è¦åœ¨Tiktokä¸Šè§‚çœ‹çš„ä¸‹ä¸€ä¸ªè§†é¢‘ç­‰ï¼Œé‚£ä¹ˆä»æ¨èé¡¹ç›®åˆ°ç‚¹å‡»å®ƒï¼ˆå¦‚æœç‚¹å‡»äº†å®ƒï¼‰ä¹‹é—´çš„æ—¶é—´æ˜¯ç§’ã€‚å¦‚æœä½ å¤„ç†è¾ƒé•¿çš„å†…å®¹ç±»å‹ï¼Œå¦‚åšå®¢æ–‡ç« ã€æ–‡ç« æˆ–YouTubeè§†é¢‘ï¼Œå¯èƒ½éœ€è¦å‡ åˆ†é’Ÿç”šè‡³å‡ å°æ—¶ã€‚ç„¶è€Œï¼Œå¦‚æœä½ å»ºç«‹äº†ä¸€ä¸ªç³»ç»Ÿï¼Œåƒone Stitch Fixé‚£æ ·ä¸ºç”¨æˆ·æ¨èè¡£æœï¼Œé‚£ä¹ˆåœ¨ç”¨æˆ·æ”¶åˆ°è¿™äº›è¡£æœå¹¶è¯•ç©¿ä¹‹å‰ï¼Œä½ ä¸ä¼šå¾—åˆ°åé¦ˆï¼Œè¿™å¯èƒ½éœ€è¦å‡ å‘¨åã€‚</p><p> Unless next to each recommended item, thereâ€™s a prompt that says: â€œ Do you like this recommendation? Yes / Noâ€, recommender systems donâ€™t have explicit negative labels. Even if you add that prompt, thereâ€™s no guarantee that users will respond to it. Typically, a recommendation is presumed to be bad if thereâ€™s a lack of positive feedback. After a certain time window, if there is no click, the label is presumed to be negative. Choosing the right window length requires thorough consideration, as it involves the speed and accuracy tradeoff. A short window length means that you can capture labels faster, which allows you to use these labels for monitoring and continual learning. However, a short window length also means that you might prematurely label an item as no click before itâ€™s being clicked on.</p><p>é™¤éæ¯ä¸ªæ¨èé¡¹ç›®æ—è¾¹éƒ½æœ‰ä¸€ä¸ªæç¤ºï¼šâ€œä½ å–œæ¬¢è¿™ä¸ªæ¨èå—ï¼Ÿæ˜¯/å¦â€ï¼Œå¦åˆ™æ¨èç³»ç»Ÿæ²¡æœ‰æ˜ç¡®çš„è´Ÿé¢æ ‡ç­¾ã€‚å³ä½¿ä½ æ·»åŠ äº†è¿™ä¸ªæç¤ºï¼Œä¹Ÿä¸èƒ½ä¿è¯ç”¨æˆ·ä¼šå“åº”ã€‚é€šå¸¸ï¼Œå¦‚æœç¼ºä¹æ­£é¢åé¦ˆï¼Œå»ºè®®è¢«è®¤ä¸ºæ˜¯ä¸å¥½çš„ã€‚åœ¨ç‰¹å®šçš„æ—¶é—´çª—å£åï¼Œå¦‚æœæ²¡æœ‰ç‚¹å‡»ï¼Œåˆ™å‡å®šæ ‡ç­¾ä¸ºè´Ÿç‰‡ã€‚é€‰æ‹©æ­£ç¡®çš„çª—å£é•¿åº¦éœ€è¦ä»”ç»†è€ƒè™‘ï¼Œå› ä¸ºå®ƒæ¶‰åŠé€Ÿåº¦å’Œç²¾åº¦çš„æƒè¡¡ã€‚çŸ­çª—å£é•¿åº¦æ„å‘³ç€æ‚¨å¯ä»¥æ›´å¿«åœ°æ•è·æ ‡ç­¾ï¼Œè¿™å…è®¸æ‚¨ä½¿ç”¨è¿™äº›æ ‡ç­¾è¿›è¡Œç›‘æ§å’ŒæŒç»­å­¦ä¹ ã€‚ç„¶è€Œï¼ŒçŸ­çª—å£é•¿åº¦ä¹Ÿæ„å‘³ç€æ‚¨å¯èƒ½ä¼šè¿‡æ—©åœ°å°†æŸä¸ªé¡¹ç›®æ ‡è®°ä¸ºâ€œåœ¨è¢«å•å‡»ä¹‹å‰ä¸å•å‡»â€ã€‚</p><p> No matter how long you set your window length to be, there might still be premature negative labels. In early 2021, a  study by the Ads team at Twitter found that even though the majority of clicks on ads happen within the first 5 minutes, some clicks happen hours after when the ad is shown. This means that this type of label tends to give an underestimate of the actual click-through rate. If you only record 1000 clicks, the actual number of clicks might be a bit over 1000 clicks.</p><p>æ— è®ºä½ å°†çª—å£é•¿åº¦è®¾ç½®ä¸ºå¤šé•¿ï¼Œéƒ½å¯èƒ½ä¼šå‡ºç°è¿‡æ—©çš„è´Ÿé¢æ ‡ç­¾ã€‚2021å¹´åˆï¼Œæ¨ç‰¹å¹¿å‘Šå›¢é˜Ÿçš„ç ”ç©¶å‘ç°ï¼Œå³ä½¿å¹¿å‘Šç‚¹å‡»æ¬¡æ•°æœ€å¤šå‘ç”Ÿåœ¨5åˆ†é’Ÿå†…ï¼Œä½†ç‚¹å‡»å¹¿å‘Šåå‡ å°æ—¶å°±ä¼šå‡ºç°ä¸€äº›ç‚¹å‡»ã€‚è¿™æ„å‘³ç€è¿™ç±»æ ‡ç­¾å¾€å¾€ä½ä¼°äº†å®é™…ç‚¹å‡»ç‡ã€‚å¦‚æœä½ åªè®°å½•äº†1000æ¬¡ç‚¹å‡»ï¼Œå®é™…çš„ç‚¹å‡»æ¬¡æ•°å¯èƒ½ä¼šè¶…è¿‡1000æ¬¡ã€‚</p><p> For tasks with long feedback loops, natural labels might not arrive for weeks or even months. Fraud detection is an example of a task with long feedback loops. For a certain period of time after a transaction, users can dispute whether that transaction is fraudulent or not. For example, when a customer read their credit cardâ€™s statement and saw a transaction they didnâ€™t recognize, they might dispute with their bank, giving the bank the feedback to label that transaction as fraudulent. A typical dispute window is a month to three months. After the dispute window has passed, if thereâ€™s no dispute from the user, you can presume the transaction to be legitimate.</p><p>å¯¹äºåé¦ˆå¾ªç¯è¾ƒé•¿çš„ä»»åŠ¡ï¼Œè‡ªç„¶æ ‡ç­¾å¯èƒ½éœ€è¦æ•°å‘¨ç”šè‡³æ•°æœˆæ‰èƒ½åˆ°è¾¾ã€‚æ¬ºè¯ˆæ£€æµ‹å°±æ˜¯ä¸€ä¸ªé•¿åé¦ˆå¾ªç¯ä»»åŠ¡çš„ä¾‹å­ã€‚åœ¨äº¤æ˜“ç»“æŸåçš„ä¸€æ®µæ—¶é—´å†…ï¼Œç”¨æˆ·å¯ä»¥è´¨ç–‘è¯¥äº¤æ˜“æ˜¯å¦æ¬ºè¯ˆã€‚ä¾‹å¦‚ï¼Œå½“å®¢æˆ·é˜…è¯»ä¿¡ç”¨å¡å¯¹è´¦å•ï¼Œå‘ç°ä¸€ç¬”ä»–ä»¬ä¸è®¤è¯†çš„äº¤æ˜“æ—¶ï¼Œä»–ä»¬å¯èƒ½ä¼šä¸é“¶è¡Œå‘ç”Ÿäº‰è®®ï¼Œå‘é“¶è¡Œæä¾›åé¦ˆï¼Œå°†è¯¥äº¤æ˜“æ ‡è®°ä¸ºæ¬ºè¯ˆã€‚ä¸€ä¸ªå…¸å‹çš„äº‰è®®çª—å£æ˜¯ä¸€ä¸ªæœˆåˆ°ä¸‰ä¸ªæœˆã€‚äº‰è®®çª—å£è¿‡åï¼Œå¦‚æœç”¨æˆ·æ²¡æœ‰äº‰è®®ï¼Œæ‚¨å¯ä»¥å‡å®šè¯¥äº¤æ˜“æ˜¯åˆæ³•çš„ã€‚</p><p> Labels with long feedback loops are helpful for reporting a modelâ€™s performance on quarterly or yearly business reports. However, they are not very helpful if you want to detect issues with your models as soon as possible. If thereâ€™s a problem with your fraud detection model and it takes you months to catch, by the time the problem is fixed, all the fraudulent transactions your faulty model let through might have caused a small business to go bankrupt.</p><p>å¸¦æœ‰é•¿åé¦ˆå¾ªç¯çš„æ ‡ç­¾æœ‰åŠ©äºåœ¨å­£åº¦æˆ–å¹´åº¦ä¸šåŠ¡æŠ¥å‘Šä¸­æŠ¥å‘Šæ¨¡å‹çš„æ€§èƒ½ã€‚ç„¶è€Œï¼Œå¦‚æœä½ æƒ³å°½å¿«å‘ç°æ¨¡å‹çš„é—®é¢˜ï¼Œå®ƒä»¬å¹¶ä¸æ˜¯å¾ˆæœ‰å¸®åŠ©ã€‚å¦‚æœä½ çš„æ¬ºè¯ˆæ£€æµ‹æ¨¡å‹æœ‰é—®é¢˜ï¼Œéœ€è¦å‡ ä¸ªæœˆæ‰èƒ½å‘ç°ï¼Œç­‰åˆ°é—®é¢˜è§£å†³æ—¶ï¼Œä½ çš„é”™è¯¯æ¨¡å‹æ³„éœ²çš„æ‰€æœ‰æ¬ºè¯ˆäº¤æ˜“éƒ½å¯èƒ½å¯¼è‡´ä¸€å®¶å°ä¼ä¸šç ´äº§ã€‚</p><p>  Before we identify the cause of ML system failures, letâ€™s briefly discuss what an ML system failure is. A failure happens when one or more expectations of the system is violated. In traditional software, we mostly care about a systemâ€™s operational expectations: whether the system executes its logics within the expected operational metrics such as the expected latency and throughput.</p><p>åœ¨ç¡®å®šMLç³»ç»Ÿæ•…éšœçš„åŸå› ä¹‹å‰ï¼Œè®©æˆ‘ä»¬ç®€è¦è®¨è®ºä¸€ä¸‹ä»€ä¹ˆæ˜¯MLç³»ç»Ÿæ•…éšœã€‚å½“è¿åç³»ç»Ÿçš„ä¸€ä¸ªæˆ–å¤šä¸ªé¢„æœŸæ—¶ï¼Œå°±ä¼šå‘ç”Ÿæ•…éšœã€‚åœ¨ä¼ ç»Ÿè½¯ä»¶ä¸­ï¼Œæˆ‘ä»¬ä¸»è¦å…³å¿ƒç³»ç»Ÿçš„æ“ä½œé¢„æœŸï¼šç³»ç»Ÿæ˜¯å¦åœ¨é¢„æœŸçš„æ“ä½œæŒ‡æ ‡ï¼ˆå¦‚é¢„æœŸçš„å»¶è¿Ÿå’Œååé‡ï¼‰å†…æ‰§è¡Œå…¶é€»è¾‘ã€‚</p><p> For an ML system, we care about both its operational metrics and its ML performance metrics. For example, consider an English-French machine translation system. Its operational expectation might be that given an English sentence, the system returns a French translation within a second latency. Its ML performance expectation is that the returned translation is an accurate translation of the original English sentence 99% of the time.</p><p>å¯¹äºMLç³»ç»Ÿï¼Œæˆ‘ä»¬å…³å¿ƒå®ƒçš„æ“ä½œæŒ‡æ ‡å’ŒMLæ€§èƒ½æŒ‡æ ‡ã€‚ä¾‹å¦‚ï¼Œè€ƒè™‘ä¸€ä¸ªè‹±æ³•æœºå™¨ç¿»è¯‘ç³»ç»Ÿã€‚å®ƒçš„æ“ä½œé¢„æœŸå¯èƒ½æ˜¯ï¼Œç»™å®šä¸€ä¸ªè‹±è¯­å¥å­ï¼Œç³»ç»Ÿä¼šåœ¨ç¬¬äºŒä¸ªå»¶è¿Ÿå†…è¿”å›ä¸€ä¸ªæ³•è¯­ç¿»è¯‘ã€‚å®ƒçš„MLæ€§èƒ½é¢„æœŸæ˜¯ï¼Œè¿”å›çš„è¯‘æ–‡åœ¨99%çš„æ—¶é—´å†…æ˜¯å¯¹åŸå§‹è‹±è¯­å¥å­çš„å‡†ç¡®ç¿»è¯‘ã€‚</p><p> If you enter an English sentence into the system and donâ€™t get back a translation, the first expectation is violated, so this is a system failure.</p><p>å¦‚æœä½ åœ¨ç³»ç»Ÿä¸­è¾“å…¥äº†ä¸€ä¸ªè‹±è¯­å¥å­ï¼Œä½†æ²¡æœ‰å¾—åˆ°ç¿»è¯‘ï¼Œé‚£ä¹ˆç¬¬ä¸€ä¸ªæœŸæœ›å€¼å°±è¢«è¿åäº†ï¼Œå› æ­¤è¿™æ˜¯ä¸€ä¸ªç³»ç»Ÿæ•…éšœã€‚</p><p> If you get back a translation that isnâ€™t correct, itâ€™s not necessarily a system failure because the accuracy expectation allows some margin of error. However, if you keep entering different English sentences into the system and keep getting back wrong translations, the second expectation is violated, which makes it a system failure.</p><p>å¦‚æœä½ å¾—åˆ°äº†ä¸€ä¸ªä¸æ­£ç¡®çš„ç¿»è¯‘ï¼Œè¿™ä¸ä¸€å®šæ˜¯ç³»ç»Ÿæ•…éšœï¼Œå› ä¸ºç²¾åº¦é¢„æœŸå…è®¸ä¸€å®šçš„è¯¯å·®èŒƒå›´ã€‚ç„¶è€Œï¼Œå¦‚æœä½ ä¸æ–­åœ°åœ¨ç³»ç»Ÿä¸­è¾“å…¥ä¸åŒçš„è‹±è¯­å¥å­ï¼Œå¹¶ä¸”ä¸æ–­åœ°å¾—åˆ°é”™è¯¯çš„ç¿»è¯‘ï¼Œé‚£ä¹ˆç¬¬äºŒä¸ªæœŸæœ›å°±è¢«è¿èƒŒäº†ï¼Œè¿™å°±å¯¼è‡´äº†ç³»ç»Ÿæ•…éšœã€‚</p><p> Operational expectation violations are easier to detect, as theyâ€™re usually accompanied by an operational breakage such as a timeout, a 404 error on a webpage, an out of memory error, a segmentation fault, etc. However, ML performance expectation violations are harder to detect as it requires measuring and monitoring the performance of ML models in production. In the example of the English-French machine translation system above, detecting whether the returned translations are correct 99% of the time is difficult if we donâ€™t know what the correct translations are supposed to be. There are countless examples of Google Translateâ€™s painfully wrong translations being used by users because they arenâ€™t aware that these are wrong translations. For this reason, we say that ML systems often fail silently.</p><p>æ“ä½œé¢„æœŸè¿è§„æ›´å®¹æ˜“æ£€æµ‹ï¼Œå› ä¸ºå®ƒä»¬é€šå¸¸ä¼´éšç€æ“ä½œä¸­æ–­ï¼Œä¾‹å¦‚è¶…æ—¶ã€ç½‘é¡µä¸Šçš„404é”™è¯¯ã€å†…å­˜ä¸è¶³é”™è¯¯ã€åˆ†æ®µé”™è¯¯ç­‰ã€‚ç„¶è€Œï¼ŒMLæ€§èƒ½é¢„æœŸè¿è§„æ›´éš¾æ£€æµ‹ï¼Œå› ä¸ºå®ƒéœ€è¦åœ¨ç”Ÿäº§ä¸­æµ‹é‡å’Œç›‘æ§MLæ¨¡å‹çš„æ€§èƒ½ã€‚åœ¨ä¸Šé¢çš„è‹±æ³•æœºå™¨ç¿»è¯‘ç³»ç»Ÿçš„ä¾‹å­ä¸­ï¼Œå¦‚æœæˆ‘ä»¬ä¸çŸ¥é“æ­£ç¡®çš„ç¿»è¯‘åº”è¯¥æ˜¯ä»€ä¹ˆï¼Œé‚£ä¹ˆåœ¨99%çš„æ—¶é—´é‡Œæ£€æµ‹è¿”å›çš„ç¿»è¯‘æ˜¯å¦æ­£ç¡®æ˜¯å¾ˆå›°éš¾çš„ã€‚æœ‰æ— æ•°çš„ä¾‹å­è¡¨æ˜ï¼Œè°·æ­Œç¿»è¯‘çš„é”™è¯¯ç¿»è¯‘è¢«ç”¨æˆ·ä½¿ç”¨ï¼Œå› ä¸ºä»–ä»¬ä¸çŸ¥é“è¿™äº›ç¿»è¯‘æ˜¯é”™è¯¯çš„ã€‚å‡ºäºè¿™ä¸ªåŸå› ï¼Œæˆ‘ä»¬è¯´MLç³»ç»Ÿé€šå¸¸ä¼šæ— å£°åœ°å¤±è´¥ã€‚</p><p> To effectively detect and fix ML system failures in production, itâ€™s useful to understand why a model, after proving to work well during development, would fail in production. Weâ€™ll examine two types of failures:  Software system failures and ML-specific failures. Software system failures are failures that would have happened to non-ML systems. Here are some examples of software system failures.</p><p>ä¸ºäº†æœ‰æ•ˆåœ°æ£€æµ‹å’Œä¿®å¤ç”Ÿäº§ä¸­çš„MLç³»ç»Ÿæ•…éšœï¼Œäº†è§£ä¸€ä¸ªæ¨¡å‹åœ¨å¼€å‘è¿‡ç¨‹ä¸­è¿è¡Œè‰¯å¥½åï¼Œä¸ºä»€ä¹ˆä¼šåœ¨ç”Ÿäº§ä¸­å¤±è´¥æ˜¯å¾ˆæœ‰ç”¨çš„ã€‚æˆ‘ä»¬å°†ç ”ç©¶ä¸¤ç§ç±»å‹çš„æ•…éšœï¼šè½¯ä»¶ç³»ç»Ÿæ•…éšœå’Œç‰¹å®šäºMLçš„æ•…éšœã€‚è½¯ä»¶ç³»ç»Ÿæ•…éšœæ˜¯éMLç³»ç»Ÿå¯èƒ½å‘ç”Ÿçš„æ•…éšœã€‚ä¸‹é¢æ˜¯ä¸€äº›è½¯ä»¶ç³»ç»Ÿæ•…éšœçš„ä¾‹å­ã€‚</p><p> Dependency failure: a software package or a codebase that your system depends on breaks, which leads your system to break. This failure mode is common when the dependency is maintained by a third party, and especially common if the third-party that maintains the dependency no longer exists  1.</p><p>ä¾èµ–å¤±è´¥ï¼šç³»ç»Ÿä¾èµ–çš„è½¯ä»¶åŒ…æˆ–ä»£ç åº“ä¸­æ–­ï¼Œå¯¼è‡´ç³»ç»Ÿä¸­æ–­ã€‚å½“ä¾èµ–å…³ç³»ç”±ç¬¬ä¸‰æ–¹ç»´æŠ¤æ—¶ï¼Œè¿™ç§æ•…éšœæ¨¡å¼å¾ˆå¸¸è§ï¼Œå¦‚æœç»´æŠ¤ä¾èµ–å…³ç³»çš„ç¬¬ä¸‰æ–¹ä¸å†å­˜åœ¨ï¼Œè¿™ç§æ•…éšœæ¨¡å¼å°¤å…¶å¸¸è§1ã€‚</p><p>  Deployment failure: failures caused by deployment errors, such as when you accidentally deploy the binaries of an older version of your model instead of the current version, or when your systems donâ€™t have the right permissions to read or write certain files.</p><p>éƒ¨ç½²å¤±è´¥ï¼šç”±éƒ¨ç½²é”™è¯¯å¼•èµ·çš„å¤±è´¥ï¼Œä¾‹å¦‚ï¼Œå½“æ‚¨æ„å¤–åœ°éƒ¨ç½²äº†æ¨¡å‹çš„æ—§ç‰ˆæœ¬è€Œä¸æ˜¯å½“å‰ç‰ˆæœ¬çš„äºŒè¿›åˆ¶æ–‡ä»¶æ—¶ï¼Œæˆ–è€…å½“æ‚¨çš„ç³»ç»Ÿæ²¡æœ‰è¯»å–æˆ–å†™å…¥æŸäº›æ–‡ä»¶çš„æ­£ç¡®æƒé™æ—¶ã€‚</p><p>  Hardware failures: when the hardware that you use to deploy your model, such as CPUs or GPUs, doesnâ€™t behave the way it should. For example, the CPUs you use might overheat and break down  2.</p><p>ç¡¬ä»¶æ•…éšœï¼šå½“æ‚¨ç”¨äºéƒ¨ç½²æ¨¡å‹çš„ç¡¬ä»¶ï¼ˆå¦‚CPUæˆ–GPUï¼‰è¡¨ç°ä¸æ­£å¸¸æ—¶ã€‚ä¾‹å¦‚ï¼Œæ‚¨ä½¿ç”¨çš„CPUå¯èƒ½è¿‡çƒ­å¹¶å‡ºç°æ•…éšœã€‚</p><p>  Downtime or crashing: if a component of your system runs from a server somewhere, such as AWS or a hosted service, and that server is down, your system will also be down.</p><p>åœæœºæˆ–å´©æºƒï¼šå¦‚æœç³»ç»Ÿçš„æŸä¸ªç»„ä»¶ä»æŸä¸ªæœåŠ¡å™¨ï¼ˆå¦‚AWSæˆ–æ‰˜ç®¡æœåŠ¡ï¼‰è¿è¡Œï¼Œè€Œè¯¥æœåŠ¡å™¨å·²å…³é—­ï¼Œåˆ™ç³»ç»Ÿä¹Ÿå°†å…³é—­ã€‚</p><p> Just because some failures are not specific to ML doesnâ€™t mean itâ€™s not important for ML engineers to understand. In 2020, Daniel Papasian and Todd Underwood, two ML engineers at Google, looked at 96 cases where a large ML pipeline at Google broke. They reviewed data from over the previous 15 years to determine the causes and found out that  60 out of these 96 failures happened due to causes not directly related to ML  3. Most of the issues are related to distributed systems e.g. where the workflow scheduler or orchestrator makes a mistake, or related to the data pipeline e.g. where data from multiple sources is joined incorrectly or the wrong data structures are being used.</p><p>ä»…ä»…å› ä¸ºä¸€äº›æ•…éšœä¸æ˜¯ç‰¹å®šäºMLçš„ï¼Œå¹¶ä¸æ„å‘³ç€MLå·¥ç¨‹å¸ˆç†è§£è¿™äº›æ•…éšœå¹¶ä¸é‡è¦ã€‚2020å¹´ï¼Œè°·æ­Œçš„ä¸¤åMLå·¥ç¨‹å¸ˆä¸¹å°¼å°”Â·å¸•å¸•è¥¿å®‰ï¼ˆDaniel Papasianï¼‰å’Œæ‰˜å¾·Â·å®‰å¾·ä¼å¾·ï¼ˆTodd Underwoodï¼‰ç ”ç©¶äº†96èµ·è°·æ­Œå¤§å‹MLç®¡é“ç ´è£‚çš„æ¡ˆä¾‹ã€‚ä»–ä»¬å›é¡¾äº†è¿‡å»15å¹´çš„æ•°æ®ï¼Œä»¥ç¡®å®šåŸå› ï¼Œå¹¶å‘ç°96æ¬¡æ•…éšœä¸­æœ‰60æ¬¡æ˜¯ç”±äºä¸ML3æ— ç›´æ¥å…³ç³»çš„åŸå› é€ æˆçš„ã€‚å¤§å¤šæ•°é—®é¢˜ä¸åˆ†å¸ƒå¼ç³»ç»Ÿæœ‰å…³ï¼Œä¾‹å¦‚å·¥ä½œæµè°ƒåº¦å™¨æˆ–ç¼–æ’å™¨å‡ºé”™ï¼Œæˆ–ä¸æ•°æ®ç®¡é“æœ‰å…³ï¼Œä¾‹å¦‚æ¥è‡ªå¤šä¸ªæºçš„æ•°æ®è¿æ¥é”™è¯¯æˆ–ä½¿ç”¨äº†é”™è¯¯çš„æ•°æ®ç»“æ„ã€‚</p><p> Addressing software system failures requires not ML skills, but traditional software engineering skills, and addressing them is beyond the scope of this class. Because of the importance of traditional software engineering skills in deploying ML systems, the majority of ML engineering is engineering, not ML  4. For readers interested in learning how to make ML systems reliable from the software engineering perspective, I highly recommend the book   Reliable Machine Learning, also published by Oâ€™Reilly with Todd Underwood as one of the authors.</p><p>è§£å†³è½¯ä»¶ç³»ç»Ÿæ•…éšœéœ€è¦çš„ä¸æ˜¯MLæŠ€èƒ½ï¼Œè€Œæ˜¯ä¼ ç»Ÿçš„è½¯ä»¶å·¥ç¨‹æŠ€èƒ½ï¼Œè§£å†³å®ƒä»¬è¶…å‡ºäº†æœ¬è¯¾ç¨‹çš„èŒƒå›´ã€‚ç”±äºä¼ ç»Ÿè½¯ä»¶å·¥ç¨‹æŠ€èƒ½åœ¨éƒ¨ç½²MLç³»ç»Ÿä¸­çš„é‡è¦æ€§ï¼Œå¤§å¤šæ•°MLå·¥ç¨‹éƒ½æ˜¯å·¥ç¨‹ï¼Œè€Œä¸æ˜¯ML 4ã€‚å¯¹äºæœ‰å…´è¶£ä»è½¯ä»¶å·¥ç¨‹çš„è§’åº¦å­¦ä¹ å¦‚ä½•ä½¿MLç³»ç»Ÿå¯é çš„è¯»è€…ï¼Œæˆ‘å¼ºçƒˆæ¨èOâ€™Reillyä¸Todd Underwoodåˆè‘—çš„ã€Šå¯é çš„æœºå™¨å­¦ä¹ ã€‹ä¸€ä¹¦ã€‚</p><p> A reason for the prevalence of software system failures is that because ML adoption in the industry is still nascent, tooling around ML production is limited and best practices are not yet well developed or standardized. However, as toolings and best practices for ML production mature, there are reasons to believe that the proportion of software system failures will decrease and the proportion of ML-specific failures will increase.</p><p>è½¯ä»¶ç³»ç»Ÿæ•…éšœæ™®éå­˜åœ¨çš„ä¸€ä¸ªåŸå› æ˜¯ï¼Œç”±äºä¸šç•Œå¯¹MLçš„é‡‡ç”¨å°šå¤„äºåˆçº§é˜¶æ®µï¼Œå›´ç»•MLç”Ÿäº§çš„å·¥å…·æœ‰é™ï¼Œæœ€ä½³å®è·µå°šæœªå¾—åˆ°å……åˆ†å¼€å‘æˆ–æ ‡å‡†åŒ–ã€‚ç„¶è€Œï¼Œéšç€MLç”Ÿäº§å·¥å…·å’Œæœ€ä½³å®è·µçš„æˆç†Ÿï¼Œæœ‰ç†ç”±ç›¸ä¿¡è½¯ä»¶ç³»ç»Ÿæ•…éšœçš„æ¯”ä¾‹å°†å‡å°‘ï¼Œè€Œç‰¹å®šäºMLçš„æ•…éšœçš„æ¯”ä¾‹å°†å¢åŠ ã€‚</p><p> ML-specific failures are failures specific to ML systems. Examples include data collection and processing problems, poor hyperparameters, changes in the training pipeline not correctly replicated in the inference pipeline and vice versa, data distribution shifts that cause a modelâ€™s performance to deteriorate over time, edge cases, and degenerate feedback loop.</p><p>ç‰¹å®šäºMLçš„æ•…éšœæ˜¯ç‰¹å®šäºMLç³»ç»Ÿçš„æ•…éšœã€‚ä¾‹å¦‚ï¼Œæ•°æ®æ”¶é›†å’Œå¤„ç†é—®é¢˜ã€è¶…å‚æ•°å·®ã€è®­ç»ƒç®¡é“ä¸­çš„å˜åŒ–æœªåœ¨æ¨ç†ç®¡é“ä¸­æ­£ç¡®å¤åˆ¶ï¼Œåä¹‹äº¦ç„¶ã€å¯¼è‡´æ¨¡å‹æ€§èƒ½éšæ—¶é—´æ¶åŒ–çš„æ•°æ®åˆ†å¸ƒå˜åŒ–ã€è¾¹ç¼˜æƒ…å†µå’Œé€€åŒ–çš„åé¦ˆå›è·¯ã€‚</p><p> In this lecture, weâ€™ll focus on addressing ML-specific failures. Even though they account for a small portion of failures, they can be more dangerous than non-ML failures as theyâ€™re hard to detect and fix, and can prevent ML systems from being used altogether. Weâ€™ve covered data problems, hyperparameter tuning, and the danger of having two separate pipelines for training and inference in previous lectures. In this lecture, weâ€™ll discuss three new but very common problems that arise after a model has been deployed: changing data distribution, edge cases, and degenerate feedback loops.</p><p>åœ¨æœ¬è¯¾ä¸­ï¼Œæˆ‘ä»¬å°†é‡ç‚¹è®¨è®ºç‰¹å®šäºMLçš„æ•…éšœã€‚å°½ç®¡å®ƒä»¬åªå æ•…éšœçš„ä¸€å°éƒ¨åˆ†ï¼Œä½†å®ƒä»¬å¯èƒ½æ¯”éMLæ•…éšœæ›´å±é™©ï¼Œå› ä¸ºå®ƒä»¬å¾ˆéš¾æ£€æµ‹å’Œä¿®å¤ï¼Œå¹¶ä¸”å¯èƒ½ä¼šé˜»æ­¢MLç³»ç»Ÿè¢«å®Œå…¨ä½¿ç”¨ã€‚åœ¨ä¹‹å‰çš„è¯¾ç¨‹ä¸­ï¼Œæˆ‘ä»¬å·²ç»è®¨è®ºäº†æ•°æ®é—®é¢˜ã€è¶…å‚æ•°è°ƒæ•´ï¼Œä»¥åŠä½¿ç”¨ä¸¤æ¡å•ç‹¬çš„ç®¡é“è¿›è¡Œè®­ç»ƒå’Œæ¨ç†çš„å±é™©ã€‚åœ¨æœ¬è¯¾ä¸­ï¼Œæˆ‘ä»¬å°†è®¨è®ºéƒ¨ç½²æ¨¡å‹åå‡ºç°çš„ä¸‰ä¸ªæ–°ä½†éå¸¸å¸¸è§çš„é—®é¢˜ï¼šæ”¹å˜æ•°æ®åˆ†å¸ƒã€è¾¹ç¼˜æƒ…å†µå’Œé€€åŒ–åé¦ˆå¾ªç¯ã€‚</p><p>  When we say that an ML model learns from the training data, it means that the model learns the underlying distribution of the training data with the goal of leveraging this learned distribution to generate accurate predictions for unseen data â€” data that it didnâ€™t see during training. Weâ€™ll go into what this means mathematically in the  Data Distribution Shifts section below. When the model is able to generate accurate predictions for unseen data, we say that this model â€œgeneralizes to unseen data.  5â€ The test data that we use to evaluate a model during development is supposed to represent unseen data, and the modelâ€™s performance on the test data is supposed to give us an idea of how well the model will generalize.</p><p>å½“æˆ‘ä»¬è¯´MLæ¨¡å‹ä»è®­ç»ƒæ•°æ®ä¸­å­¦ä¹ æ—¶ï¼Œè¿™æ„å‘³ç€è¯¥æ¨¡å‹å­¦ä¹ è®­ç»ƒæ•°æ®çš„åŸºæœ¬åˆ†å¸ƒï¼Œç›®çš„æ˜¯åˆ©ç”¨å­¦ä¹ åˆ°çš„åˆ†å¸ƒä¸ºçœ‹ä¸è§çš„æ•°æ®ç”Ÿæˆå‡†ç¡®çš„é¢„æµ‹ï¼Œè¿™äº›æ•°æ®æ˜¯å®ƒåœ¨è®­ç»ƒæœŸé—´æ²¡æœ‰çœ‹åˆ°çš„ã€‚æˆ‘ä»¬å°†åœ¨ä¸‹é¢çš„æ•°æ®åˆ†å¸ƒéƒ¨åˆ†ä»æ•°å­¦ä¸Šæ¢è®¨è¿™æ„å‘³ç€ä»€ä¹ˆã€‚å½“æ¨¡å‹èƒ½å¤Ÿä¸ºçœ‹ä¸è§çš„æ•°æ®ç”Ÿæˆå‡†ç¡®çš„é¢„æµ‹æ—¶ï¼Œæˆ‘ä»¬è¯´è¿™ä¸ªæ¨¡å‹â€œæ¨å¹¿åˆ°çœ‹ä¸è§çš„æ•°æ®ã€‚5â€æˆ‘ä»¬åœ¨å¼€å‘è¿‡ç¨‹ä¸­ç”¨æ¥è¯„ä¼°æ¨¡å‹çš„æµ‹è¯•æ•°æ®åº”è¯¥ä»£è¡¨çœ‹ä¸è§çš„æ•°æ®ï¼Œæ¨¡å‹åœ¨æµ‹è¯•æ•°æ®ä¸Šçš„è¡¨ç°åº”è¯¥è®©æˆ‘ä»¬äº†è§£æ¨¡å‹æ¨å¹¿çš„æ•ˆæœã€‚</p><p> One of the first things I learned in ML courses is that itâ€™s essential for the training data and the unseen data to come from the same distribution. The assumption is that the unseen data comes from a  stationary distribution that is  the same as the training data distribution. If the unseen data comes from a different distribution, the model might not generalize well  6.</p><p>æˆ‘åœ¨MLè¯¾ç¨‹ä¸­å­¦åˆ°çš„ç¬¬ä¸€ä»¶äº‹æ˜¯ï¼Œè®­ç»ƒæ•°æ®å’Œçœ‹ä¸è§çš„æ•°æ®å¿…é¡»æ¥è‡ªåŒä¸€ä¸ªåˆ†å¸ƒã€‚å‡è®¾çœ‹ä¸è§çš„æ•°æ®æ¥è‡ªä¸è®­ç»ƒæ•°æ®åˆ†å¸ƒç›¸åŒçš„å¹³ç¨³åˆ†å¸ƒã€‚å¦‚æœçœ‹ä¸è§çš„æ•°æ®æ¥è‡ªä¸åŒçš„åˆ†å¸ƒï¼Œè¯¥æ¨¡å‹å¯èƒ½æ— æ³•å¾ˆå¥½åœ°æ¨å¹¿ã€‚</p><p> This assumption is incorrect in most cases for two reasons. First, the underlying distribution of the real-world data is unlikely to be  the same as the underlying distribution of the training data. Curating a training dataset that can accurately represent the data that a model will encounter in production turns out to be very difficult  7. Real-world data is multi-faceted, and in many cases, virtually infinite, whereas training data is finite and constrained by the time, compute, and human resources available during the dataset creation and processing. There are many different selection and sampling biases that can happen and make real-world data diverge from training data. The divergence can be something as minor as real-world data using a different type of encoding of emojis. This type of divergence leads to a common failure mode known as  the train-serving skew: a model that does great in development but performs poorly when deployed.</p><p>è¿™ç§å‡è®¾åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹æ˜¯ä¸æ­£ç¡®çš„ï¼ŒåŸå› æœ‰äºŒã€‚é¦–å…ˆï¼ŒçœŸå®ä¸–ç•Œæ•°æ®çš„æ½œåœ¨åˆ†å¸ƒä¸å¤ªå¯èƒ½ä¸è®­ç»ƒæ•°æ®çš„æ½œåœ¨åˆ†å¸ƒç›¸åŒã€‚ç­–åˆ’ä¸€ä¸ªèƒ½å¤Ÿå‡†ç¡®è¡¨ç¤ºæ¨¡å‹åœ¨ç”Ÿäº§ä¸­ä¼šé‡åˆ°çš„æ•°æ®çš„è®­ç»ƒæ•°æ®é›†æ˜¯éå¸¸å›°éš¾çš„ã€‚ç°å®ä¸–ç•Œä¸­çš„æ•°æ®æ˜¯å¤šæ–¹é¢çš„ï¼Œåœ¨è®¸å¤šæƒ…å†µä¸‹å‡ ä¹æ˜¯æ— é™çš„ï¼Œè€Œè®­ç»ƒæ•°æ®æ˜¯æœ‰é™çš„ï¼Œå¹¶ä¸”å—æ•°æ®é›†åˆ›å»ºå’Œå¤„ç†æœŸé—´å¯ç”¨çš„æ—¶é—´ã€è®¡ç®—å’ŒäººåŠ›èµ„æºçš„é™åˆ¶ã€‚å¯èƒ½ä¼šå‡ºç°è®¸å¤šä¸åŒçš„é€‰æ‹©å’Œé‡‡æ ·åå·®ï¼Œä½¿ç°å®ä¸–ç•Œçš„æ•°æ®ä¸è®­ç»ƒæ•°æ®äº§ç”Ÿåå·®ã€‚è¿™ç§å·®å¼‚å¯èƒ½ä¸ä½¿ç”¨ä¸åŒç±»å‹è¡¨æƒ…ç¼–ç çš„çœŸå®ä¸–ç•Œæ•°æ®ä¸€æ ·å°ã€‚è¿™ç§ç±»å‹çš„åˆ†æ­§å¯¼è‡´äº†ä¸€ç§å¸¸è§çš„æ•…éšœæ¨¡å¼ï¼Œç§°ä¸ºâ€œåˆ—è½¦æœåŠ¡å€¾æ–œâ€ï¼šè¿™ç§æ¨¡å¼åœ¨å¼€å‘ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨éƒ¨ç½²æ—¶è¡¨ç°ä¸ä½³ã€‚</p><p> Second, the real world isnâ€™t  stationary. Things change. Data distributions shift. In 2019, when people searched for Wuhan, they likely wanted to get travel information, but since COVID-19, when people search for Wuhan, they likely want to know about the place where COVID-19 originated. Another common failure mode is that a model does great when first deployed, but its performance degrades over time as the data distribution changes. This failure mode needs to be continually monitored and detected for as long as a model remains in production.</p><p>ç¬¬äºŒï¼Œç°å®ä¸–ç•Œä¸æ˜¯é™æ­¢çš„ã€‚äº‹æƒ…å˜äº†ã€‚æ•°æ®åˆ†å¸ƒå‘ç”Ÿäº†å˜åŒ–ã€‚2019ï¼Œ2019å† çŠ¶ç—…æ¯’ç–¾ç—…2019å† çŠ¶ç—…æ¯’ç–¾ç—…ï¼Œä½†å½“äººä»¬æœç´¢æ­¦æ±‰æ—¶ï¼Œä»–ä»¬å¯èƒ½æƒ³å¾—åˆ°æ—…æ¸¸ä¿¡æ¯ï¼Œä½†æ˜¯è‡ªä»COVID-19ï¼Œå½“äººä»¬æœç´¢æ­¦æ±‰æ—¶ï¼Œä»–ä»¬å¯èƒ½æƒ³çŸ¥é“COVID-19èµ·æºçš„åœ°æ–¹ã€‚å¦ä¸€ç§å¸¸è§çš„æ•…éšœæ¨¡å¼æ˜¯ï¼Œæ¨¡å‹åœ¨é¦–æ¬¡éƒ¨ç½²æ—¶è¡¨ç°å‡ºè‰²ï¼Œä½†éšç€æ•°æ®åˆ†å¸ƒçš„å˜åŒ–ï¼Œå…¶æ€§èƒ½ä¼šéšç€æ—¶é—´çš„æ¨ç§»è€Œä¸‹é™ã€‚åªè¦æ¨¡å‹ä»åœ¨ç”Ÿäº§ä¸­ï¼Œå°±éœ€è¦æŒç»­ç›‘æ§å’Œæ£€æµ‹è¿™ç§æ•…éšœæ¨¡å¼ã€‚</p><p> When I use COVID-19 as an example that causes data shifts, some people have the impression that data shifts only happen because of unusual events, which implies they donâ€™t happen often. Data shifts happen all the time, suddenly, gradually, or seasonally. They can happen suddenly because of a specific event, such as when your existing competitors change their pricing policies and you have to update your price predictions in response, or when you launch your product in a new region, or when a celebrity mentions your product which causes a surge in new users, and so on. They can happen gradually because social norms, cultures, languages, trends, industries, and more just change over time. They can also happen due to seasonal variations, such as people might be more likely to request rideshares in the winter when itâ€™s cold and snowy than in the spring.</p><p>å½“æˆ‘ä½¿ç”¨2019å† çŠ¶ç—…æ¯’ç–¾ç—…å¼•èµ·æ•°æ®è½¬ç§»æ—¶ï¼Œä¸€äº›äººä¼šè§‰å¾—æ•°æ®è½¬ç§»åªæ˜¯å› ä¸ºä¸å¯»å¸¸çš„äº‹ä»¶å‘ç”Ÿï¼Œè¿™æ„å‘³ç€å®ƒä»¬ä¸ä¼šç»å¸¸å‘ç”Ÿã€‚æ•°æ®å˜åŒ–æ€»æ˜¯å‘ç”Ÿçš„ï¼Œçªç„¶çš„ã€é€æ¸çš„æˆ–å­£èŠ‚æ€§çš„ã€‚å®ƒä»¬å¯èƒ½ä¼šå› ä¸ºæŸä¸ªç‰¹å®šäº‹ä»¶è€Œçªç„¶å‘ç”Ÿï¼Œä¾‹å¦‚ï¼Œå½“ç°æœ‰ç«äº‰å¯¹æ‰‹æ”¹å˜å…¶å®šä»·æ”¿ç­–æ—¶ï¼Œä½ å¿…é¡»æ›´æ–°ä»·æ ¼é¢„æµ‹ä»¥ä½œå‡ºå›åº”ï¼Œæˆ–è€…å½“ä½ åœ¨ä¸€ä¸ªæ–°çš„åœ°åŒºæ¨å‡ºäº§å“æ—¶ï¼Œæˆ–è€…å½“ä¸€ä½åäººæåˆ°ä½ çš„äº§å“ä»è€Œå¯¼è‡´æ–°ç”¨æˆ·æ¿€å¢æ—¶ï¼Œç­‰ç­‰ã€‚å®ƒä»¬å¯ä»¥é€æ¸å‘ç”Ÿï¼Œå› ä¸ºç¤¾ä¼šè§„èŒƒã€æ–‡åŒ–ã€è¯­è¨€ã€è¶‹åŠ¿ã€è¡Œä¸šç­‰ç­‰éƒ½ä¼šéšç€æ—¶é—´è€Œæ”¹å˜ã€‚è¿™ç§æƒ…å†µä¹Ÿå¯èƒ½å› å­£èŠ‚å˜åŒ–è€Œå‘ç”Ÿï¼Œæ¯”å¦‚äººä»¬å¯èƒ½æ›´å€¾å‘äºåœ¨å¯’å†·ä¸‹é›ªçš„å†¬å­£è€Œä¸æ˜¯æ˜¥å­£è¦æ±‚ä¹˜åé‡å…”ã€‚</p><p> When talking about data shifts, many people imagine that they are due to external changes, such as natural disasters, holiday seasons, or user behaviors. But in reality, due to the complexity of ML systems and the poor practices in deploying them, a large percentage of what might look like data shifts on monitoring dashboards are caused by internal errors  8, such as bugs in the data pipeline, missing values incorrectly filled in, inconsistencies between the features extracted during training and inference, features standardized using statistics from the wrong subset of data, wrong model version, or bugs in the app interface that forces users to change their behaviors.</p><p>å½“è°ˆåˆ°æ•°æ®è½¬ç§»æ—¶ï¼Œè®¸å¤šäººè®¤ä¸ºè¿™æ˜¯ç”±äºå¤–éƒ¨å˜åŒ–é€ æˆçš„ï¼Œæ¯”å¦‚è‡ªç„¶ç¾å®³ã€å‡æœŸæˆ–ç”¨æˆ·è¡Œä¸ºã€‚ä½†åœ¨ç°å®ä¸­ï¼Œç”±äºMLç³»ç»Ÿçš„å¤æ‚æ€§å’Œéƒ¨ç½²è¿‡ç¨‹ä¸­çš„ä¸è‰¯åšæ³•ï¼Œç›‘æ§ä»ªè¡¨ç›˜ä¸Šçœ‹èµ·æ¥åƒæ•°æ®è½¬ç§»çš„å¤§éƒ¨åˆ†éƒ½æ˜¯ç”±å†…éƒ¨é”™è¯¯8é€ æˆçš„ï¼Œä¾‹å¦‚æ•°æ®ç®¡é“ä¸­çš„é”™è¯¯ã€é”™è¯¯å¡«å†™çš„ç¼ºå¤±å€¼ã€ï¼Œåœ¨è®­ç»ƒå’Œæ¨ç†æœŸé—´æå–çš„ç‰¹å¾ã€ä½¿ç”¨é”™è¯¯æ•°æ®å­é›†çš„ç»Ÿè®¡æ•°æ®æ ‡å‡†åŒ–çš„ç‰¹å¾ã€é”™è¯¯çš„æ¨¡å‹ç‰ˆæœ¬æˆ–åº”ç”¨ç¨‹åºç•Œé¢ä¸­è¿«ä½¿ç”¨æˆ·æ”¹å˜å…¶è¡Œä¸ºçš„ç¼ºé™·ä¹‹é—´çš„ä¸ä¸€è‡´ã€‚</p><p> Since this is an error mode that affects almost all ML models, weâ€™ll cover this in detail in the section  Data Distribution Shifts.</p><p>ç”±äºè¿™æ˜¯ä¸€ç§å½±å“å‡ ä¹æ‰€æœ‰MLæ¨¡å‹çš„é”™è¯¯æ¨¡å¼ï¼Œæˆ‘ä»¬å°†åœ¨â€œæ•°æ®åˆ†å¸ƒâ€ä¸€èŠ‚ä¸­è¯¦ç»†ä»‹ç»è¿™ä¸€ç‚¹ã€‚</p><p>  Imagine there existed a self-driving car that can drive you safely 99.99% of the time, but the other 0.01% of the time, it might get into a catastrophic accident that can leave you permanently injured or even dead  9. Would you use that car?</p><p>æƒ³è±¡ä¸€ä¸‹ï¼Œæœ‰ä¸€è¾†è‡ªåŠ¨é©¾é©¶æ±½è½¦å¯ä»¥åœ¨99.99%çš„æ—¶é—´é‡Œå®‰å…¨é©¾é©¶ä½ ï¼Œä½†åœ¨å¦å¤–0.01%çš„æ—¶é—´é‡Œï¼Œå®ƒå¯èƒ½ä¼šé™·å…¥ä¸€åœºç¾éš¾æ€§äº‹æ•…ï¼Œå¯¼è‡´ä½ æ°¸ä¹…å—ä¼¤ç”šè‡³æ­»äº¡ã€‚ä½ ä¼šç”¨é‚£è¾†è½¦å—ï¼Ÿ</p><p> If youâ€™re tempted to say no, youâ€™re not alone. An ML model that performs well on most cases but fails on a small number of cases might not be usable if these failures cause catastrophic consequences. For this reason, major self-driving car companies are focusing on making their systems work on edge cases  10  11  12.</p><p>å¦‚æœä½ æƒ³è¯´ä¸ï¼Œä½ å¹¶ä¸å­¤å•ã€‚å¦‚æœMLæ¨¡å‹åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹è¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨å°‘æ•°æƒ…å†µä¸‹å¤±è´¥ï¼Œé‚£ä¹ˆå¦‚æœè¿™äº›å¤±è´¥å¯¼è‡´ç¾éš¾æ€§åæœï¼Œå®ƒå¯èƒ½ä¸å¯ç”¨ã€‚å‡ºäºè¿™ä¸ªåŸå› ï¼Œä¸»è¦çš„è‡ªåŠ¨é©¾é©¶æ±½è½¦å…¬å¸æ­£ä¸“æ³¨äºä½¿ä»–ä»¬çš„ç³»ç»Ÿåœ¨è¾¹ç¼˜æƒ…å†µä¸‹å·¥ä½œ10 11 12ã€‚</p><p> Edge cases are the data samples so extreme that they cause the model to make catastrophic mistakes. Even though edge cases generally refer to data samples drawn from the same distribution, if there is a sudden increase in the number of data samples in which your model doesnâ€™t perform well on, it could be an indication that the underlying data distribution has shifted.</p><p>è¾¹ç¼˜æƒ…å†µæ˜¯æŒ‡æ•°æ®æ ·æœ¬éå¸¸æç«¯ï¼Œå¯¼è‡´æ¨¡å‹å‡ºç°ç¾éš¾æ€§é”™è¯¯ã€‚å°½ç®¡è¾¹ç¼˜æ¡ˆä¾‹é€šå¸¸æŒ‡çš„æ˜¯ä»åŒä¸€åˆ†å¸ƒä¸­æå–çš„æ•°æ®æ ·æœ¬ï¼Œä½†å¦‚æœæ¨¡å‹åœ¨å…¶ä¸­è¡¨ç°ä¸ä½³çš„æ•°æ®æ ·æœ¬æ•°é‡çªç„¶å¢åŠ ï¼Œåˆ™å¯èƒ½è¡¨æ˜åŸºç¡€æ•°æ®åˆ†å¸ƒå‘ç”Ÿäº†å˜åŒ–ã€‚</p><p> Autonomous vehicles are often used to illustrate how edge cases can prevent an ML system from being deployed. But this is also true for any safety-critical application such as medical diagnosis, traffic control, eDiscovery  13, etc. It can also be true for non-safety-critical applications. Imagine a customer service chatbot that gives reasonable responses to most of the requests, but sometimes, it spits out outrageously racist or sexist content. This chatbot will be a brand risk for any company that wants to use it, thus rendering it unusable.</p><p>è‡ªåŠ¨é©¾é©¶è½¦è¾†é€šå¸¸ç”¨äºè¯´æ˜è¾¹ç¼˜æƒ…å†µå¦‚ä½•é˜»æ­¢éƒ¨ç½²MLç³»ç»Ÿã€‚ä½†è¿™ä¹Ÿé€‚ç”¨äºä»»ä½•å®‰å…¨å…³é”®å‹åº”ç”¨ï¼Œå¦‚åŒ»ç–—è¯Šæ–­ã€äº¤é€šæ§åˆ¶ã€eDiscovery 13ç­‰ã€‚éå®‰å…¨å…³é”®å‹åº”ç”¨ä¹Ÿé€‚ç”¨ã€‚æƒ³è±¡ä¸€ä¸‹ï¼Œä¸€ä¸ªå®¢æˆ·æœåŠ¡èŠå¤©æœºå™¨äººå¯¹å¤§å¤šæ•°è¯·æ±‚éƒ½ç»™å‡ºäº†åˆç†çš„å“åº”ï¼Œä½†æœ‰æ—¶å®ƒä¼šåå‡ºæç«¯ç§æ—ä¸»ä¹‰æˆ–æ€§åˆ«æ­§è§†çš„å†…å®¹ã€‚è¿™ä¸ªèŠå¤©æœºå™¨äººå¯¹ä»»ä½•æƒ³ä½¿ç”¨å®ƒçš„å…¬å¸æ¥è¯´éƒ½æ˜¯ä¸€ä¸ªå“ç‰Œé£é™©ï¼Œå› æ­¤æ— æ³•ä½¿ç”¨ã€‚</p><p>  You might wonder about the differences between an outlier and an edge case. The definition of what makes an edge case varies by discipline. In ML, because of its recent adoption in production, edge cases are still being discovered, which makes their definition contentious.</p><p>ä½ å¯èƒ½æƒ³çŸ¥é“å¼‚å¸¸å€¼å’Œè¾¹ç¼˜æƒ…å†µä¹‹é—´çš„åŒºåˆ«ã€‚è¾¹ç¼˜æ¡ˆä¾‹çš„å®šä¹‰å› å­¦ç§‘è€Œå¼‚ã€‚åœ¨MLä¸­ï¼Œç”±äºå…¶æœ€è¿‘åœ¨ç”Ÿäº§ä¸­çš„é‡‡ç”¨ï¼Œè¾¹ç¼˜æ¡ˆä¾‹ä»åœ¨è¢«å‘ç°ï¼Œè¿™ä½¿å¾—å®ƒä»¬çš„å®šä¹‰æœ‰äº‰è®®ã€‚</p><p> In this lecture, outliers refer to data: an example that differs significantly from other examples. Edge cases refer to performance: an example where a model performs significantly worse than other examples. An outlier can cause a model to perform unusually poorly, which makes it an edge case. However, not all outliers are edge cases. For example, a person jay-walking on a highway is an outlier, but itâ€™s not an edge case if your self-driving car can accurately detect that person and decide on a motion response appropriately.</p><p>åœ¨è¿™å ‚è¯¾ä¸­ï¼Œç¦»ç¾¤å€¼æŒ‡çš„æ˜¯æ•°æ®ï¼šä¸€ä¸ªä¸å…¶ä»–ä¾‹å­æˆªç„¶ä¸åŒçš„ä¾‹å­ã€‚è¾¹ç¼˜æƒ…å†µæŒ‡çš„æ˜¯æ€§èƒ½ï¼šä¸€ä¸ªæ¨¡å‹çš„æ€§èƒ½æ˜æ˜¾ä½äºå…¶ä»–ç¤ºä¾‹çš„ç¤ºä¾‹ã€‚å¼‚å¸¸å€¼å¯èƒ½ä¼šå¯¼è‡´æ¨¡å‹è¡¨ç°å¼‚å¸¸ç³Ÿç³•ï¼Œè¿™ä½¿å…¶æˆä¸ºè¾¹ç¼˜æƒ…å†µã€‚ç„¶è€Œï¼Œå¹¶éæ‰€æœ‰çš„å¼‚å¸¸å€¼éƒ½æ˜¯è¾¹ç¼˜æƒ…å†µã€‚ä¾‹å¦‚ï¼Œåœ¨é«˜é€Ÿå…¬è·¯ä¸Šè¡Œèµ°çš„äººæ˜¯ä¸€ä¸ªå¼‚å¸¸å€¼ï¼Œä½†å¦‚æœä½ çš„è‡ªåŠ¨é©¾é©¶æ±½è½¦èƒ½å¤Ÿå‡†ç¡®åœ°æ£€æµ‹åˆ°é‚£ä¸ªäººå¹¶é€‚å½“åœ°å†³å®šè¿åŠ¨å“åº”ï¼Œé‚£å°±ä¸æ˜¯è¾¹ç¼˜æƒ…å†µã€‚</p><p> During model development, outliers can negatively affect your modelâ€™s performance. In many cases, it might be beneficial to remove outliers as it helps your model to learn better decision boundaries and generalize better to unseen data. However, during inference, you donâ€™t usually have the option to remove o</p><p>åœ¨æ¨¡å‹å¼€å‘è¿‡ç¨‹ä¸­ï¼Œå¼‚å¸¸å€¼å¯èƒ½ä¼šå¯¹æ¨¡å‹çš„æ€§èƒ½äº§ç”Ÿè´Ÿé¢å½±å“ã€‚åœ¨è®¸å¤šæƒ…å†µä¸‹ï¼Œåˆ é™¤å¼‚å¸¸å€¼å¯èƒ½æ˜¯æœ‰ç›Šçš„ï¼Œå› ä¸ºå®ƒæœ‰åŠ©äºæ‚¨çš„æ¨¡å‹æ›´å¥½åœ°äº†è§£å†³ç­–è¾¹ç•Œï¼Œå¹¶æ›´å¥½åœ°æ¦‚æ‹¬æœªçŸ¥æ•°æ®ã€‚ç„¶è€Œï¼Œåœ¨æ¨ç†è¿‡ç¨‹ä¸­ï¼Œä½ é€šå¸¸æ²¡æœ‰åˆ é™¤oçš„é€‰é¡¹</p><p>......</p><p>......</p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/åˆ†å‘/">#åˆ†å‘</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/æ¨¡å‹/">#æ¨¡å‹</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/è®¾è®¡/">#è®¾è®¡</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/åˆ›æ„/">#åˆ›æ„</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/æ‘„å½±/">#æ‘„å½±</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/å›¾ç‰‡/">#å›¾ç‰‡</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/æ¸¸æˆ/">#æ¸¸æˆ</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/è½¯ä»¶/">#è½¯ä»¶</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/è§†é¢‘/">#è§†é¢‘</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/å¹¿å‘Š/">#å¹¿å‘Š</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/æ‰‹æœº/">#æ‰‹æœº</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/ç½‘ç«™/">#ç½‘ç«™</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/å…è´¹/">#å…è´¹</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/ä¸‹è½½/">#ä¸‹è½½</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/å¾®è½¯/">#å¾®è½¯</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/è‹¹æœ/">#è‹¹æœ</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/éŸ³ä¹/">#éŸ³ä¹</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/åšå®¢/">#åšå®¢</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/æ¶æ/">#æ¶æ</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/è‰ºæœ¯/">#è‰ºæœ¯</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/è°·æ­Œ/">#è°·æ­Œ</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/å·¥å…·/">#å·¥å…·</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy;2012-2021 diglog.com </div></div></body></html>